{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from map_dm_nav.visualisation_tools import plot_likelihood\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_transitions_per_actions(B, agent_state_mapping,possible_actions, selected_actions=[]):\n",
    "    labels = [value['state'] for value in agent_state_mapping.values()]\n",
    "    actions_plots = []\n",
    "    l = len(labels) *1.5\n",
    "    for action in range(len(possible_actions)):\n",
    "        if len(selected_actions) > 0 and action not in selected_actions:\n",
    "            continue\n",
    "        fig = plt.figure(action, figsize=(l,l))\n",
    "        a = B[2:4,:len(labels),action]\n",
    "        fig = sns.heatmap(a, linewidth=0.5, vmin=0,vmax=1.0 ,cmap=\"YlOrBr\", xticklabels=labels, yticklabels=['2','3'])\n",
    "        fig.tick_params(axis='both', which='major', labelsize=14)  # Adjust label font size\n",
    "        fig.set_title(possible_actions[action], fontsize=20)\n",
    "        fig.set_xlabel('Prev State', fontsize=16)\n",
    "        fig.set_ylabel('Next State', fontsize=16)\n",
    "        \n",
    "        actions_plots.append(fig)\n",
    "    return actions_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_transitions(B: np.ndarray, state_map: dict, actions: dict) -> np.ndarray:\n",
    "    \"\"\"Plot Transitions matrix showing the probability of a transition between two states given a certain action.\"\"\"\n",
    "    \n",
    "    sorted_state_map = dict(sorted(state_map.items(), key=lambda item: item[1]['state']))\n",
    "    labels = [f\"{key} ({value['state']})\" for key, value in sorted_state_map.items()]\n",
    "    print('labels',labels)\n",
    "    n_actions = len(actions)\n",
    "    l = int(np.ceil(np.sqrt(n_actions)))\n",
    "    L = int(np.ceil(n_actions / l))\n",
    "    \n",
    "    fig, axes = plt.subplots(L, l)\n",
    "    \n",
    "    axes = np.atleast_2d(axes)  # Ensure axes is always a 2D array\n",
    "    count = 0\n",
    "    print('L and l', L,l)\n",
    "    for i in range(L):\n",
    "        for j in range(l):\n",
    "            if count >= n_actions:\n",
    "                fig.delaxes(axes[i][j])\n",
    "                continue\n",
    "            \n",
    "            if count not in actions:\n",
    "                print(count, 'not in actions, n actions',n_actions)\n",
    "                continue\n",
    "\n",
    "            action_str = str(actions[count])  # Convert action name to string\n",
    "\n",
    "            # Plot the heatmap\n",
    "            g = sns.heatmap(B[:len(labels), :len(labels), count], cmap=\"OrRd\", linewidth=3, \n",
    "                            cbar=False, ax=axes[i, j], xticklabels=labels, yticklabels=labels)\n",
    "\n",
    "            g.tick_params(axis='both', which='major', labelsize=14)  # Adjust label font size\n",
    "            g.set_title(action_str, fontsize=20)\n",
    "            g.set_xlabel('Prev State', fontsize=16)\n",
    "            g.set_ylabel('Next State', fontsize=16)\n",
    "\n",
    "            # Rotate labels for better visibility\n",
    "            g.set_xticklabels(labels, rotation=45, ha=\"right\", fontsize=12)\n",
    "            g.set_yticklabels(labels, rotation=0, fontsize=12)\n",
    "            \n",
    "            count += 1\n",
    "\n",
    "    plt.subplots_adjust(left=0.2, bottom=0.2)  # Add margin space\n",
    "    plt.tight_layout()\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_B1_B2_plots(B1: np.ndarray, B2: np.ndarray, state_map: dict, actions: dict) -> np.ndarray:\n",
    "    \"\"\"Plot Transitions matrix showing the probability of a transition between two states given a certain action.\n",
    "       Common values in B1 and B2 (within a margin of 0.1) are set to 0 in the resulting B.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create B by zeroing out common values within margin 0.1\n",
    "    margin = 0.1\n",
    "    B = np.where(np.abs(B1 - B2) <= margin,0, B2)\n",
    "    \n",
    "    sorted_state_map = dict(sorted(state_map.items(), key=lambda item: item[1]['state']))\n",
    "    labels = [f\"{key} ({value['state']})\" for key, value in sorted_state_map.items()]\n",
    "\n",
    "    n_actions = len(actions)\n",
    "    l = int(np.ceil(np.sqrt(n_actions)))\n",
    "    L = int(np.ceil(n_actions / l))\n",
    "    \n",
    "    fig, axes = plt.subplots(L, l, figsize=(L*3 + max(10, 2.5*len(state_map)), \n",
    "                                             l*2 + max(10, 1.5*len(state_map))))\n",
    "    \n",
    "    axes = np.atleast_2d(axes)  # Ensure axes is always a 2D array\n",
    "    count = 0\n",
    "\n",
    "    for i in range(L):\n",
    "        for j in range(l):\n",
    "            if count >= n_actions:\n",
    "                fig.delaxes(axes[i][j])\n",
    "                continue\n",
    "            \n",
    "            if count not in actions:\n",
    "                continue\n",
    "\n",
    "            action_str = str(actions[count])  # Convert action name to string\n",
    "\n",
    "            # Plot the heatmap\n",
    "            g = sns.heatmap(B[:len(labels), :len(labels), count], cmap=\"OrRd\", linewidth=3, \n",
    "                            cbar=False, ax=axes[i, j], xticklabels=labels, yticklabels=labels)\n",
    "\n",
    "            g.tick_params(axis='both', which='major', labelsize=14)  # Adjust label font size\n",
    "            g.set_title(action_str, fontsize=20)\n",
    "            g.set_xlabel('Prev State', fontsize=16)\n",
    "            g.set_ylabel('Next State', fontsize=16)\n",
    "\n",
    "            # Rotate labels for better visibility\n",
    "            g.set_xticklabels(labels, rotation=45, ha=\"right\", fontsize=12)\n",
    "            g.set_yticklabels(labels, rotation=0, fontsize=12)\n",
    "            \n",
    "            count += 1\n",
    "\n",
    "    plt.subplots_adjust(left=0.2, bottom=0.2)  # Add margin space\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return fig, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_state_in_map(B: np.ndarray, state_mapping: dict,fig_ax=[None, None]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Plot states as dots positioned based on `state_mapping` keys.\n",
    "    Draw transitions between states based on transition probabilities in `B`.\n",
    "\n",
    "    Parameters:\n",
    "    - B (np.ndarray): Transition matrix of shape (num_states, num_states, num_actions).\n",
    "    - state_mapping (dict): Mapping of (x, y) positions to state properties.\n",
    "    - possible_actions (dict): Dictionary of action indices to angle ranges.\n",
    "    - pose_dist (float): Distance associated with each move action.\n",
    "\n",
    "    Returns:\n",
    "    - fig (matplotlib Figure): The generated figure.\n",
    "    \"\"\"\n",
    "    if fig_ax[0] is None:\n",
    "        fig, ax = plt.subplots(figsize=(25, 25))\n",
    "    else:\n",
    "        fig = fig_ax[0]\n",
    "        ax = fig_ax[1]\n",
    "\n",
    "\n",
    "    # Get unique observation values for color mapping\n",
    "    unique_obs = np.sort(list({v['ob'] for v in state_mapping.values()}))\n",
    "    color_map = get_cmap() #get_cmap('viridis', len(unique_obs))\n",
    "    ob_to_color = {ob: color_map.colors[i] for i, ob in enumerate(unique_obs)}\n",
    "\n",
    "    # Draw transitions between states\n",
    "    num_states, _, num_actions = B.shape\n",
    "    for prev_state in range(num_states):\n",
    "        for next_state in range(num_states):\n",
    "            for action in range(num_actions):\n",
    "                prob = B[next_state, prev_state, action]\n",
    "                if prob > 0.1:  # Only plot meaningful transitions\n",
    "                    # Find corresponding positions in `state_mapping`\n",
    "                    prev_pos = next((pos for pos, data in state_mapping.items() if data['state'] == prev_state), None)\n",
    "                    next_pos = next((pos for pos, data in state_mapping.items() if data['state'] == next_state), None)\n",
    "                    \n",
    "                    if prev_pos and next_pos:\n",
    "                        ax.plot([prev_pos[1], next_pos[1]], [prev_pos[0], next_pos[0]], \n",
    "                                'k-', linewidth=prob * 10)  # Scale linewidth with probability\n",
    "\n",
    "    # Plot states as dots\n",
    "    for (x, y), data in state_mapping.items():\n",
    "        state = data['state']\n",
    "        ob = data.get('ob', 0)\n",
    "        color = ob_to_color[ob]\n",
    "\n",
    "        ax.plot(y, x, 'o', color=color, markersize=20)  # Position state as (y, x)\n",
    "        ax.text(y - 0.05, x + 0.05, str(state), fontsize=25, ha='right', c='r')  # Label state number\n",
    "\n",
    "    # Formatting\n",
    "    # ax.invert_yaxis()\n",
    "    ax.invert_xaxis()\n",
    "    ax.set_aspect('equal')\n",
    "    ax.tick_params(axis='both', which='major', labelsize=26)\n",
    "    plt.ylabel('X', fontsize=30)\n",
    "    plt.xlabel('Y', fontsize=30)\n",
    "    plt.title('State Transitions', fontsize=35)\n",
    "    plt.grid(False)\n",
    "    \n",
    "    return fig\n",
    "def create_custom_cmap(custom_colors) -> colors.ListedColormap:\n",
    "    return colors.ListedColormap(custom_colors[:]) #,  alpha=None)\n",
    "\n",
    "def get_cmap() -> colors.ListedColormap:\n",
    "    custom_colors = (\n",
    "            np.array(\n",
    "                [\n",
    "                    [255, 255, 255],#white 1\n",
    "                    [255, 0, 0],#red 2\n",
    "                    [0, 255, 0], #green 3\n",
    "                    [50,50, 255], #bluish 4\n",
    "                    [112, 39, 195], #purple5\n",
    "                    [255, 255, 0], #yellow6\n",
    "                    [100, 100, 100], #grey7\n",
    "                    [115, 60, 60], #brown8\n",
    "                    [255, 0, 255], #flash pink9\n",
    "                    [80, 145,80], #kaki10\n",
    "                    [201,132,226], #pink11\n",
    "                    [75,182,220], #turquoise12\n",
    "                    [255,153,51], #orange13\n",
    "                    [255,204,229], #light pink14\n",
    "                    [153,153,0], #ugly kaki 15\n",
    "                    [229,255,204], #light green16\n",
    "                    [204,204,255],#light purple17\n",
    "                    [0, 153,153], #dark turquoise18\n",
    "                    [138, 108, 106], #light brown19\n",
    "                    [108, 115, 92],#ugly green20\n",
    "                    [149, 199, 152],#pale green21\n",
    "                    [89, 235, 210], #flashy light blue22\n",
    "                    [37, 105, 122], #dark blue23\n",
    "                    [22, 25, 92], #dark purple-blue24\n",
    "                    [131, 24, 219], #flashy purple25\n",
    "                    [109, 11, 120], #purple-pink26\n",
    "                    [196, 145, 191], #pale pink27\n",
    "                    [148, 89, 130], #dark pink28\n",
    "                    [201, 75, 119], #pink-red29\n",
    "                    [189, 89, 92], #light red30\n",
    "\n",
    "                ]\n",
    "            )\n",
    "            / 256\n",
    "        )\n",
    "\n",
    "    n_colors = len(custom_colors)\n",
    "    return create_custom_cmap(custom_colors[:n_colors])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mcts_tree(root_node):\n",
    "    \"\"\"Visualises the Monte Carlo Tree Search (MCTS) tree.\"\"\"\n",
    "    G = nx.DiGraph()  # Directed Graph\n",
    "    dico = {}\n",
    "    visited = set()  # To avoid infinite recursion\n",
    "\n",
    "    # Recursively extract tree structure\n",
    "    def add_nodes_edges(node, parent=None, action=None):\n",
    "        if node.id in visited:\n",
    "            if parent is not None:\n",
    "                G.add_edge(parent.id, node.id, action=int(action))\n",
    "            return  # Already added and traversed â€” skip further traversal\n",
    "\n",
    "        visited.add(node.id)\n",
    "\n",
    "        # Aggregate or update visit count\n",
    "        if node.id not in dico:\n",
    "            dico[node.id] = node.N\n",
    "        else:\n",
    "            dico[node.id] += node.N\n",
    "\n",
    "        # Label for display\n",
    "        node_label = f\"ID: {node.id}\\nN: {round(dico[node.id], 2)},\\nR: {round(node.state_reward, 2)}\"\n",
    "        G.add_node(node.id, label=node_label, reward=dico[node.id])\n",
    "\n",
    "        if parent is not None:\n",
    "            G.add_edge(parent.id, node.id, action=int(action))\n",
    "\n",
    "        if node.has_children_nodes():\n",
    "            for action, child_node in node.childs.items():\n",
    "                add_nodes_edges(child_node, node, action)\n",
    "\n",
    "    add_nodes_edges(root_node)\n",
    "\n",
    "    dico = sorted(dico.items(), key=lambda x: x[1])\n",
    "    logging.info(f\"max visits:{dico}, len dict:{len(dico)}\")\n",
    "\n",
    "    pos = nx.kamada_kawai_layout(G)\n",
    "    # Scale positions to increase spacing\n",
    "    pos = {k: (x * 1.5, y * 1.5) for k, (x, y) in pos.items()}\n",
    "\n",
    "    # Node colors based on reward\n",
    "    rewards = [G.nodes[n]['reward'] for n in G.nodes]\n",
    "    min_reward = min(rewards) if rewards else 0\n",
    "    max_reward = max(rewards) if rewards else 1\n",
    "    node_colors = [(r - min_reward) / (max_reward - min_reward + 1e-6) for r in rewards]\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    nx.draw(G, pos, with_labels=True, labels=nx.get_node_attributes(G, 'label'),\n",
    "            node_color=node_colors, cmap=plt.cm.cool, node_size=1500,\n",
    "            font_size=8, font_weight='bold', edgecolors=\"black\", alpha=0.9)\n",
    "\n",
    "    # Draw edge labels (actions)\n",
    "    edge_labels = nx.get_edge_attributes(G, 'action')\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=7, label_pos=0.7)\n",
    "\n",
    "    plt.title(\"Monte Carlo Tree Search (MCTS) Visualization\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from map_dm_nav.model.pymdp.agent import Agent\n",
    "from map_dm_nav.model.odometry import PoseOdometry\n",
    "from map_dm_nav.model.pymdp import utils\n",
    "from map_dm_nav.model.pymdp.control import get_expected_obs, get_expected_states, calc_states_info_gain, calc_expected_utility, calc_pA_info_gain, calc_pB_info_gain\n",
    "from map_dm_nav.model.pymdp.maths import softmax, spm_log_single\n",
    "from map_dm_nav.model.modules import *\n",
    "from map_dm_nav.model.pymdp.learning import update_obs_likelihood_dirichlet\n",
    "# from .pymdp.maths import spm_dot\n",
    "import math\n",
    "import copy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def pickle_load_model(store_path: str = None):\n",
    "    \"\"\"Loads a pickled model from the specified path.\"\"\"\n",
    "    store_path = Path(store_path)\n",
    "    if not store_path.exists():\n",
    "        logging.error(f\"Model file not found at: {store_path}\")\n",
    "        return None\n",
    "    try:\n",
    "        with open(store_path, 'rb') as f:\n",
    "            loaded_model = pickle.load(f)\n",
    "            logging.info(f\"Model successfully loaded from: {store_path}\")\n",
    "            return loaded_model\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to load model from {store_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Node Class ---\n",
    "class Node:\n",
    "    \"\"\"\n",
    "    Represents a node in the MCTS tree.\n",
    "    Stores state information, MCTS statistics, and tree structure links.\n",
    "    \"\"\"\n",
    "    def __init__(self, state_qs:np.ndarray, pose_id:int, parent:object=None, action_index:int=0, observation:np.ndarray=None, initial_reward:float=0.0, possible_actions=None):\n",
    "        self.pose_id = pose_id\n",
    "        self.id = pose_id  # Using pose_id as a unique identifier for the node\n",
    "\n",
    "        # State Representation\n",
    "        self.state_qs = state_qs  # Belief over states (e.g., particle filter weights)\n",
    "        self.observation = observation # Observation associated with reaching this state (qo_pi)\n",
    "\n",
    "        # MCTS Statistics\n",
    "        self.total_reward = 0 #initial_reward # Sum of rewards accumulated through this node (Formerly T)\n",
    "        self.N = 0 # Visit count\n",
    "\n",
    "        # Tree Structure\n",
    "        self.parent = parent # Reference to the parent node\n",
    "        self.childs = {} # Dictionary mapping action -> child Node\n",
    "        self.action_index = action_index # Action taken by the parent to reach this node\n",
    "\n",
    "        # Action Space\n",
    "        self.possible_actions = possible_actions # List of possible actions from this node's state (computed during expansion)\n",
    "        self.untried_actions = None # Actions not yet explored from this node\n",
    "\n",
    "        # Intrinsic Reward (EFE components calculated when node is evaluated)\n",
    "        self.state_reward = initial_reward # The immediate EFE/G calculated for reaching this state\n",
    "\n",
    "    def get_averaged_reward(self)->float:\n",
    "        \"\"\"Calculates the average reward accumulated through this node.\"\"\"\n",
    "        if self.N == 0:\n",
    "            return self.state_reward # Avoid division by zero for unvisited nodes\n",
    "        return self.total_reward / self.N\n",
    "\n",
    "    def get_ucb1_score(self, c_param:float=1.41,use_utility:bool=True,use_states_info_gain:bool=True)->float:\n",
    "        \"\"\"\n",
    "        Calculates the UCB1 score for this node.\n",
    "        Balances exploitation (average reward) and exploration (visit count).\n",
    "\n",
    "        UCB1 ensures that the search doesn't prematurely focus only on the initially best-looking option but also invests simulations in exploring other potentially promising, but less certain, branches. This leads to more robust and accurate value estimates for the actions at the root node over many simulations.\n",
    "        \"\"\"\n",
    "        if self.N == 0:\n",
    "            return float('inf') # Prioritize exploring unvisited nodes\n",
    "\n",
    "        if self.parent is None:\n",
    "             # Should not happen during selection if root is handled correctly, but added for safety\n",
    "             parent_visits = self.N\n",
    "        else:\n",
    "             parent_visits = self.parent.N\n",
    "\n",
    "        if parent_visits == 0: # Avoid log(0) or division by zero if parent somehow has 0 visits\n",
    "            parent_visits = 1\n",
    "\n",
    "        exploitation_term = self.get_averaged_reward()\n",
    "        exploration_term = c_param * math.sqrt(math.log(parent_visits) / self.N)\n",
    "\n",
    "        # logging.debug(f\"Node {self.id}: AvgReward={exploitation_term:.3f}, ExploitTerm={exploration_term:.3f}, ParentN={parent_visits}, SelfN={self.N}\")\n",
    "\n",
    "        # Add intrinsic state reward to bias selection towards immediately rewarding states\n",
    "        # Note: Depending on the scale of state_reward vs rollout_reward, this might need tuning.\n",
    "        reward = 0\n",
    "        if use_utility:\n",
    "            reward += exploitation_term\n",
    "        if use_states_info_gain:\n",
    "            reward += exploration_term\n",
    "        return reward #+ self.state_reward\n",
    "\n",
    "    def is_fully_expanded(self)->bool:\n",
    "        \"\"\"Checks if we verified possible actions from this node leading to a child node. This suppose we have No isolated node\"\"\"\n",
    "        return self.possible_actions is not None and len(self.childs) > 0\n",
    "\n",
    "    def has_children_nodes(self)->bool:\n",
    "        \"\"\"Checks if the node has any child nodes.\"\"\"\n",
    "        return len(self.childs) > 0\n",
    "    \n",
    "    def select_best_child_UCB(self, c_param:float=1.41,use_utility:bool=True, use_info_gain:bool=True,parent_list=[])->object:\n",
    "        \"\"\"Selects the child with the highest UCB1 score.\"\"\"\n",
    "        best_score = -float('inf')\n",
    "        best_child = None\n",
    "        scores = []\n",
    "        for action, child in self.childs.items():\n",
    "            score = child.get_ucb1_score(c_param,use_utility, use_info_gain)\n",
    "            # logging.info(f\"  Child {child.id} (Action {action}) UCB1: {score:.2f}\")\n",
    "            scores.append(score)\n",
    "            if score > best_score and child.id not in parent_list[1:]:\n",
    "                best_score = score\n",
    "                best_child = child\n",
    "\n",
    "        if best_child is None:\n",
    "            best_child_id = np.argmax(scores)\n",
    "            best_child = list(self.childs.values())[best_child_id]\n",
    "        #logging.debug(f\"Node {self.id}: Selected child {best_child.id if best_child else 'None'} with score {best_score:.2f}\")\n",
    "        return best_child\n",
    "    \n",
    "    def all_children_AIF(self)->list:\n",
    "        \"\"\"Selects the child with AIF.\"\"\"\n",
    "        all_averaged_efe = [c.get_averaged_reward() for c in self.childs.values()]\n",
    "        # q_pi, best_action_id = self.infer_policy_over_actions(all_averaged_efe, self.possible_actions)\n",
    "        # logging.debug(f\"  Child {child.id} (Action {action}) average_EFE: {score:.2f}\")    \n",
    "        #logging.debug(f\"Node {self.id}: Selected child {best_child.id if best_child else 'None'} with score {best_score:.2f}\")\n",
    "        return all_averaged_efe\n",
    "\n",
    "    def detach_parent(self)-> None:\n",
    "        \"\"\"Removes the reference to the parent node to allow garbage collection.\"\"\"\n",
    "        logging.debug(f\"Detaching parent from node {self.id}\")\n",
    "        del self.parent\n",
    "        self.parent = None\n",
    "\n",
    "# --- Model Interface Class ---\n",
    "class MCTS_Model_Interface:\n",
    "    \"\"\"\n",
    "    Acts as a wrapper or interface to the underlying Active Inference model.\n",
    "    Provides methods to query the model for transitions, observations, rewards, etc.\n",
    "    \"\"\"\n",
    "    def __init__(self, underlying_model:object):\n",
    "        self.model = underlying_model # The actual model object (e.g., Ours_V5_RW instance)\n",
    "        # Caches can be added here if needed for expensive model calls\n",
    "        # self.transition_cache = {}\n",
    "        # self.observation_cache = {}\n",
    "        # self.reward_cache = {}\n",
    "        logging.info(f\"MCTS_Model_Interface initialized with model type: {type(underlying_model)}\")\n",
    "\n",
    "    def get_possible_actions(self)->list:\n",
    "        \"\"\"Returns a list of all possible actions [action_id]\"\"\"\n",
    "        return list(self.model.get_possible_actions().keys())\n",
    "\n",
    "    def id_to_pose(self, pose_id:int)->list:\n",
    "        return self.model.PoseMemory.id_to_pose(pose_id)\n",
    "    \n",
    "    def get_next_node_pose_id(self, current_pose_id:int, action:int)->int:\n",
    "        \"\"\"Calculates the next pose ID resulting from taking an action.\"\"\"   \n",
    "        odom = self.model.PoseMemory.id_to_pose(current_pose_id)\n",
    "        next_pose = self.model.PoseMemory.pose_transition_from_action(action, odom=odom)\n",
    "        next_pose_id = self.model.PoseMemory.pose_to_id(next_pose, save_in_memory=False)\n",
    "        next_pose = self.model.PoseMemory.id_to_pose(next_pose_id)\n",
    "        pose_in_action_range = self.model.PoseMemory.pose_in_action_range(action, next_pose, odom= odom) #if we don't reach that pose with that action, we pass\n",
    "        \n",
    "        if not pose_in_action_range:\n",
    "            #logging.warning(f\"Action {action} from pose {current_pose_id} leads to unreachable pose {next_pose_id}. Invalid transition.\")\n",
    "            return -1 # Indicate invalid transition\n",
    "        #logging.info(f\"Action {action} from pose {odom}, {current_pose_id} leads to pose {next_pose}, {next_pose_id}. Invalid transition.\")\n",
    "        return next_pose_id\n",
    "\n",
    "    def get_next_state_belief(self, current_belief_qs:np.ndarray, action:int)->np.ndarray:\n",
    "        \"\"\"Predicts the next belief state (qs) given the current belief and action.\"\"\"\n",
    "        # This corresponds to the belief state transition model p(qs'|qs, a)\n",
    "        return self.model.get_next_state_given_action(qs=current_belief_qs, action=action)\n",
    "\n",
    "    def get_expected_observation(self, next_belief_qs:np.ndarray)->np.ndarray:\n",
    "        \"\"\"Calculates the expected observation (qo_pi) given a belief state.\"\"\"\n",
    "        # This corresponds to p(o|qs')\n",
    "        return self.model.get_expected_observation(next_belief_qs)\n",
    "\n",
    "    def calculate_expected_free_energy(self, next_belief_qs:np.ndarray, expected_observation_qo_pi:np.ndarray, current_qs:np.ndarray, action:int)->float:\n",
    "        \"\"\"\n",
    "        Calculates the Expected Free Energy (G) for a potential next state.\n",
    "        G = Utility + Information Gain\n",
    "        \"\"\"\n",
    "        G = 0.0\n",
    "        H = 0.0\n",
    "        logging.debug(f\"action:{action}, next_belief_qs: {str(next_belief_qs)}\")\n",
    "        if self.model.use_states_info_gain:\n",
    "            #the highest (>0), the more interesting\n",
    "            info_gain = self.model.infer_info_gain_term([next_belief_qs]) # Assuming takes a list\n",
    "            G += info_gain\n",
    "\n",
    "            logging.debug(f\"  Info Gain Term: {info_gain:.4f}\")\n",
    "        if self.model.use_utility:\n",
    "            #the lowest (<0), the more interesting\n",
    "            logging.debug(f\"  Utility Term exp ob: {str(expected_observation_qo_pi)}\")\n",
    "            utility = self.model.infer_utility_term(expected_observation_qo_pi)\n",
    "            G += utility \n",
    "            logging.debug(f\"  Utility Term: {utility:.4f}\")\n",
    "\n",
    "        if self.model.use_inductive_inference:\n",
    "           H -= infer_inductive_preference(self.model, current_qs, next_belief_qs)\n",
    "           logging.debug(f\" Inductive Inference: {H:.4f}\")\n",
    "        if self.model.use_param_info_gain: #not good in asociation with the other terms\n",
    "            #the highest (>0), the less interesting\n",
    "            param_info_gain = self.model.infer_param_info_gain([next_belief_qs],expected_observation_qo_pi, current_qs, action)[0]/100\n",
    "            G -= param_info_gain\n",
    "            logging.debug(f\"  Param info gain Term: {param_info_gain:.4f}\")\n",
    "\n",
    "        logging.debug(f\"  Calculated G: {G:.4f}\")\n",
    "        return G, H\n",
    "\n",
    "    def infer_policy_over_actions(self, action_values:list, available_actions:list, action_selection:str=None, alpha:float=None):\n",
    "        \"\"\"Infers a probability distribution (policy) over actions based on their values (e.g., EFE).\"\"\"\n",
    "        # This likely involves a softmax function as in the original code's example\n",
    "        q_pi, best_action_id = self.model.infer_best_action_given_actions(action_values, available_actions,action_selection, alpha)\n",
    "        return q_pi, best_action_id\n",
    "\n",
    "    def get_utility_term(self):\n",
    "        return self.model.use_utility\n",
    "    def get_use_states_info_gain_term(self):\n",
    "        return self.model.use_states_info_gain\n",
    "# --- MCTS Algorithm Class ---\n",
    "class MCTS:\n",
    "    \"\"\"\n",
    "    Implements the Monte Carlo Tree Search algorithm using an Active Inference model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, AIF_model:object, c_param:float=1.41, num_simulation:int=25, max_rollout_depth:int=10):\n",
    "        self.model_interface = MCTS_Model_Interface(AIF_model)\n",
    "        self.c_param = c_param # Exploration parameter for UCB1\n",
    "        self.num_simulation  = num_simulation # Number of MCTS simulations per planning step\n",
    "        self.max_rollout_depth = max_rollout_depth # Maximum depth for the simulation (rollout) phase\n",
    "        logging.info(f\"MCTS initialized with exploration parameter c={c_param}, num_simus={num_simulation}, max_depth={max_rollout_depth}, policy_alpha={AIF_model.alpha},  action_selection={AIF_model.action_selection}\")\n",
    "\n",
    "    def start_mcts(self,state_qs:np.ndarray, pose_id:int, observation:np.ndarray, next_possible_actions:list= None, num_steps:int=1, logging=None, plot=False)-> list:\n",
    "        current_node = Node(state_qs=state_qs,\n",
    "                pose_id=pose_id,\n",
    "                parent=None,\n",
    "                action_index=None,\n",
    "                observation=observation, \n",
    "                possible_actions=next_possible_actions)\n",
    "        \n",
    "        best_actions = []\n",
    "        data = {\"qs\": state_qs[0],\n",
    "            \"qpi\": [],\n",
    "            \"efe\": [],\n",
    "            \"info_gain\": [],\n",
    "            \"utility\": [],\n",
    "            #\"bayesian_surprise\": utils.bayesian_surprise(posterior[0].copy(), prior),\n",
    "            }\n",
    "        for i in range(num_steps):\n",
    "            best_action, data = self.plan(current_node, self.num_simulation, self.max_rollout_depth, data, logging=logging)\n",
    "            best_actions.append(best_action)\n",
    "            if num_steps>1 and best_action in current_node.childs:\n",
    "                next_node = current_node.childs[best_action]\n",
    "                if logging:\n",
    "                    logging.info(f\"MCTS:Executing action {best_action} -> Transitioning to Node {next_node.id}\")\n",
    "\n",
    "                # IMPORTANT: Detach the chosen next state from its parent (the previous state).\n",
    "                # This makes the chosen next state the new root for the *next* planning step\n",
    "                # and allows the old parts of the tree to be garbage collected.\n",
    "                next_node.detach_parent()\n",
    "                current_node = next_node # Update the current state\n",
    "        if plot:\n",
    "            plot_node = copy.deepcopy(current_node)\n",
    "            data['plot_MCTS_tree'] = plot_node\n",
    "        if logging:\n",
    "            logging.info(f\"MCTS:Executing actions {best_actions} -> Transitioning up to Node {current_node.childs[best_action].id}\")\n",
    "           \n",
    "        return best_actions, data\n",
    "\n",
    "    def _select_node(self, root_node:object, logging=None)->object:\n",
    "        \"\"\"Phase 1: Selection - Traverse the tree using UCB1 until a leaf node is reached.\"\"\"\n",
    "        current = root_node\n",
    "        self.parent_list = []\n",
    "        # logging.debug(f\"--- Selection Phase Start (Root: {root_node.id}) ---\")\n",
    "        while current.is_fully_expanded():\n",
    "            if logging:\n",
    "                logging.debug(f\"  Selected Node {current.id}\")\n",
    "            # logging.debug(f\"Selecting from Node {current.id} (N={current.N}, TR={current.total_reward:.3f})\")\n",
    "            #USING UCB\n",
    "            #self.parent_list.extend([child.id for child in current.childs.values()])\n",
    "            self.parent_list.append(current.id)\n",
    "            next = current.select_best_child_UCB(self.c_param, self.model_interface.get_utility_term(), self.model_interface.get_use_states_info_gain_term, self.parent_list)\n",
    "            \n",
    "            if next is not None:\n",
    "                current = next\n",
    "            else:\n",
    "                break\n",
    "            #safety to avoid loopings\n",
    "            counting_occurences = {x: self.parent_list.count(x) for x in set(self.parent_list)}\n",
    "            if any(x > 2 for x in counting_occurences.values()):\n",
    "                break\n",
    "            #USING AIF\n",
    "            # children_G = current.all_children_AIF()\n",
    "            # q_pi, best_action = self.model_interface.infer_policy_over_actions(children_G, current.possible_actions, action_selection='stochastic', alpha=1.0)\n",
    "            # current = current.childs[best_action]\n",
    "        if logging:\n",
    "            logging.info(f\"--- Selection Phase End (Selected Node: {current.id}) ---\")\n",
    "        self.parent_list.append(current.id)\n",
    "        return current\n",
    "\n",
    "    def _expand_node_in_all_possible_direction(self, node:object)->object:\n",
    "        \"\"\"Phase 2: Expansion - Add a new child node for an untried action.\"\"\"\n",
    "        \n",
    "        if node.possible_actions is None :\n",
    "            node.possible_actions =[]\n",
    "            all_possible_actions = self.model_interface.get_possible_actions()\n",
    "        else:\n",
    "            all_possible_actions = node.possible_actions\n",
    "        node.childs = {}\n",
    "            \n",
    "        #we save as the current node child each new node created taking an action from current pose \n",
    "        for action in all_possible_actions:\n",
    "            next_pose_id = self.model_interface.get_next_node_pose_id(node.pose_id, action)\n",
    "            #=== check if new  (redundant)===#\n",
    "            if action not in node.possible_actions:\n",
    "                if next_pose_id < 0 or next_pose_id in self.parent_list[:-1] : #no known or next pose looping back in path\n",
    "                    continue\n",
    "                node.possible_actions.append(action)\n",
    "        \n",
    "            #=== action leading to a node, saving believed qs and qo ===#\n",
    "            # print('node.state_qs', node.state_qs[0].round(4), action)\n",
    "            next_state_qs = self.model_interface.get_next_state_belief(node.state_qs, action=action)[0]\n",
    "            # print('next_state_qs', next_state_qs[0][0].round(3))\n",
    "            qo_pi = self.model_interface.get_expected_observation(next_state_qs)\n",
    "            #python should erase unreferenced classes. But let's systematise it\n",
    "            if action in node.childs:\n",
    "                del node.childs[action]\n",
    "            # Calculate the immediate reward (Expected Free Energy) for this transition\n",
    "            # Note: This G is associated with *reaching* the new state.\n",
    "            child_reward_G, child_H = self.model_interface.calculate_expected_free_energy(next_state_qs, qo_pi, node.state_qs, action)\n",
    "            child_reward = child_reward_G+ child_H \n",
    "            if next_pose_id in self.tree_table:\n",
    "                child_node = self.tree_table[next_pose_id]\n",
    "                if child_node.state_reward < child_reward:\n",
    "                    child_node.state_reward = child_reward\n",
    "            else:\n",
    "                # Create the new child node\n",
    "                child_node = Node(\n",
    "                    state_qs=next_state_qs,\n",
    "                    pose_id=next_pose_id,\n",
    "                    parent=node,\n",
    "                    action_index=action,\n",
    "                    observation=qo_pi,\n",
    "                    initial_reward= child_reward \n",
    "                    # Rollout will determine total_reward\n",
    "                    # possible_actions will be determined when the child is expanded later\n",
    "                )\n",
    "\n",
    "                self.tree_table[child_node.id] = child_node\n",
    "\n",
    "                #To get a headstart (not necessary)\n",
    "                # child_node.N +=1\n",
    "                # child_node.total_reward = child_node.state_reward \n",
    "                # parent = child_node\n",
    "                # while parent.parent:\n",
    "                #     parent = parent.parent\n",
    "                #     parent.N += 1\n",
    "                #     parent.total_reward = parent.total_reward + child_reward_G\n",
    "\n",
    "            node.childs[action] = child_node\n",
    "            logging.info(f\"from node {node.id} -> Child Node {child_node.id}, expanding with action {action}(Initial full={child_node.state_reward:.3f}, G={child_reward_G:.3f} H={child_H:.3f})\")\n",
    "            # logging.debug(f\"--- Expansion Phase End (Expanded Node: {child_node.id}) ---\")\n",
    "        return node # Return the newly expanded node\n",
    "\n",
    "\n",
    "    # def _rollout(self, start_node:object, max_depth:int)->float:\n",
    "        \"\"\"\n",
    "        Phase 3: Simulation (Rollout) - Simulate a trajectory from the start_node\n",
    "        using a default policy (e.g., random actions) and return the cumulative reward (G).\n",
    "        \"\"\"\n",
    "        logging.debug(f\"--- Rollout Phase Start (Node: {start_node.id}, Max Depth: {max_depth}) ---\")\n",
    "        \n",
    "        cumulative_G = 0.0\n",
    "        depth = 0\n",
    "\n",
    "        current_node = start_node\n",
    "        while depth < max_depth:\n",
    "            # 1. Check possible actions from the *current simulated pose*\n",
    "            if not current_node.is_fully_expanded() or len(current_node.possible_actions) == 0:\n",
    "                #current_node = self._expand_node_in_all_possible_direction(current_node)\n",
    "                # logging.debug(f\"  Rollout Depth {depth}: No actions possible from pose {current_sim_pose_id}. Stopping.\")\n",
    "                break # Dead end in simulation\n",
    "\n",
    "            # 2. Choose an action using the default policy (random)\n",
    "            action = random.choice(current_node.possible_actions)\n",
    "\n",
    "            child = current_node.childs[action]\n",
    "            # 3. Simulate the transition (expected state and observation)\n",
    "            # next_sim_qs = child.state_qs\n",
    "            # sim_qo_pi = child.observation\n",
    "\n",
    "            # 4. Calculate reward (G) for this simulated step\n",
    "            step_G = child.state_reward\n",
    "           \n",
    "            cumulative_G += step_G\n",
    "            logging.info(f\"  Rollout Depth {depth}: Action {action}, Next node{child.id}, StepG={step_G:.3f}, CumulG={cumulative_G:.3f}\")\n",
    "\n",
    "            # 5. Update simulated state\n",
    "            current_node = child\n",
    "            depth += 1\n",
    "\n",
    "        # logging.debug(f\"--- Rollout Phase End (Node: {start_node.id}, Total Rollout G: {cumulative_G:.3f}) ---\")\n",
    "        return cumulative_G\n",
    "\n",
    "    def _rollout(self, start_node:object, max_depth:int)->float:\n",
    "        \"\"\"\n",
    "        Phase 3: Simulation (Rollout) - Simulate a trajectory from the start_node\n",
    "        using a default policy (e.g., random actions) and return the cumulative reward (G).\n",
    "        \"\"\"\n",
    "        # logging.debug(f\"--- Rollout Phase Start (Node: {start_node.id}, Max Depth: {max_depth}) ---\")\n",
    "        current_sim_qs = start_node.state_qs\n",
    "        current_sim_pose_id = start_node.pose_id\n",
    "        cumulative_G = 0.0\n",
    "        depth = 1\n",
    "\n",
    "        current_node = start_node\n",
    "\n",
    "        while depth < max_depth:\n",
    "            # 1. Get possible actions from the *current simulated pose*\n",
    "            if current_node and current_node.is_fully_expanded():\n",
    "                all_possible_actions = current_node.possible_actions\n",
    "            else:\n",
    "                all_possible_actions = self.model_interface.get_possible_actions()\n",
    "            \n",
    "            if len(all_possible_actions)==0:\n",
    "                # logging.debug(f\"  Rollout Depth {depth}: No actions possible from pose {current_sim_pose_id}. Stopping.\")\n",
    "                break # Dead end in simulation\n",
    "\n",
    "            # 2. Choose an action using the default policy (random)\n",
    "            action = random.choice(all_possible_actions)\n",
    "\n",
    "            # 3. Simulate the transition\n",
    "            next_sim_pose_id = self.model_interface.get_next_node_pose_id(current_sim_pose_id, action)\n",
    "            if next_sim_pose_id < 0:\n",
    "                 # logging.debug(f\"  Rollout Depth {depth}: Action {action} from pose {current_sim_pose_id} leads to invalid state. Stopping.\")\n",
    "                 break # Invalid move in simulation\n",
    "\n",
    "            next_sim_qs = self.model_interface.get_next_state_belief(current_sim_qs, action)[0]\n",
    "            sim_qo_pi = self.model_interface.get_expected_observation(next_sim_qs)\n",
    "\n",
    "            # 4. Calculate reward (G) for this simulated step\n",
    "            step_G, step_H = self.model_interface.calculate_expected_free_energy(next_sim_qs, sim_qo_pi, current_sim_qs, action)\n",
    "            cumulative_G += step_G + step_H\n",
    "            logging.debug(f\"  Rollout Depth {depth}: Action {action}, NextPose {next_sim_pose_id}, StepG={step_G:.3f}, StepH={step_H:.3f}, CumulG={cumulative_G:.3f}\")\n",
    "\n",
    "            # 5. Update simulated state\n",
    "            current_sim_qs = next_sim_qs\n",
    "            current_sim_pose_id = next_sim_pose_id\n",
    "            depth += 1\n",
    "\n",
    "            # 6. If a node exist for that action, retrieve it to get appropriate next actions\n",
    "            if current_node and current_node.has_children_nodes():\n",
    "                current_node = current_node.childs.get(action,None)\n",
    "            else:\n",
    "                current_node = None\n",
    "\n",
    "        # logging.debug(f\"--- Rollout Phase End (Node: {start_node.id}, Total Rollout G: {cumulative_G:.3f}) ---\")\n",
    "        return cumulative_G / depth\n",
    "    \n",
    "\n",
    "    def _minimal_rollout(self, start_node:object,max_depth:int)->float:\n",
    "        \"\"\"\n",
    "        Phase 3: Simulation (Rollout) - Simulate a trajectory from the start_node\n",
    "        using a default policy (e.g., random actions) and return the cumulative reward (G).\n",
    "        \"\"\"\n",
    "        # logging.debug(f\"--- Rollout Phase Start (Node: {start_node.id}, Max Depth: {max_depth}) ---\")\n",
    "        current_sim_qs = start_node.state_qs\n",
    "        current_sim_pose_id = start_node.pose_id\n",
    "        current_node = start_node\n",
    "        best_state_reward = -1000\n",
    "\n",
    "        #for depth in range(max_depth):\n",
    "        # 1. Get possible actions from the *current simulated pose*\n",
    "        if current_node and current_node.is_fully_expanded():\n",
    "            all_possible_actions = current_node.possible_actions\n",
    "        else:\n",
    "            all_possible_actions = self.model_interface.get_possible_actions()\n",
    "        \n",
    "        if len(all_possible_actions)==0:\n",
    "            # logging.debug(f\"  Rollout Depth {depth}: No actions possible from pose {current_sim_pose_id}. Stopping.\")\n",
    "            return 0 # Dead end in simulation\n",
    "        # 2. Review ALL the actions\n",
    "        for action in all_possible_actions:\n",
    "                # 3. Simulate the transition\n",
    "                next_sim_pose_id = self.model_interface.get_next_node_pose_id(current_sim_pose_id, action)\n",
    "                if next_sim_pose_id < 0:\n",
    "                        # logging.debug(f\"  Rollout Depth {depth}: Action {action} from pose {current_sim_pose_id} leads to invalid state. Stopping.\")\n",
    "                        continue # Invalid move in simulation\n",
    "\n",
    "                next_sim_qs = self.model_interface.get_next_state_belief(current_sim_qs, action)[0]\n",
    "                sim_qo_pi = self.model_interface.get_expected_observation(next_sim_qs)\n",
    "\n",
    "                # 4. Calculate reward (G) for this simulated step\n",
    "                step_G, step_H = self.model_interface.calculate_expected_free_energy(next_sim_qs, sim_qo_pi, current_sim_qs, action)\n",
    "                step_reward = step_G + step_H\n",
    "                if step_reward > best_state_reward:\n",
    "                    best_state_reward = step_reward\n",
    "                logging.debug(f\"  Rollout node {start_node.id}: Action {action}, NextPose {next_sim_pose_id}, step_reward={step_reward:.3f}, StepG={step_G:.3f}, StepH={step_H:.3f}\")\n",
    "\n",
    "\n",
    "                # 6. If a node exist for that action, retrieve it to get appropriate next actions\n",
    "                if current_node and current_node.has_children_nodes():\n",
    "                    current_node = current_node.childs.get(action,None)\n",
    "                else:\n",
    "                    current_node = None\n",
    "        #SECURITY (should be useless)\n",
    "        if best_state_reward == -1000:\n",
    "            best_state_reward = 0\n",
    "        # logging.debug(f\"--- Rollout Phase End (Node: {start_node.id}, Total Rollout G: {cumulative_G:.3f}) ---\")\n",
    "        return best_state_reward\n",
    "    \n",
    "    def _backpropagate(self, node:object, reward:float)-> None:\n",
    "        \"\"\"Phase 4: Backpropagation - Update visit counts and total rewards up the tree.\"\"\"\n",
    "        # logging.debug(f\"--- Backpropagation Start (Node: {node.id}, Reward: {reward:.3f}) ---\")\n",
    "        current = node\n",
    "        while current is not None:\n",
    "            current.N += 1\n",
    "            current.total_reward += reward\n",
    "            # logging.debug(f\"  Updating Node {current.id}: N={current.N}, TR={current.total_reward:.3f}\")\n",
    "            current = current.parent\n",
    "        # logging.debug(f\"--- Backpropagation End ---\")\n",
    "\n",
    "    def run_simulation(self, root_node, max_rollout_depth, logging=None):\n",
    "        \"\"\"Runs a single iteration of the MCTS algorithm (Select, Expand, Simulate, Backpropagate).\"\"\"\n",
    "        # logging.debug(f\"=== Starting MCTS Simulation ===\")\n",
    "\n",
    "        # Phase 1: Selection\n",
    "        selected_node = self._select_node(root_node, logging=logging)\n",
    "\n",
    "        # Phase 2: Expansion\n",
    "        # If the selected node is not terminal and not fully expanded, expand it.\n",
    "        # Check if the node is terminal (add domain-specific logic if needed, e.g., goal reached)\n",
    "        # is_terminal = False # Placeholder - add condition if applicable\n",
    "        # if not is_terminal:\n",
    "        if not selected_node.is_fully_expanded():\n",
    "            selected_node = self._expand_node_in_all_possible_direction(selected_node)\n",
    "        else:\n",
    "            # If fully expanded, the rollout starts from the selected node itself\n",
    "            # This can happen if selection leads to an already expanded node\n",
    "            logging.debug(f\"Selected node {selected_node.id} is fully expanded, starting rollout from here.\")\n",
    "            #pass\n",
    "\n",
    "\n",
    "        # Phase 3: Simulation (Rollout)\n",
    "        # Start rollout from the newly expanded node (or the selected node if expansion wasn't possible/needed)\n",
    "        reward = self._minimal_rollout(selected_node,max_rollout_depth)\n",
    "        #reward = self._rollout(selected_node, max_rollout_depth)\n",
    "        # Add the immediate state reward (G) of the node where the rollout started\n",
    "        # This connects the immediate EFE gain with the future expected gains from the rollout\n",
    "        reward += selected_node.state_reward\n",
    "\n",
    "        # Phase 4: Backpropagation\n",
    "        self._backpropagate(selected_node, reward)\n",
    "    \n",
    "        children_info = [('a', a, 'child id',c.id,'N',c.N,'T', round(c.total_reward,2),'efe_av', round(c.get_averaged_reward(),2)) for a,c in root_node.childs.items()]\n",
    "        logging.info(f\"Root node children stats: {children_info}\")\n",
    "        # logging.debug(f\"=== Finished MCTS Simulation ===\")\n",
    "\n",
    "    def plan(self, root_node:object, num_simulations:int, max_rollout_depth:int, data:dict=None, logging=None)-> int: #dict\n",
    "        \"\"\"Runs the MCTS planning process for a given number of simulations.\"\"\"\n",
    "        if logging:\n",
    "            logging.info(f\"Starting MCTS planning from root node {root_node.id} for {num_simulations} simulations.\")\n",
    "\n",
    "        self.tree_table = {}\n",
    "        for i in range(num_simulations):\n",
    "            # print()\n",
    "            if logging:\n",
    "                logging.info(f\"--- Simulation {i+1}/{num_simulations} ---\")\n",
    "            self.run_simulation(root_node, max_rollout_depth, logging)\n",
    "\n",
    "        # After simulations, determine the best action from the root\n",
    "        best_action, q_pi_actions_values = self.get_best_action(root_node)\n",
    "        data['qpi'].append(q_pi_actions_values[0])\n",
    "        data['efe'].append(q_pi_actions_values[1])\n",
    "\n",
    "        return best_action, data\n",
    "\n",
    "    def get_best_action(self, root_node:object)->int:\n",
    "        \"\"\"Selects the best action from the root node after simulations.\"\"\"\n",
    "        if not root_node.childs:\n",
    "            logging.warning(\"Root node has no children after simulations. Cannot determine best action.\")\n",
    "            return None # Or a default action\n",
    "\n",
    "        # Option 1: Choose the most visited child (robust)\n",
    "        # best_action = max(root_node.childs.keys(), key=lambda action: root_node.childs[action].N)\n",
    "\n",
    "        # Option 2: Choose the child with the highest average reward (can be greedy)\n",
    "        # best_action = max(root_node.childs.keys(), key=lambda action: root_node.childs[action].get_averaged_reward())\n",
    "\n",
    "        # Option 3: Use the model's policy inference based on average rewards (AIF scheme)\n",
    "        action_values = []\n",
    "        available_actions = []\n",
    "        child_info = []\n",
    "        for action, child in root_node.childs.items():\n",
    "            avg_reward = child.get_averaged_reward()\n",
    "            if child.id < 0 : #We don't care about uncharted state, thus we artificially decrease their attractiveness\n",
    "                avg_reward = 0\n",
    "            action_values.append(avg_reward)\n",
    "            available_actions.append(action)\n",
    "            child_info.append(f\"Action {action}: AvgR={avg_reward:.3f}, N={child.N}\")\n",
    "        logging.info(f\"Root node children stats: {'; '.join(child_info)}\")\n",
    "\n",
    "        if len(available_actions)==0:\n",
    "             logging.warning(\"No valid actions available from root node children.\")\n",
    "             return None, []\n",
    "\n",
    "        q_pi, best_action_id = self.model_interface.infer_policy_over_actions(action_values, available_actions)\n",
    "        logging.info(f\"action average G: {action_values}\")\n",
    "        logging.info(f\"softmax policies: {q_pi.round(2)}\")\n",
    "        logging.info(f\"Selected best action based on policy: {best_action_id}\")\n",
    "        \n",
    "        # Ensure the selected action is actually one of the children\n",
    "        if best_action_id not in root_node.childs:\n",
    "             logging.error(f\"Policy selected action {best_action_id} which is not a child of the root node. Available: {list(root_node.childs.keys())}. Falling back to most visited.\")\n",
    "             # Fallback to most visited\n",
    "             if available_actions:\n",
    "                best_action_id = max(root_node.childs.keys(), key=lambda action: root_node.childs.get(action).N if root_node.childs.get(action) else -1)\n",
    "             else:\n",
    "                 return None, [] # No valid children\n",
    "\n",
    "        full_action_values = [action_values[available_actions.index(a)] if a in available_actions else 0 for a in self.model_interface.get_possible_actions()]\n",
    "        full_q_pi = [q_pi[available_actions.index(a)] if a in available_actions else 0 for a in self.model_interface.get_possible_actions()]\n",
    "        return best_action_id, (full_q_pi, full_action_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ours_V5_RW(Agent):\n",
    "    #====== NECESSARY TO SETUP MODEL ======#\n",
    "    def __init__(self, num_obs=2, num_states=2, dim=2, observations=[0,(0,0)], lookahead_policy=4, \\\n",
    "                 learning_rate_pB=3.0, n_actions= 6,\\\n",
    "                 influence_radius:float=0.5, robot_dim:float=0.25, \\\n",
    "                   lookahead_node_creation=3) -> None:\n",
    "        self.agent_state_mapping = {} #testing purposes\n",
    "        self.influence_radius = influence_radius\n",
    "        self.robot_dim = robot_dim \n",
    "        self.possible_actions = self.generate_actions(n_actions) \n",
    "        self.PoseMemory = PoseOdometry(self.possible_actions, influence_radius, robot_dim)\n",
    "\n",
    "        self.preferred_ob = [-1,-1]\n",
    "\n",
    "\n",
    "        self.lookahead_node_creation = lookahead_node_creation\n",
    "        observations, agent_params = self.create_agent_params(num_obs=num_obs, num_states=num_states, observations=observations, \\\n",
    "                            learning_rate_pB=learning_rate_pB, dim=dim, lookahead_policy=lookahead_policy)\n",
    "        super().__init__(**agent_params)\n",
    "        self.initialisation(observations=observations)\n",
    "    \n",
    "    def create_agent_params(self,num_obs:int=2, num_states:int=2, observations:list=[0,(0,0)], \n",
    "                    learning_rate_pB:float=3.0, dim:int=2, lookahead_policy:int=4):\n",
    "        ob = observations[0]\n",
    "        p_idx = -1\n",
    "        if dim > 1:\n",
    "            #start pose in map\n",
    "            if len(observations) < 2:\n",
    "                observations.append([0.0,0.0])\n",
    "            self.PoseMemory.reset_odom(observations[1])\n",
    "            p_idx = self.PoseMemory.pose_to_id()\n",
    "            observations[1] = p_idx\n",
    "            \n",
    "        else:\n",
    "            p_idx = self.PoseMemory.pose_to_id()\n",
    "        \n",
    "        self.current_pose = self.PoseMemory.get_odom(as_tuple=True)\n",
    "        #INITIALISE AGENT PARAMS\n",
    "        B_agent = create_B_matrix(num_states,len(self.possible_actions))\n",
    "        if 'STAY' in self.possible_actions and self.set_stationary_B:\n",
    "            B_agent = set_stationary(B_agent,self.possible_actions['STAY'])\n",
    "        pB = utils.to_obj_array(B_agent)\n",
    "\n",
    "        obs_dim = [np.max([num_obs, ob + 1])] + ([np.max([num_obs, p_idx + 1])] if dim > 1 else [])\n",
    "        A_agent = create_A_matrix(obs_dim,[num_states]*dim,dim)\n",
    "        pA = utils.dirichlet_like(A_agent, scale = 1)\n",
    "\n",
    "        return observations, {\n",
    "            'A': A_agent,\n",
    "            'B': B_agent,\n",
    "            'pA': pA,\n",
    "            'pB': pB,\n",
    "            'policy_len': lookahead_policy,\n",
    "            'inference_horizon': lookahead_policy,\n",
    "            'lr_pB': learning_rate_pB,\n",
    "            'lr_pA': 5,\n",
    "            'save_belief_hist': True,\n",
    "            'action_selection': \"stochastic\", \n",
    "            'use_param_info_gain': False\n",
    "        }\n",
    "\n",
    "    def initialisation(self,observations:list=[0,[0,0]]):\n",
    "        \"\"\"\n",
    "        Initialises the agent with the first observation and ensures all parameters \n",
    "        are suitable for continuous navigation.\n",
    "\n",
    "        Parameters:\n",
    "            observations (list, optional): Initial observation. Defaults to [0, [0, 0]].\n",
    "            linear_policies (bool, optional): \n",
    "                - If **False**: Explores all combinations of actions (exponential complexity: `n_action^policy_len` with `policy_len == lookahead`).\n",
    "                - If **True**: Generates a linear path reaching a **lookahead distance** or **num steps**.\n",
    "                - The path remains linear if no \"STAY\" actions are included.\n",
    "                - If \"STAY\" actions exist, the path follows a polynomial pattern.\n",
    "                - \"STAY\" actions are irregular and appear only at the end of a policy.\n",
    "            E (optional): Additional environment-specific parameters (default: None).\n",
    "\n",
    "        Note:\n",
    "            - `linear_policies=True` is optimized for cases where `num_factor == 1` \n",
    "            and `len(num_control) == 1`.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "      \n",
    "        self.reset(start_pose=self.PoseMemory.get_poses_from_memory()[0])\n",
    "        if self.edge_handling_params[\"use_BMA\"] and hasattr(self, \"q_pi_hist\"): #This is not compatible with our way of moving\n",
    "            del self.q_pi_hist\n",
    "            \n",
    "        self.inference_params = {'num_iter': 3, 'dF': 1.0, 'dF_tol': 0.001}\n",
    "        #Not necessary, but cleaner\n",
    "        for i in range(len(self.A)):\n",
    "            self.A[i][:,:] = 0.01 #reset A for cleaner plot and more fair state inference\n",
    "        self.update_A_with_data(observations,0)\n",
    "        self.update_agent_state_mapping(self.current_pose, observations, 0)\n",
    "        self.infer_states(observation = observations, partial_ob=None)\n",
    "        if 'STAY' in self.possible_actions.values():\n",
    "            stay_action = [key for key, value in self.possible_actions.items() if value == 'STAY'][0]\n",
    "            self.B[0] = set_stationary(self.B[0], stay_action)\n",
    "        return \n",
    "\n",
    "    def reset(self, init_qs:np.ndarray=None, start_pose:tuple=None):\n",
    "        \"\"\"\n",
    "        Resets the agent's posterior beliefs about hidden states to a uniform distribution \n",
    "        and resets the simulation time to the initial timestep.\n",
    "\n",
    "        This function initializes or resets key agent parameters, including past actions, \n",
    "        observations, and beliefs, ensuring proper inference and navigation behavior.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        init_qs : numpy.ndarray, optional\n",
    "            A predefined posterior over hidden states. If provided, the agent's beliefs \n",
    "            will be initialized using `init_qs` instead of a uniform prior.\n",
    "        \n",
    "        start_pose : tuple, optional\n",
    "            The initial position (pose) of the agent. If provided, it sets `self.current_pose`.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        qs : numpy.ndarray\n",
    "            The initialized posterior over hidden states. The structure of `qs` depends on \n",
    "            the inference algorithm selected:\n",
    "\n",
    "            - If `self.inference_algo == 'VANILLA'`:  \n",
    "            `qs` is a simple uniform distribution over hidden states.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        - If `self.edge_handling_params['policy_sep_prior']` is enabled, \n",
    "        the latest beliefs are initialized separately for each policy.\n",
    "        - If `init_qs` is provided, it is directly assigned to `self.qs`, \n",
    "        bypassing uniform initialization.\n",
    "        \"\"\"\n",
    "\n",
    "        self.curr_timestep = 0\n",
    "        self.action = None\n",
    "        self.prev_actions = None\n",
    "        self.prev_obs = []\n",
    "        self.qs_step = 0\n",
    "     \n",
    "        self.current_pose = start_pose\n",
    "        if init_qs is None:\n",
    "            \n",
    "            self.D = self._construct_D_prior()\n",
    "           \n",
    "            if hasattr(self, \"q_pi_hist\"):\n",
    "                self.q_pi_hist = []\n",
    "\n",
    "            if hasattr(self, \"qs_hist\"):\n",
    "                self.qs_hist = []\n",
    "            \n",
    "            if self.inference_algo == 'VANILLA':\n",
    "                self.qs = utils.obj_array_uniform(self.num_states)\n",
    "            else:\n",
    "                print('MMP INFERENCE NOT IMPLEMENTED')\n",
    "        \n",
    "        else:\n",
    "            self.qs = init_qs\n",
    "\n",
    "        return self.qs\n",
    "    \n",
    "    def generate_actions(self,n_actions:int)->dict:\n",
    "        \"\"\"\n",
    "        Divides the 360-degree orientation into discrete action zones and \n",
    "        returns a dictionary mapping each action to its corresponding range.\n",
    "\n",
    "        Parameters:\n",
    "            n_actions (int): The number of discrete actions to divide the \n",
    "                            360-degree space into.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary where keys are action indices (int), and values \n",
    "                are lists containing the start and end zone (in degrees):\n",
    "                `{action_index: [start_zone, end_zone]}`.\n",
    "\n",
    "        Note:\n",
    "            - The action zones are evenly spaced across 360 degrees.\n",
    "            - The function include a \"STAY\" action.\n",
    "            - The start and end values are rounded to the nearest integer.\n",
    "        \"\"\"\n",
    "        stay = False\n",
    "        if n_actions% 2 != 0:\n",
    "            n_actions = n_actions-1\n",
    "            stay = True\n",
    "        zone_range_deg = round(360/n_actions,1)\n",
    "        n_actions_keys = np.arange(0, n_actions, 1)\n",
    "        zone_spacing_deg = np.arange(0, 361, zone_range_deg)\n",
    "        possible_actions = {}\n",
    "        for action_key in n_actions_keys:\n",
    "            possible_actions[action_key] = [round(zone_spacing_deg[action_key]), round(zone_spacing_deg[action_key+1]),]\n",
    "        if stay:\n",
    "            possible_actions[len(possible_actions)] = \"STAY\"\n",
    "\n",
    "        return possible_actions\n",
    "\n",
    "    #==== TEST&VISU PURPOSES ONLY ====#\n",
    "    def update_agent_state_mapping(self, pose:tuple, ob:list, state_belief:list=None)-> dict:\n",
    "        \"\"\" Dictionnary to keep track of believes and associated obs, usefull for testing purposes\"\"\"\n",
    "        if state_belief is None:\n",
    "            state = -1\n",
    "        else:\n",
    "            state = np.argmax(state_belief)\n",
    "        #If we already have an ob, let's not squish it with ghost nodes updates\n",
    "        if pose in self.agent_state_mapping.keys() and self.agent_state_mapping[pose]['ob'] != -1:\n",
    "            ob[0] = self.agent_state_mapping[pose]['ob']\n",
    "        self.agent_state_mapping[pose] = {'state' : state , 'ob': ob[0]}\n",
    "        if len(ob) > 1:\n",
    "           self.agent_state_mapping[pose]['ob2'] =  ob[1] \n",
    "      \n",
    "        return self.agent_state_mapping\n",
    "    \n",
    "    #==== SET METHODS ====#\n",
    "    def explo_oriented_navigation(self):\n",
    "        self.use_param_info_gain = False #if true, do not use with the other terms\n",
    "        self.use_states_info_gain = True \n",
    "        self.use_utility = False\n",
    "\n",
    "    def goal_oriented_navigation(self, obs=None, **kwargs):\n",
    "        pref_weight = kwargs.get('pref_weight', 1.0)\n",
    "        self.update_preference(obs, pref_weight)\n",
    "        self.use_param_info_gain = False #if true, do not use with the other terms\n",
    "        self.use_states_info_gain = False #This make it FULLY Goal oriented\n",
    "        #NOTE: if we want it to prefere this C but still explore a bit once certain about state \n",
    "        #(keep exploration/exploitation balanced) keep info gain\n",
    "        self.use_utility = True\n",
    "\n",
    "\n",
    "    def set_action_step(self, action):\n",
    "        ''' only to do if we don't nfer action'''\n",
    "        self.action = np.array([action])\n",
    "        self.step_time()\n",
    "    \n",
    "    #==== GET METHODS\n",
    "    def get_current_pose_id(self):\n",
    "        ''' we do not want a negative pose od'''\n",
    "        if self.current_pose is None:\n",
    "            current_pose = self.PoseMemory.get_odom()[:2]\n",
    "        else:\n",
    "            current_pose = self.current_pose\n",
    "        return self.PoseMemory.pose_to_id(current_pose)\n",
    "    \n",
    "    def get_belief_over_states(self):\n",
    "        \"\"\"\n",
    "        get the belief distribution over states\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: The extracted belief distribution over states.\n",
    "        \"\"\"\n",
    "        return self.qs\n",
    "    \n",
    "    def get_current_timestep(self):\n",
    "        return self.curr_timestep\n",
    "    def get_possible_actions(self):\n",
    "        print('IN MODEL get_possible_actions', self.possible_actions)\n",
    "        return self.possible_actions\n",
    "    def set_memory_views(self, views):\n",
    "        self.ViewMemory = views\n",
    "    def get_memory_views(self):\n",
    "        return self.ViewMemory\n",
    "    \n",
    "    def get_n_states(self):\n",
    "        return len(self.agent_state_mapping)\n",
    "    \n",
    "    def get_agent_state_mapping(self)->dict:\n",
    "        return self.agent_state_mapping\n",
    "    \n",
    "    def get_B(self):\n",
    "        return self.B[0]\n",
    "    \n",
    "    def get_A(self):\n",
    "        return self.A\n",
    "    def get_current_most_likely_pose(self, z_score:float, min_z_score:float=2, qs=None,  observations:list=[])->int:\n",
    "        \"\"\"\n",
    "        Given a z_scores (usually around 2), is the agent certain about the state. If it is, to which pose does it correspond?\n",
    "        Return pose -1 if < threhsold, else return pose id.\n",
    "        If no state stands out at all, we don't know where we are and return -2\n",
    "        \"\"\"\n",
    "        if qs is None:\n",
    "            qs = self.get_belief_over_states()[0]\n",
    "        p_idx = -1\n",
    "        mean = np.mean(qs)\n",
    "        std_dev = np.std(qs)\n",
    "        #print('qs mean and std_dev', mean, std_dev)\n",
    "        # Calculate Z-scores\n",
    "        z_scores = (qs - mean) / std_dev\n",
    "        # Get indices of values with Z-score above 2\n",
    "        outlier_indices = np.where(np.abs(z_scores) > z_score)[0]\n",
    "        min_outlier_indices = np.where(np.abs(z_scores) > min_z_score)[0]\n",
    "        \n",
    "        \n",
    "        #print(\"Indices of outliers (Z-score >\",z_score,\"):\" , outlier_indices)\n",
    "        #If we are sure of a state (independent of number of states), we don't have pose as ob and A allows for pose\n",
    "        if len(outlier_indices) >= 0 and len(observations) < 2 and len(self.A) > 1:\n",
    "            #If 1 state stands out\n",
    "            if len(outlier_indices) == 1:\n",
    "                p_idx = outlier_indices[0]\n",
    "        #If min_z_scores length is 0, it means no proba is standing out! We don't know where we are   \n",
    "        elif len(min_outlier_indices) == 0 and len(observations) < 2 and len(self.A) > 1:\n",
    "            p_idx = -2\n",
    "        return p_idx\n",
    "\n",
    "    def get_observation_most_likely_states(self, z_score:float, observations:list=[])->int:\n",
    "        \"\"\"\n",
    "        Given a z_scores (usually around 2), is the agent certain about the state. If it is, to which pose does it correspond?\n",
    "        Return pose -1 if < threhsold, else return pose id.\n",
    "        If no state stands out at all, we don't know where we are and return -2\n",
    "        \"\"\"\n",
    "        likelihood = self.get_A()[0][observations[0],:]\n",
    "        p_idx = -1\n",
    "        mean = np.mean(likelihood)\n",
    "        std_dev = np.std(likelihood)\n",
    "        logging.info(f'likelihood mean and std_dev {mean}, {std_dev}')\n",
    "        # Calculate Z-scores\n",
    "        z_scores = (likelihood - mean) / std_dev\n",
    "        # Get indices of values with Z-score above 2\n",
    "        outlier_indices = np.where(np.abs(z_scores) > z_score)[0]       \n",
    "        print('z_scores',z_scores)\n",
    "        #print(\"likelihood Indices of outliers (Z-score >\",z_score,\"):\" , outlier_indices)\n",
    "        #If we are sure of a state (independent of number of states), we don't have pose as ob and A allows for pose\n",
    "    \n",
    "        return outlier_indices\n",
    "    \n",
    "    def get_expected_observation(self, qs=np.ndarray, A:np.ndarray=None)-> np.ndarray:\n",
    "        \"\"\" get observation belief for state qs\"\"\"\n",
    "        if A is None:\n",
    "            A = self.A\n",
    "        qo_pi = get_expected_obs(qs, A)\n",
    "        return qo_pi\n",
    "\n",
    "    def get_next_state_given_action(self, qs= np.array, action=int, B=None)->np.ndarray:\n",
    "        ''' expect only 1 qs, return only 1 qs with the same shape (1,) == np.ndarray([np.ndarray([])])'''\n",
    "        if B is None:\n",
    "            B = self.B\n",
    "\n",
    "        # print('B check', B[0][:,np.argmax(qs), action])\n",
    "        if isinstance(action, (int,np.int64)):\n",
    "            action = np.array([[action]])\n",
    "            \n",
    "        qs_pi = get_expected_states(qs, B, action)\n",
    "        return qs_pi\n",
    "    \n",
    "    \n",
    "    #==== MCTS_CALL ====#\n",
    "    def define_actions_from_MCTS_run(self,num_steps=1, logging=None,  **kwargs)->list: #,dict\n",
    "        \"\"\" \n",
    "        MCTS RUN, UNDER TEST (SHOULD NOT BE RE-CREATED EACH RUN)\n",
    "        TODO: adapt for when we want a full policy\n",
    "\n",
    "        \"\"\"\n",
    "        c_param = 5\n",
    "        num_simulations = 100  # Number of MCTS simulations per planning step\n",
    "        max_rollout_depth = 1 #UNUSED NOW # Maximum depth for the simulation (rollout) phase\n",
    "        mcts = MCTS(self, c_param, num_simulations, max_rollout_depth)\n",
    "\n",
    "        observations = kwargs.get('observations', None)\n",
    "        next_possible_actions = kwargs.get('next_possible_actions', None)\n",
    "        plot_MCTS_tree = kwargs.get('plot_MCTS_tree', False)\n",
    "\n",
    "        #If we are not inferring state at each state during the model update, we do it here\n",
    "        if observations is not None and self.current_pose is None:\n",
    "        #If self.current_pose is not None then we have step_update that infer state\n",
    "            \n",
    "            #NB: Only give obs if state not been inferred before \n",
    "            if len(observations) < len(self.A):\n",
    "                partial_ob = 0\n",
    "                            \n",
    "            elif len(observations) == len(self.A):\n",
    "                partial_ob = None\n",
    "                if self.current_pose == None:\n",
    "                    self.current_pose = observations[1]\n",
    "                observations[1] = self.PoseMemory.pose_to_id(observations[1])\n",
    "            \n",
    "            self.infer_states(observation = observations, partial_ob=partial_ob, save_hist=True)\n",
    "\n",
    "        initial_pose_id = self.get_current_pose_id()\n",
    "        initial_belief_qs = self.get_belief_over_states() # Get initial belief\n",
    "        initial_observation = self.get_expected_observation(initial_belief_qs)\n",
    "\n",
    "        best_actions, data = mcts.start_mcts(state_qs=initial_belief_qs,\n",
    "                     pose_id=initial_pose_id, observation=initial_observation, \\\n",
    "                     next_possible_actions=next_possible_actions, num_steps=num_steps, logging=logging, plot=plot_MCTS_tree)\n",
    "        \n",
    "        #NOTE: THIS CONSIDERONLY FIRST ACTION OF POLICY. MIGHT LEADS TO ISSUE DEPENDING ON HOW WE USE THAT\n",
    "        self.q_pi = data['qpi'][0]\n",
    "        self.G = data['efe'][0]\n",
    "\n",
    "        #NOTE: THIS CONSIDER THAT WE APPLY FIRST ACTION OF POLICY. MIGHT LEADS TO ISSUE DEPENDING ON HOW WE USE THAT\n",
    "        self.action = np.array([best_actions[0]])\n",
    "        self.step_time()\n",
    "        \n",
    "        return best_actions[:num_steps], data\n",
    "    \n",
    "    #==== INFERENCE ====#\n",
    "\n",
    "    def infer_states(self, observation:list, action:np.ndarray= None ,save_hist:bool=True, partial_ob:int=None, qs:list=None):\n",
    "        \"\"\"\n",
    "        Performs variational inference to update posterior beliefs over hidden states given an observation.\n",
    "\n",
    "        This method updates the agent's belief state (`qs`) by incorporating new observations \n",
    "        and optionally considering the previous action. The update process depends on the \n",
    "        selected inference algorithm (`VANILLA`).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        observation : list or tuple \n",
    "            The observed state indices for each observation modality.\n",
    "    \n",
    "        action : np.ndarray, optional\n",
    "            The most recent action taken by the agent. If provided, it helps refine posterior beliefs.\n",
    "\n",
    "        save_hist : bool, default=True\n",
    "            If True, stores the latest observation and updates historical data for future inference.\n",
    "\n",
    "\n",
    "        partial_ob : int, optional\n",
    "            Specifies a particular observation modality to update the belief state for, rather than all modalities.\n",
    "\n",
    "        qs : list, optional\n",
    "            A predefined posterior belief state. If provided, this will be used instead of computing from scratch.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        qs : numpy.ndarray of dtype object\n",
    "            Updated posterior beliefs over hidden states. The structure depends on the inference algorithm:\n",
    "            - For `VANILLA`, `qs` represents a single posterior belief over hidden states.\n",
    "\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        - If `self.inference_algo == \"VANILLA\"`, posterior updates consider an empirical prior derived from \n",
    "        the transition model (`B`) or from a uniform prior (`D`).\n",
    "        - The method also updates `self.qs_hist` and `self.qs_step` when `save_hist=True`, \n",
    "        enabling tracking of belief evolution over time.\n",
    "        \"\"\"\n",
    "\n",
    "        if save_hist:\n",
    "            self.prev_obs.append(observation)\n",
    "            observations_hist = self.prev_obs\n",
    "        else:\n",
    "            observations_hist = self.prev_obs.copy()\n",
    "            observations_hist.append(observation)\n",
    "\n",
    "        if action == None:\n",
    "            action = self.action\n",
    "\n",
    "        if self.inference_algo == \"VANILLA\":\n",
    "            if action is not None:\n",
    "                if qs is None:\n",
    "                    ref_qs = self.get_belief_over_states() #we don't yet want to consider current obs to selest qs\n",
    "                else: #safety to avoid any risk\n",
    "                    ref_qs = qs[:]\n",
    "                empirical_prior = control.get_expected_states(\n",
    "                    ref_qs, self.B, action.reshape(1, -1) #type: ignore\n",
    "                )[0]\n",
    "            #unused, but kept as a memor\n",
    "            else:\n",
    "                self.D = self._construct_D_prior() #self.D\n",
    "                empirical_prior = self.D\n",
    "            if self.current_pose is None:\n",
    "                #TODO: increase A with observation even when self.current_pose is None\n",
    "                for i in range(len(self.A)):\n",
    "                    if partial_ob != None:\n",
    "                        i = partial_ob\n",
    "                    if observation[i] >= len(self.A[i]):\n",
    "                        print('ERROR IN INFER STATE: given observation not in A')\n",
    "                        qs = self.get_belief_over_states()\n",
    "                        return qs\n",
    "            qs = update_posterior_states(\n",
    "            self.A,\n",
    "            observation,\n",
    "            empirical_prior,\n",
    "            partial_ob,\n",
    "            **self.inference_params\n",
    "            )\n",
    "            F = 0\n",
    "            qs_step = 0\n",
    "\n",
    "        if save_hist:\n",
    "            self.F = F # variational free energy of each policy  \n",
    "            self.qs_step = qs_step\n",
    "            if hasattr(self, \"qs_hist\"):\n",
    "                self.qs_hist.append(qs)\n",
    "            self.qs = qs\n",
    "\n",
    "        return qs\n",
    "    \n",
    "    def infer_pose(self, pose)->list:\n",
    "        '''\n",
    "        Parameters:\n",
    "            pose (int or list): The index of the pose or the pose itself\n",
    "        Here we consider that action consider the actual action sensed by agent (thus consider no motion)\n",
    "        and we consider PoseMemory adapted to treat that perception\n",
    "        '''\n",
    "        if isinstance(pose,int):\n",
    "            pose = self.PoseMemory.id_to_pose(pose)\n",
    "        self.PoseMemory.update_odom_given_pose(pose)\n",
    "        if self.current_pose !=None:\n",
    "            self.current_pose = self.PoseMemory.get_odom(as_tuple=True)[:2]\n",
    "        return self.current_pose\n",
    "\n",
    "    def infer_action(self, logs=None, **kwargs):\n",
    "        \"\"\"\n",
    "        return the best action to take\n",
    "        possible params (as a dict):\n",
    "        observations (List): (only if state not been inferred before)\n",
    "        next_possible_actions (List): constraint the action to take to be among a list of given choices. \n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        return action as int and info as dict\n",
    "        \"\"\"\n",
    "        observations = kwargs.get('observations', None)\n",
    "        next_possible_actions = kwargs.get('next_possible_actions', list(self.possible_actions.keys()))\n",
    "        if logs is not None:\n",
    "            logs.info('observations'+ str(observations)+ 'next_possible_actions'+ str(next_possible_actions))\n",
    "        # prior = self.get_belief_over_states()\n",
    "        \n",
    "        #If we are not inferring state at each state during the model update, we do it here\n",
    "        if observations is not None and self.current_pose is None:\n",
    "        #If self.current_pose is not None then we have step_update that infer state\n",
    "            \n",
    "            #NB: Only give obs if state not been inferred before \n",
    "            if len(observations) < len(self.A):\n",
    "                partial_ob = 0\n",
    "                            \n",
    "            elif len(observations) == len(self.A):\n",
    "                partial_ob = None\n",
    "                if self.current_pose == None:\n",
    "                    self.current_pose = observations[1]\n",
    "                observations[1] = self.PoseMemory.pose_to_id(observations[1])\n",
    "            \n",
    "            posterior = self.infer_states(observation = observations, partial_ob=partial_ob, save_hist=True)\n",
    "            # print('infer action: self.current_pose', self.current_pose, posterior[0].round(3))\n",
    "        if logs is not None:\n",
    "            logs.info('still there')\n",
    "        #In case we don't have observations.\n",
    "        posterior = self.get_belief_over_states()\n",
    "        #print('infer action: inferred prior state', posterior[0].round(3))\n",
    "        q_pi, efe, info_gain, utility = self.infer_policies(posterior, logs=logs)\n",
    "        if logs is not None:\n",
    "            logs.info('catching up here')\n",
    "        poses_efe = None\n",
    "        action = self.sample_action(q_pi, next_possible_actions)\n",
    "\n",
    "        if logs is not None:\n",
    "            logs.info('no problem here')\n",
    "        #TODO: switch back to sample_action once tests done\n",
    "        # action, poses_efe = self.sample_action_test(next_possible_actions)\n",
    "        \n",
    "        #What we would expect given prev prior and B transition \n",
    "        # prior = spm_dot(self.B[0][:, :, int(action)], prior)\n",
    "        \n",
    "        self.q_pi = q_pi\n",
    "        self.G = efe\n",
    "\n",
    "        data = { \"qs\": posterior[0],\n",
    "            \"qpi\": q_pi,\n",
    "            \"efe\": efe,\n",
    "            \"info_gain\": info_gain,\n",
    "            \"utility\": utility,\n",
    "            #\"bayesian_surprise\": utils.bayesian_surprise(posterior[0].copy(), prior),\n",
    "            }\n",
    "        if poses_efe is not None:\n",
    "            data['poses_efe'] = poses_efe\n",
    "        return int(action), data\n",
    "    \n",
    "    def infer_policies(self, qs=None, logs=None):\n",
    "        \"\"\"\n",
    "        Perform policy inference by optimizing a posterior (categorical) distribution over policies.\n",
    "        This distribution is computed as the softmax of ``G * gamma + lnE`` where ``G`` is the negative expected\n",
    "        free energy of policies, ``gamma`` is a policy precision and ``lnE`` is the (log) prior probability of policies.\n",
    "        This function returns the posterior over policies as well as the negative expected free energy of each policy.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        q_pi: 1D ``numpy.ndarray``\n",
    "            Posterior beliefs over policies, i.e. a vector containing one posterior probability per policy.\n",
    "        G: 1D ``numpy.ndarray``\n",
    "            Negative expected free energies of each policy, i.e. a vector containing one negative expected free energy per policy.\n",
    "        \"\"\"\n",
    "        if qs is None:\n",
    "            qs = self.qs\n",
    "\n",
    "        #If we want to increase the precision of the utility \n",
    "        # term on A, we can play with the section below.\n",
    "        #Currently unused \n",
    "        if self.use_utility:\n",
    "            A = copy.deepcopy(self.A)\n",
    "            # for modality, array in enumerate(A[0]):\n",
    "            #     # Compute normalization\n",
    "            #     summed = array.sum(axis=0, keepdims=True)\n",
    "            #     # print(summed)\n",
    "            #     A[0][modality] = array * 10 / summed\n",
    "        else:\n",
    "            A = self.A\n",
    "\n",
    "        q_pi, G, info_gain, utility = update_posterior_policies(\n",
    "            qs,\n",
    "            A,\n",
    "            self.B,\n",
    "            self.C,\n",
    "            self.policies,\n",
    "            self.use_utility,\n",
    "            self.use_states_info_gain,\n",
    "            self.use_param_info_gain,\n",
    "            self.pA,\n",
    "            self.pB,\n",
    "            E = self.E,\n",
    "            gamma = self.gamma,\n",
    "            diff_policy_len = False, #TODO: erase in a refactoring\n",
    "            logs= logs\n",
    "        )\n",
    "        if hasattr(self, \"q_pi_hist\"):\n",
    "            self.q_pi_hist.append(q_pi)\n",
    "            if len(self.q_pi_hist) > self.inference_horizon:\n",
    "                self.q_pi_hist = self.q_pi_hist[-(self.inference_horizon-1):]\n",
    "            \n",
    "        return q_pi, G, info_gain, utility\n",
    "    \n",
    "    def sample_action(self, q_pi:np.ndarray, possible_first_actions:list=None)->int:\n",
    "        \"\"\"\n",
    "        Sample or select a discrete action from the posterior over control states.\n",
    "        This function both sets or cachÃ©s the action as an internal variable with the agent and returns it.\n",
    "        This function also updates time variable (and thus manages consequences of updating the moving reference frame of beliefs)\n",
    "        using ``self.step_time()``.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        action: 1D ``numpy.ndarray``\n",
    "            Vector containing the indices of the actions for each control factor\n",
    "        \"\"\"\n",
    "        if possible_first_actions != None:\n",
    "            #Removing all policies leading us to uninteresting or forbiden action. //speed computation//\n",
    "            policies, q_pi = zip(*[(policy, q_pi[p_id]) for p_id, policy \\\n",
    "                                   in enumerate(self.policies) if policy[0] in possible_first_actions])\n",
    "        else:\n",
    "            policies =  self.policies\n",
    "\n",
    "        if self.sampling_mode == \"marginal\":\n",
    "            action = control.sample_action(\n",
    "                q_pi, policies, self.num_controls, action_selection = self.action_selection, alpha = self.alpha\n",
    "            )\n",
    "        elif self.sampling_mode == \"full\":\n",
    "            action = control.sample_policy(q_pi, policies, self.num_controls,\n",
    "                                           action_selection=self.action_selection, alpha=self.alpha)\n",
    "        self.action = action\n",
    "        self.step_time()\n",
    "\n",
    "        return action\n",
    "    \n",
    "    def infer_current_most_likely_pose(self, observations:list, z_score:float=2, min_z_score:float=2):\n",
    "        ''' define our position p '''\n",
    "        \n",
    "        # if self.current_pose is None:\n",
    "        #     z_score = 2\n",
    "        \n",
    "        p_idx = self.get_current_most_likely_pose(z_score, min_z_score, observations = observations)\n",
    "        #if we have a pose, replace current inferred pose by the most likely one.\n",
    "        if p_idx >= 0:\n",
    "            self.current_pose = self.PoseMemory.id_to_pose(p_idx)\n",
    "            self.PoseMemory.reset_odom(self.current_pose)\n",
    "            #print('updating believed pose given certitude on state:', self.current_pose)\n",
    "        elif p_idx < -1:\n",
    "            self.current_pose = None\n",
    "        return p_idx\n",
    "    \n",
    "    def infer_best_action_given_actions(self, G:list, actions:list, action_selection:str=None, alpha:float=None):\n",
    "        if isinstance(actions[0], (int, np.int64)):\n",
    "            actions = np.array([[[a]] for a in actions])\n",
    "\n",
    "        if action_selection is None:\n",
    "            action_selection = self.action_selection\n",
    "        if alpha is None:\n",
    "            alpha = self.alpha\n",
    "        G = np.array(G)\n",
    "        lnE = spm_log_single(np.ones(G.shape) / len(G))\n",
    "\n",
    "        q_pi = softmax(G * self.gamma + lnE) \n",
    "        if self.sampling_mode == \"marginal\":\n",
    "            best_action = control.sample_action(q_pi, policies = actions, num_controls = self.num_controls, action_selection = action_selection, alpha= alpha)\n",
    "        elif self.sampling_mode == \"full\":\n",
    "            best_action = control.sample_policy(q_pi, actions, self.num_controls,\n",
    "                                           action_selection=action_selection, alpha=alpha)\n",
    "        return q_pi, int(best_action[0])\n",
    "    \n",
    "    def infer_utility_term(self, qo_pi:np.ndarray, C=None)->float:\n",
    "        \"\"\" given the observation belief of a state, what is the utility term\"\"\"\n",
    "        if C is None:\n",
    "            C = self.C\n",
    "        utility_term = calc_expected_utility(qo_pi, C)  #negative value, the highest the more interesting\n",
    "        if self.inductive_inference:\n",
    "            Bt = (self.get_B() > self.certitude_transition_threshold).astype(float)\n",
    "            H = 0\n",
    "            for n in range(self.num_steps):\n",
    "                I_next = ((Bt.T @ I[-1]) > 0 ).astype(float) # New reachable states (as bool)\n",
    "                print(I_next)\n",
    "                I.append(I_next[0])\n",
    "                print('setp', len(I)-1)\n",
    "\n",
    "            utility_term += H\n",
    "        return utility_term\n",
    "    \n",
    "    def infer_info_gain_term(self, qs_pi:np.ndarray, A=None)->float:\n",
    "        \"\"\" given the belief of a state, what is the info gain term (Note the method expects several qs, thus qs must be in 3 layers of np.ndarray)\"\"\"\n",
    "        if A is None:\n",
    "            A = self.A\n",
    "        return calc_states_info_gain(A, qs_pi)\n",
    "    \n",
    "    def infer_param_info_gain(self, qs_pi:np.ndarray, qo_pi:np.ndarray, qs:np.ndarray, action:int):\n",
    "        \"\"\"Infer param info gain for an action (but can also be a policy)\"\"\"\n",
    "        G = 0\n",
    "        if self.pA is not None:\n",
    "            param_info_gain = calc_pA_info_gain(self.pA, qo_pi, qs_pi)\n",
    "            G +=  param_info_gain\n",
    "        if self.pB is not None:\n",
    "            if isinstance(action, (int,np.int64)):\n",
    "                action = np.array([[action]])\n",
    "            param_info_gain = calc_pB_info_gain(self.pB, qs_pi, qs, action)\n",
    "            G +=  param_info_gain\n",
    "\n",
    "        return G\n",
    "    \n",
    "    #==== OTHER METHODS ====#\n",
    "\n",
    "    def determine_next_pose(self, action_id:int, pose:list=None,  min_dist_to_next_node:float=None):\n",
    "        next_pose = self.PoseMemory.pose_transition_from_action(action =action_id, odom= pose, ideal_dist=min_dist_to_next_node)\n",
    "        next_pose = [round(elem, 2) for elem in next_pose]\n",
    "        next_pose_id = self.PoseMemory.pose_to_id(next_pose, save_in_memory=False)\n",
    "        #print('action, next pose and id', action_id, next_pose, next_pose_id)\n",
    "        return next_pose, next_pose_id\n",
    "\n",
    "    def determine_action_given_angle_deg(self, angle):\n",
    "        \"\"\"\n",
    "        Find the key in possible_actions corresponding to the given angle.\n",
    "\n",
    "        Args:\n",
    "            angle (float): The angle to check in DEGREES\n",
    "\n",
    "        Returns:\n",
    "            int: The corresponding action key, or None if no match is found.\n",
    "        \"\"\"\n",
    "        actions = self.possible_actions.copy()\n",
    "        if \"STAY\" in actions.values():\n",
    "            actions.popitem()\n",
    "        action_key = [k for k,v in actions.items() if v[0] <= angle and v[1] > angle]\n",
    "        return action_key[0]\n",
    "        \n",
    "        #same thing\n",
    "        # for key, value in self.possible_actions.items():\n",
    "        #     if value == \"STAY\":\n",
    "        #         continue\n",
    "        #     if value[0] <= angle < value[1]:  # Check if angle falls within range\n",
    "        #         return key\n",
    "        # return None\n",
    "\n",
    "    def calculate_min_dist_to_next_node(self, state_step:int=1):\n",
    "        return self.influence_radius * state_step + self.robot_dim/2#/3 to consider -a little- robot_dim when adding nodes.as_integer_ratio\n",
    "    \n",
    "    def define_next_possible_actions(self, obstacle_dist_per_actions:list, restrictive:bool=False, logs=None):\n",
    "        min_dist = self.calculate_min_dist_to_next_node()\n",
    "        \n",
    "        n_actions = len(self.possible_actions) - (\"STAY\" in self.possible_actions.values())\n",
    "        possible_actions = [i for i in range(n_actions) if obstacle_dist_per_actions[i] >= min_dist]\n",
    "        if restrictive:\n",
    "            possible_actions_2 = possible_actions[:]\n",
    "            for action in possible_actions_2:\n",
    "                next_pose, next_pose_id = self.determine_next_pose(action, min_dist_to_next_node=min_dist)\n",
    "                registered_pose = self.PoseMemory.id_to_pose(next_pose_id)\n",
    "                if logs:\n",
    "                    logs.info(f'next pose{next_pose}{next_pose_id}, with action{action}, but registered_pose{registered_pose}')\n",
    "                if registered_pose[0] != next_pose[0] or registered_pose[1] != next_pose[1] :\n",
    "                    possible_actions.remove(action)\n",
    "                    \n",
    "        if \"STAY\" in self.possible_actions.values():\n",
    "            possible_actions.append(n_actions)\n",
    "\n",
    "        return possible_actions\n",
    "\n",
    "    #==== Update A, B, C ====#\n",
    "    def update_A_with_data(self,obs:list, state:int)->np.ndarray:\n",
    "        \"\"\"Given obs and state, update A entry \"\"\"\n",
    "        A = self.A\n",
    "        \n",
    "        for dim in range(self.num_modalities ):\n",
    "            A[dim][:,state] = 0\n",
    "            A[dim][obs[dim],state] = 1\n",
    "        self.A = A\n",
    "        return A\n",
    "    \n",
    "    def update_A(self, obs, qs=None):\n",
    "        \"\"\"\n",
    "        Update approximate posterior beliefs about Dirichlet parameters that parameterise the observation likelihood or ``A`` array.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        observation: ``list`` or ``tuple`` of ints\n",
    "            The observation input. Each entry ``observation[m]`` stores the index of the discrete\n",
    "            observation for modality ``m``.\n",
    "\n",
    "        Returns\n",
    "        -----------\n",
    "        qA: ``numpy.ndarray`` of dtype object\n",
    "            Posterior Dirichlet parameters over observation self (same shape as ``A``), after having updated it with observations.\n",
    "        \"\"\"\n",
    "        if qs is None:\n",
    "            qs = self.qs\n",
    "        qA = update_obs_likelihood_dirichlet(\n",
    "            self.pA, \n",
    "            self.A, \n",
    "            obs, \n",
    "            qs, \n",
    "            self.lr_pA, \n",
    "            self.modalities_to_learn\n",
    "        )\n",
    "\n",
    "        self.pA = qA # set new prior to posterior\n",
    "        self.A = utils.norm_dist_obj_arr(qA) # take expected value of posterior Dirichlet parameters to calculate posterior over A array\n",
    "\n",
    "        return qA\n",
    "    \n",
    "    def update_B(self,qs:np.ndarray, qs_prev:np.ndarray, action:int, lr_pB:int=None)-> np.ndarray:\n",
    "        \"\"\"\n",
    "        Updates the posterior Dirichlet parameters (`pB`) that parameterize the transition likelihood (`B`).\n",
    "\n",
    "        This function refines the transition model by incorporating new posterior beliefs about states (`qs`),\n",
    "        previous state beliefs (`qs_prev`), and the most recent action taken. The update is performed using \n",
    "        a Dirichlet-multinomial approach, ensuring a smooth adaptation of transition probabilities.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        qs : numpy.ndarray\n",
    "            Marginal posterior beliefs over hidden states at the current time step.\n",
    "\n",
    "        qs_prev : numpy.ndarray\n",
    "            Marginal posterior beliefs over hidden states at the previous time step.\n",
    "\n",
    "        action : int\n",
    "            The most recent action taken by the agent, which affects transition updates.\n",
    "\n",
    "        lr_pB : int, optional\n",
    "            Learning rate for updating `pB`. If not specified, defaults to `self.lr_pB`.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        qB : numpy.ndarray\n",
    "            Updated posterior Dirichlet parameters over transition probabilities (`B`). \n",
    "            This has the same shape as `B` but now incorporates learned state-action transitions.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        - The update is computed using the `update_state_likelihood_dirichlet` function, \n",
    "        which adjusts `pB` based on the observed transitions.\n",
    "        - The function ensures that `qB` does not contain negative values by applying a failsafe correction.\n",
    "        - Transition probabilities (`B`) are normalized after updating `pB` to maintain a valid probability distribution.\n",
    "        - If `lr_pB` is negative, a failsafe mechanism prevents `qB` from dropping below a minimum threshold (0.005).\n",
    "        - The updated `qB` is stored as `self.pB`, and `B` is re-normalized for future inference.\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        if lr_pB is None:\n",
    "            lr_pB = self.lr_pB\n",
    "        \n",
    "        qB = update_state_likelihood_dirichlet(\n",
    "            self.pB,\n",
    "            self.B,\n",
    "            [action],\n",
    "            qs,\n",
    "            qs_prev,\n",
    "            lr_pB,\n",
    "            self.factors_to_learn\n",
    "        )\n",
    "    \n",
    "        qB[0] = np.maximum(qB[0], 0.005) #No negative value (failsafe because of lr possibly negative)\n",
    "        #no 0 values because 0 values can't variate anymore\n",
    "        self.pB = qB # set new prior to posterior\n",
    "        self.B = utils.norm_dist_obj_arr(qB)  # take expected value of posterior Dirichlet parameters to calculate posterior over B array\n",
    "        return qB\n",
    "\n",
    "    def update_A_dim_given_obs(self, obs:list,null_proba:list=[True]) -> np.ndarray:\n",
    "        ''' \n",
    "        Verify if the observations are new and fit into the current A shape.\n",
    "        If not, increase A shape in observation (n row) only.\n",
    "        '''\n",
    "        A = self.A\n",
    "        num_obs, num_states, num_modalities, num_factors = utils.get_model_dimensions(A=A)\n",
    "        \n",
    "        # Calculate the maximum dimension increase needed across all modalities\n",
    "        dim_add = [int(max(0,obs[m] + 1 - num_obs[m])) for m in range(num_modalities)]\n",
    "        # Update matrices size\n",
    "        for m in range(num_modalities):\n",
    "            A[m] = update_A_matrix_size(A[m], add_ob=dim_add[m], null_proba=null_proba[m])\n",
    "            if self.pA is not None:\n",
    "                self.pA[m] = utils.dirichlet_like(utils.to_obj_array(A[m]), scale=1)[0]\n",
    "        num_obs, num_states, num_modalities, num_factors = utils.get_model_dimensions(A=A)\n",
    "        self.num_obs = num_obs\n",
    "        self.A = A\n",
    "        return A\n",
    "    \n",
    "    def update_A_dim_given_pose(self, pose_idx:int,null_proba:bool=True) -> np.ndarray:\n",
    "        ''' \n",
    "        Verify if the observations are new and fit into the current A shape.\n",
    "        If not, increase A shape and associate those observations with the newest state generated.\n",
    "        If yes, search for the first empty column available and fill it with new inferred position (pose_idx)\n",
    "        '''\n",
    "        A = self.A\n",
    "        num_obs, num_states, num_modalities, num_factors = utils.get_model_dimensions(A=A)\n",
    "        if pose_idx >= max(num_states):\n",
    "            # Calculate the maximum dimension increase needed across all modalities\n",
    "            dim_add = int(max(0,pose_idx + 1 - num_obs[num_modalities-1]))\n",
    "            # Update matrices size\n",
    "            #and associate new observations with the newest state generated\n",
    "            if dim_add > 0:\n",
    "                A[0] = update_A_matrix_size(A[0], add_state=dim_add, null_proba=null_proba)\n",
    "                if num_modalities > 1:\n",
    "                    A[1] = update_A_matrix_size(A[1], add_ob=dim_add, add_state=dim_add, null_proba=null_proba)\n",
    "                    self.num_obs[1] = A[1].shape[0]\n",
    "        if num_modalities > 1:\n",
    "            #columns_wthout_data = np.sort(np.append(np.where(np.all(A[1] == 1/A[1].shape[0], axis=0))[0], np.where(np.all(A[1] == 0, axis=0))[0]))\n",
    "            A[1][:, pose_idx] = 0\n",
    "            A[1][pose_idx, pose_idx] = 1\n",
    "            \n",
    "\n",
    "        if self.pA is not None:\n",
    "            self.pA = utils.dirichlet_like(utils.to_obj_array(A), scale=1)\n",
    "                        \n",
    "        self.num_states = [A[0].shape[1]]\n",
    "        self.A = A\n",
    "        return A\n",
    "    \n",
    "    def update_B_dim_given_A(self)-> np.ndarray:\n",
    "        \"\"\" knowing A dimension, update B state dimension to match\"\"\"\n",
    "        B = self.B\n",
    "        add_dim = self.A[0].shape[1]-B[0].shape[1]\n",
    "        if add_dim > 0: \n",
    "            #increase B dim\n",
    "            B = update_B_matrix_size(B, add= add_dim)\n",
    "            self.pB = update_B_matrix_size(self.pB, add= add_dim, alter_weights=True)\n",
    "            if len(self.qs) > 1:\n",
    "                for seq in self.qs:\n",
    "                    for subseq in seq:\n",
    "                        subseq[0] = np.append(subseq[0], [0] * add_dim)\n",
    "            else:\n",
    "            \n",
    "                self.qs[0] = np.append(self.qs[0],[0]*add_dim)\n",
    "        \n",
    "        self.num_states = [B[0].shape[0]]\n",
    "        self.B = B\n",
    "        return B\n",
    "    \n",
    "    def update_believes_with_obs(self, Qs:list, action:int, obs:list)-> None:\n",
    "        \"\"\"\n",
    "        Updates the model's transition (`B`) and observation (`A`) matrices using the given \n",
    "        posterior beliefs over states (`Qs`), action taken, and new observation.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        Qs : list\n",
    "            The updated posterior beliefs over hidden states.\n",
    "\n",
    "        action : int\n",
    "            The action taken at the current step.\n",
    "\n",
    "        obs : list\n",
    "            The observed sensory input at the current step.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "            Updates the transition (`B`) and observation (`A`) matrices in-place.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        - If `qs_hist` is available, it retrieves the previous belief state and ensures consistency \n",
    "        in dimensionality before updating `B` using `Qs`.\n",
    "        - If the transition resulted in a change of state, the function also updates `B` for \n",
    "        the reverse transition using the inverse action.\n",
    "        - After updating `B`, the function re-infers the new state (`Qs`) based on `obs` and \n",
    "        updates `A` accordingly.\n",
    "        \"\"\"\n",
    "        if len(self.qs_hist) > 0:#secutity check\n",
    "            qs_hist = self.qs_hist[-1]\n",
    "            qs_hist[0] = np.append(qs_hist[0],[0]*\\\n",
    "                                   (len(Qs[0])-len(qs_hist[0])))\n",
    "            self.update_B(Qs, qs_hist, action, lr_pB = 10) \n",
    "            #2 WAYS TRANSITION UPDATE (only if T to diff state)\n",
    "            if np.argmax(qs_hist[0]) != np.argmax(Qs[0]):\n",
    "                a_inv = reverse_action(self.possible_actions, action)\n",
    "                self.update_B(qs_hist, Qs, a_inv, lr_pB = 7)\n",
    "        Qs = self.infer_states(obs) \n",
    "        self.update_A(obs, Qs)\n",
    "\n",
    "    def update_B_given_unreachable_pose(self,next_pose:list, action:int)-> None:\n",
    "        \"\"\" We reduce transition probability between those 2 states that do not connect\"\"\"\n",
    "        if self.current_pose is not None and next_pose in self.PoseMemory.get_poses_from_memory() :\n",
    "            n_pose_id = self.PoseMemory.pose_to_id(next_pose)\n",
    "            qs = self.get_belief_over_states()\n",
    "            hypo_qs = self.infer_states([n_pose_id], np.array([action]), partial_ob=1, save_hist=False)\n",
    "\n",
    "            # print(self.B[0][np.argmax(hypo_qs[0])][np.argmax(qs[0])][action], self.B[0][np.argmax(qs[0])][np.argmax(hypo_qs[0])][action])\n",
    "            # print(self.B[0][np.argmax(qs[0])][np.argmax(hypo_qs[0])][action], self.B[0][np.argmax(hypo_qs[0])][np.argmax(qs[0])][action])\n",
    "            self.update_B(hypo_qs, qs,action,lr_pB=-10)\n",
    "            a_inv = reverse_action(self.possible_actions, action)\n",
    "            self.update_B(qs,hypo_qs,a_inv,lr_pB=-7)\n",
    "\n",
    "    def update_qs_dim(self, qs:np.array=None, update_qs_memory:bool=True)->np.ndarray:\n",
    "        if qs is None:\n",
    "            qs = self.qs[:]\n",
    "        if len(qs[0]) < self.B[0].shape[0]:\n",
    "            qs[0] = np.append(qs[0],[0]*(self.B[0].shape[0]-len(qs[0])))\n",
    "\n",
    "        if update_qs_memory:       \n",
    "            self.qs = qs\n",
    "            for p_step, past_qs in enumerate(self.qs_hist):\n",
    "                if len(past_qs[0]) < self.B[0].shape[0]:\n",
    "                    past_qs[0] = np.append(past_qs[0],[0]*(self.B[0].shape[0]-len(past_qs[0])))\n",
    "                    self.qs_hist[p_step]= past_qs\n",
    "        return qs\n",
    "    \n",
    "    def update_C_dim(self):\n",
    "        if self.C is not None:\n",
    "            num_obs, num_states, num_modalities, num_factors = utils.get_model_dimensions(A=self.A) \n",
    "            for m in range(num_modalities):\n",
    "                if self.C[m].shape[0] < num_obs[m]:\n",
    "                    self.C[m] = np.append(self.C[m], [0]*(num_obs[m]- self.C[m].shape[0]))\n",
    "    \n",
    "    def update_preference(self, obs:list=[-1,-1], pref_weight:float=1.0):\n",
    "        \"\"\"given a list of observations (must fill all expected observation. If no preference enters -1) we fill C with thos as preference. \n",
    "        If we have a partial preference over several observations, \n",
    "        then the given observation should be an integer < 0, the preference will be a null array \n",
    "        \"\"\"\n",
    "        if isinstance(obs, list):\n",
    "            self.update_A_dim_given_obs(obs, null_proba=[False]*len(obs))\n",
    "\n",
    "            C = self._construct_C_prior()\n",
    "\n",
    "            for modality, ob in enumerate(obs):\n",
    "                if ob >= 0:\n",
    "                    self.preferred_ob[modality] = ob\n",
    "                    ob_processed = utils.process_observation(ob, 1, [self.num_obs[modality]])\n",
    "                    ob = utils.to_obj_array(ob_processed)\n",
    "                else:\n",
    "                    ob = utils.obj_array_zeros([self.num_obs[modality]])\n",
    "                C[modality] = np.array(ob[0]) * pref_weight\n",
    "\n",
    "            if not isinstance(C, np.ndarray):\n",
    "                raise TypeError(\n",
    "                    'C vector must be a numpy array'\n",
    "                )\n",
    "            self.C = utils.to_obj_array(C)\n",
    "\n",
    "            assert len(self.C) == self.num_modalities, f\"Check C vector: number of sub-arrays must be equal to number of observation modalities: {self.num_modalities}\"\n",
    "\n",
    "            for modality, c_m in enumerate(self.C):\n",
    "                assert c_m.shape[0] == self.num_obs[modality], f\"Check C vector: number of rows of C vector for modality {modality} should be equal to {self.num_obs[modality]}\"\n",
    "        else:\n",
    "            self.preferred_ob = [-1,-1]\n",
    "            self.C = self._construct_C_prior()\n",
    "\n",
    "    #====== UPDATE MODEL ======#\n",
    "    def update_transitions_both_ways(self,qs:np.ndarray, next_qs:np.ndarray, action_id:int, \\\n",
    "                                     direct_lr_pB:int, reverse_lr_pB:int)-> None:\n",
    "        \n",
    "        a_inv = reverse_action(self.possible_actions, action_id)\n",
    "        self.update_B(next_qs, qs, action_id, lr_pB = direct_lr_pB) \n",
    "        self.update_B(qs, next_qs, a_inv, lr_pB = reverse_lr_pB)\n",
    "   \n",
    "    def update_imagined_translation(self, qs:np.ndarray, action_jump:int, n_actions:int, action_id:int, cur_pose:list, \\\n",
    "                                    min_dist_to_next_node:int, obstacle_dist_per_actions:int):\n",
    "        \"\"\"\n",
    "        Updates the model's transition probabilities (`B` matrix) from current pose to imagined poses and between imagined poses up to 'action_jump' actions away\n",
    "        It reinforces direct and indirect motion transitions while considering obstacles. \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        qs : np.ndarray\n",
    "            The posterior belief over states before taking the action.\n",
    "\n",
    "        action_jump : int\n",
    "            The range of adjacent actions to consider when updating transitions.\n",
    "\n",
    "        n_actions : int\n",
    "            The total number of possible actions.\n",
    "\n",
    "        action_id : int\n",
    "            The current action being taken.\n",
    "\n",
    "        cur_pose : list\n",
    "            The current position in the environment.\n",
    "\n",
    "        min_dist_to_next_node : int\n",
    "            The minimum distance required to move to the next node.\n",
    "\n",
    "        obstacle_dist_per_actions : int\n",
    "            The distance of obstacles from the current state for each possible action.\n",
    "\n",
    "        hypo_qs : list or None\n",
    "            The hypothetical belief state over hidden states, used when reinforcing indirect motion. \n",
    "            If `None`, direct motion updates are applied.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "            Updates the transition probabilities (`B` matrix) in-place.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "\n",
    "        \"\"\"\n",
    "        #1) We get current physical pose info + the next imagined pose info given action_id\n",
    "        _, next_pose_id = self.determine_next_pose(action_id, cur_pose, min_dist_to_next_node) #from odom to next imagined pose\n",
    "        next_pose = self.PoseMemory.id_to_pose(next_pose_id) #get memorised pose (not the approximated one)\n",
    "        cur_pose_id = self.PoseMemory.pose_to_id(cur_pose) #get odom pose id\n",
    "        next_state_ob_dist = obstacle_dist_per_actions[action_id] #to check if ob between physical pose to next imagined pose\n",
    "        \n",
    "        prev_action = -1\n",
    "        #print('__')\n",
    "        for offset in range(action_jump, -action_jump - 1, -1):\n",
    "            action_adjacent = action_id + offset\n",
    "            #print('action_adjacent, offset', action_adjacent, offset)\n",
    "            #restraingning action between possible actions numbers\n",
    "            if action_adjacent < 0 :\n",
    "                action_adjacent = n_actions +action_adjacent\n",
    "            else:\n",
    "                action_adjacent %= (n_actions)\n",
    "            #from physical pose, get next adjacent pose given offset action \n",
    "            next_adjacent_pose, next_adjacent_pose_id = self.determine_next_pose(action_adjacent, cur_pose, min_dist_to_next_node)\n",
    "            #if no adjacent pose, nothing to do\n",
    "            #print('next_adjacent_pose_id', next_adjacent_pose_id,'next_pose_id', next_pose_id, 'cur_pose_id',cur_pose_id)\n",
    "            if next_adjacent_pose_id < 0 or next_adjacent_pose_id==cur_pose_id:\n",
    "                continue\n",
    "            #if adjacent pose exists, then we get it's state (obtained from Transitioning from physical state to this adjacent state)\n",
    "            adjacent_qs = self.infer_states([next_adjacent_pose_id], np.array([action_adjacent]), save_hist=False, partial_ob=1, qs=qs)\n",
    "            adjacent_state_dist_to_ob = obstacle_dist_per_actions[action_adjacent] #get if ob at this adjacent pose\n",
    "            #print('offset', offset, 'action_adjacent', action_adjacent, 'adjacent_state_dist_to_ob', round(adjacent_state_dist_to_ob,2))\n",
    "            #We correct to pose ID pose, to be sure it matches\n",
    "            next_adjacent_pose = self.PoseMemory.id_to_pose(next_adjacent_pose_id) #get memorised pose (not the approximated one)\n",
    "            \n",
    "            #If known state and this is the direct transition from physical to an already existing state \n",
    "            if offset == 0 : #if direct motion from current state to another state  \n",
    "                reference_qs = qs\n",
    "                action = action_adjacent\n",
    "                direct_lr_pB = 5\n",
    "                reverse_lr_pB = 3\n",
    "                pose_in_action_range = self.PoseMemory.pose_in_action_range(action, next_pose, odom= cur_pose)\n",
    "                #print('direct transition from new current odom', cur_pose_id, 'to', next_pose_id)\n",
    "                \n",
    "            #If this transition is a lateral transition \n",
    "            elif offset != 0 and next_adjacent_pose_id != next_pose_id: #if indirect motion, we don't want to reinforce 'stay' motion with wrong action\n",
    "                reference_qs = self.infer_states([next_pose_id], np.array([action_id]), save_hist=False, partial_ob=1, qs=qs) #next direct imagined pose qs\n",
    "                angle = angle_turn_from_pose_to_p(pose = next_pose, goal_pose= next_adjacent_pose, in_deg=True)\n",
    "                action = self.determine_action_given_angle_deg(angle)\n",
    "                direct_lr_pB = 1\n",
    "                reverse_lr_pB = 1\n",
    "                pose_in_action_range = self.PoseMemory.pose_in_action_range(action, next_adjacent_pose, odom= next_pose)\n",
    "                #Just to avoid reinforcing same link several times (can happens if we check pose to id only considering distance)\n",
    "                if prev_action == action:\n",
    "                    #print('already updated that transition')\n",
    "                    continue\n",
    "                prev_action = action\n",
    "                #print('lateral transition from imagined pose',next_pose_id, 'to', next_adjacent_pose_id)\n",
    "            else:\n",
    "                continue\n",
    "            #print('pose_in_action_range', pose_in_action_range, 'action', action,'next_pose', next_adjacent_pose, 'odom', next_pose)\n",
    "            #If the pose is not in this action range, we don't enforce it + we can't have the poses being unreachable.\n",
    "            if pose_in_action_range and adjacent_state_dist_to_ob > min_dist_to_next_node and next_state_ob_dist > min_dist_to_next_node :\n",
    "                # Positive LR\n",
    "                self.update_transitions_both_ways(reference_qs, adjacent_qs, action, direct_lr_pB=direct_lr_pB, reverse_lr_pB=reverse_lr_pB)\n",
    "            elif pose_in_action_range:\n",
    "                #print('negative reinforcement')\n",
    "                # Negative LR\n",
    "                self.update_transitions_both_ways(reference_qs, adjacent_qs, action, direct_lr_pB=-direct_lr_pB, reverse_lr_pB=-reverse_lr_pB)\n",
    "\n",
    "    def update_transition_nodes(self, obstacle_dist_per_actions:list)-> None:\n",
    "        ''' \n",
    "        For each new pose observation, add a ghost state and update the estimated transition and observation for that ghost state.\n",
    "        '''\n",
    "        #print('Ghost nodes process:')\n",
    "        action_jump = int((len(self.possible_actions)-1) / 6)\n",
    "        sure_about_data_until_this_state = 1\n",
    "        ''' \n",
    "            TODO LIST: \n",
    "            1) Check if transition possible \n",
    "            IF impossible motion:\n",
    "                2) increase transition from current state to current state for this action (both ways)\n",
    "                3) if obstacle, check if there is a transition existing for this action and decrease state transition (both ways)\n",
    "            go to next action\n",
    "            Else: \n",
    "                4) infer new pose in that direction \n",
    "                5) check if a pose exist in that direction (margin of zone of influence)\n",
    "                6) if yes, increase transition prob to existing pose with that action\n",
    "                7) if no, \n",
    "                    7') increase all matrices IF NEED BE\n",
    "                    7'')create new node \n",
    "                8) check if previous and next action have obstacle. If no, link previous/next pose node to current pose node\n",
    "                9) from this node, check if action still possible further with increased zone of influence + margin (thus until we reach an obstacle) \n",
    "            skip next action (as we want 6 nodes around if no obstacle anywhere)\n",
    "            '''\n",
    "        \n",
    "        n_actions = len(self.possible_actions) - (\"STAY\" in self.possible_actions.values())\n",
    "        qs = self.get_belief_over_states()\n",
    "        \n",
    "        min_dist_to_next_node = self.calculate_min_dist_to_next_node()\n",
    "        \n",
    "        for action_id in range(n_actions):\n",
    "            #print('______________________________')\n",
    "            hypo_qs = None\n",
    "            state_step = 1\n",
    "            prev_step_qs = qs[:]\n",
    "            no_obstacle = True\n",
    "            cur_pose = self.PoseMemory.get_odom().copy()\n",
    "            cur_ref_pose = cur_pose.copy()\n",
    "            pose_in_action_range = True\n",
    "            \n",
    "            #9)\n",
    "            #The second element is just to avoid any risk of infinity loop\n",
    "            while no_obstacle and state_step<=self.lookahead_node_creation:\n",
    "                next_state_min_dist_to_next_node = self.calculate_min_dist_to_next_node(state_step)\n",
    "                #1)\n",
    "                #Is obstacle too close?\n",
    "                #print('for action', action_id, 'obstacle', obstacle_dist_per_actions[action_id], 'min_dist for new state', next_state_min_dist_to_next_node)\n",
    "                if obstacle_dist_per_actions[action_id] <=  next_state_min_dist_to_next_node :\n",
    "                    no_obstacle = False \n",
    "                    #Only enforce the loop back to current pose if it's a direct motion\n",
    "                    if state_step <= sure_about_data_until_this_state:\n",
    "                        #2)\n",
    "                        #print('enforcing motion:',action_id,' leads to current state')\n",
    "                        self.update_B(qs, qs, action_id, lr_pB = 10)   \n",
    "                else:\n",
    "                    #4)\n",
    "                    next_pose, next_pose_id = self.determine_next_pose(action_id, cur_ref_pose, min_dist_to_next_node)\n",
    "                    #print('next_pose', next_pose, self.PoseMemory.get_poses_from_memory().copy())\n",
    "                    #5) ->7)  \n",
    "                    if next_pose_id < 0 and pose_in_action_range:\n",
    "                        next_pose_id = self.PoseMemory.pose_to_id(next_pose) \n",
    "                        #print('creating new node in position', next_pose_id)\n",
    "                        #7')\n",
    "                        self.update_A_dim_given_pose(next_pose_id,null_proba=True)\n",
    "                        self.update_B_dim_given_A()\n",
    "                        self.update_C_dim()\n",
    "                        prev_step_qs = self.update_qs_dim(prev_step_qs,update_qs_memory=False)\n",
    "                        #7'')\n",
    "                        hypo_qs = self.infer_states([next_pose_id], np.array([action_id]), partial_ob=1, save_hist=False, qs=prev_step_qs)\n",
    "                        self.update_agent_state_mapping(tuple(next_pose[:2]), [-1, next_pose_id], hypo_qs[0])\n",
    "                        #We don't want lateral state transition updated when we are extrapolating further than \"sure_about_data_until_this_state\"\n",
    "                        #plus we only want the action continuing in a straight line from physical current pose. \n",
    "                        #becquse the beam rqnge grows bigger as the vectors are longer.                            \n",
    "                    else:\n",
    "                        #print('pose existing nearby as', next_pose_id,'not creating new node')\n",
    "                        hypo_qs = self.infer_states([next_pose_id], np.array([action_id]), partial_ob=1, save_hist=False, qs=prev_step_qs)\n",
    "\n",
    "                    if state_step > sure_about_data_until_this_state and pose_in_action_range:\n",
    "                            #print('DIRECT MOTION AT STATE STEP',state_step)\n",
    "                            self.update_imagined_translation(prev_step_qs[:], 0, n_actions, action_id, cur_ref_pose, \\\n",
    "                                        min_dist_to_next_node, obstacle_dist_per_actions)\n",
    "                    prev_step_qs = hypo_qs[:]\n",
    "                    cur_ref_pose = self.PoseMemory.id_to_pose(next_pose_id)\n",
    "                    pose_in_action_range = self.PoseMemory.pose_in_action_range(action_id, cur_ref_pose, odom= cur_pose, influence_radius=next_state_min_dist_to_next_node)#doesn't work\n",
    "                    #print('cur_ref_pose', cur_ref_pose, 'can be reached from ', cur_pose, 'with action', action_id,'?:', pose_in_action_range)\n",
    "                    \n",
    "                state_step +=1\n",
    "            #3), 5)->6)with offset 0 and 8)\n",
    "            qs = self.update_qs_dim(qs)\n",
    "            self.update_imagined_translation(qs[:], action_jump, n_actions, action_id, cur_pose, \\\n",
    "                                   min_dist_to_next_node, obstacle_dist_per_actions)\n",
    "               \n",
    "    def agent_step_update(self, action_id:int, obs:list, logs=None)->None:\n",
    "        \"\"\"\n",
    "        Updates the agent's belief state, transition probabilities, and learned environment \n",
    "        model based on the given action and observations.\n",
    "\n",
    "        This method performs the following steps:\n",
    "        1. **Infer new pose**: Updates the agent's estimated position.\n",
    "        2. **Update observation model (A) and control model (C)**: Adjusts probability distributions \n",
    "        to incorporate new observations.\n",
    "        3. **Update transition model (B)**: Modifies transition probabilities based on inferred states.\n",
    "        4. **Update belief states**: Updates internal beliefs given the latest observations.\n",
    "        5. **Update state mapping for visualization**: Stores the agent's inferred position and \n",
    "        corresponding belief state.\n",
    "        6. **Update transition nodes**: Modifies state transitions based on perceived obstacles.\n",
    "        7. **Ensure stationary transitions**: If a 'STAY' action exists, enforces it in the transition model.\n",
    "\n",
    "        Parameters:\n",
    "            action_id (int): The index of the action taken by the agent.\n",
    "            obs (list): The list of observations, expected to contain:\n",
    "                - primary_ob (int): The primary observed feature (e.g., color).\n",
    "                - pose_id (int, optional): The ID of the inferred pose. \n",
    "                - obstacles_dist_per_action_range (list): Distances to obstacles for each action.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        #we could get action_id from ours.action instead?\n",
    "\n",
    "        #We only update A and B if we have inferred a current pose\n",
    "        #Thus until doubt over current loc is not solved, we don't update internal self\n",
    "        if self.current_pose != None:\n",
    "            #Just for memory sake\n",
    "            primary_ob = obs[0]\n",
    "            if isinstance(obs[1],int):\n",
    "                pose_id = obs[1]\n",
    "            else:\n",
    "                pose_id = self.PoseMemory.pose_to_id(self.current_pose)\n",
    "\n",
    "            obstacles_dist_per_action_range = obs[-1]\n",
    "            \n",
    "            #1. INFER NEW POSE (should be after motion and before update)\n",
    "            # pose = self.PoseMemory.id_to_pose(pose_id)\n",
    "            # self.current_pose = self.infer_pose(pose) #Not sure it shouold be here. in case i want to give whatever...\n",
    "            \n",
    "            observations = [primary_ob,pose_id]\n",
    "            if logs:\n",
    "                logs.info('observations pose %f, action %f, ob_id %f, obstacles %s' % (pose_id, action_id, primary_ob, str(obstacles_dist_per_action_range)))\n",
    "            #2. UPDATE A C DIM IF NEW OB\n",
    "            self.update_A_dim_given_obs(observations, null_proba=[True,False])\n",
    "            self.update_C_dim()\n",
    "            #updating B in case pose_id new\n",
    "            self.update_B_dim_given_A()\n",
    "            #3. UPDATE BELIEVES GIVEN OBS\n",
    "            prior = self.infer_states(observations, save_hist=False)\n",
    "\n",
    "            #print('prior on believed state; action', self.action, action_id, \\\n",
    "            #    'colour_ob:', primary_ob , 'inf pose:',self.current_pose,'prior belief:', prior[0].round(3))\n",
    "                \n",
    "            self.update_believes_with_obs(prior,action=action_id, obs=observations)\n",
    "\n",
    "            posterior = self.infer_states(observations, save_hist=True)\n",
    "            ## agent_state_mapping for TEST PURPOSES and visualisation\n",
    "            self.update_agent_state_mapping(tuple(self.current_pose[:2]), observations, posterior[0])\n",
    "            #4. update all nodes\n",
    "            self.update_transition_nodes(obstacle_dist_per_actions=obstacles_dist_per_action_range)\n",
    "            #This is not mandatory, just a gain of time\n",
    "            if 'STAY' in self.possible_actions.values():\n",
    "                stay_action = [key for key, value in self.possible_actions.items() if value == 'STAY'][0]\n",
    "                self.B[0] = set_stationary(self.B[0], stay_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import median_abs_deviation\n",
    "\n",
    "def get_observation_most_likely_states(self, observations: list, per_threshold: float = 0.5) -> list:\n",
    "    \"\"\"\n",
    "    Robust standout detector using percentile, fallback for sparse/multi-peak distributions.\n",
    "    \"\"\"\n",
    "    likely_states = {}\n",
    "\n",
    "    for modality, ob in enumerate(observations):\n",
    "        if ob < 0:\n",
    "                continue\n",
    "        standout_indices = []\n",
    "        qo = np.array(self.get_A()[modality][ob])\n",
    "        # print('qo', qo.round(3))\n",
    "        # threshold for standout values\n",
    "        standout_indices = np.where(qo >= per_threshold)[0]\n",
    "\n",
    "        # Special case: only one clear maximum, much larger than rest\n",
    "        max_val = np.max(qo)\n",
    "        second_max = np.partition(qo.flatten(), -2)[-2]\n",
    "        # print('max_val', max_val,'second_max',second_max)\n",
    "        if max_val < 4 * second_max and second_max not in standout_indices:\n",
    "            np.append(standout_indices,second_max)\n",
    "        # print('standout_indices',standout_indices)\n",
    "        for idx in standout_indices:\n",
    "            likely_states[idx] = likely_states.get(idx, 0) + 1\n",
    "\n",
    "    if not likely_states:\n",
    "        return []\n",
    "#     print('likely_states', likely_states)\n",
    "\n",
    "\n",
    "    # Return most recurrent standout indices across modalities\n",
    "    most_recurrent = max(likely_states.values())\n",
    "    standout_final = [state for state, count in likely_states.items() if count == most_recurrent]\n",
    "\n",
    "    return standout_final\n",
    "\n",
    "\n",
    "\n",
    "def prev_get_observation_most_likely_states(self, observations:list,z_score:float=8)->list:\n",
    "        \"\"\"\n",
    "        Given a z_scores (usually around 8) and observations likelihood, which state do we expect?\n",
    "        Consider expected states through all modality and return most recurrent states\n",
    "        \"\"\"\n",
    "        likely_states = {}\n",
    "        standout_indices = []\n",
    "        print('observations',observations)\n",
    "        for modality, ob in enumerate(observations):\n",
    "                qo = self.get_A()[modality][ob]\n",
    "                print('qo', qo.round(3))\n",
    "\n",
    "                max_val = np.max(qo)\n",
    "                max_idx = np.argmax(qo)\n",
    "                second_max = np.partition(qo, -2)[-2]\n",
    "                print('max_val', max_val,'second_max',second_max)\n",
    "                # If max is significantly greater than second max â†’ clearly dominant\n",
    "                if max_val > 4 * second_max:\n",
    "                        likely_states[max_idx] = likely_states.get(max_idx, 0) + 1\n",
    "                        continue\n",
    "                mad = median_abs_deviation(qo, scale='normal')\n",
    "                if mad == 0:\n",
    "                        # Handle one-hot like case\n",
    "                        if np.count_nonzero(qo >= 1.0 ) == 1:\n",
    "                                print('HERE')\n",
    "                                idx = np.argmax(qo)\n",
    "                                likely_states[idx] = likely_states.get(idx, 0) + 1\n",
    "                        continue  # No variability, nothing stands out\n",
    "                \n",
    "                \n",
    "                median = np.median(qo)\n",
    "                print('mad median', mad, median,)\n",
    "                z_scores = (qo - median) / mad\n",
    "                indices = np.where(z_scores > z_score)[0]\n",
    "                np.set_printoptions(suppress=True)\n",
    "                print('zscore and indices',z_scores.round(1), indices)\n",
    "                for state in indices:\n",
    "                        likely_states[state] = likely_states.get(state, 0) + 1\n",
    "                  \n",
    "        if len(likely_states) == 0:\n",
    "                return []\n",
    "        most_recurrent_state = max(likely_states.values())\n",
    "        standout_indices = [key for key, value in likely_states.items() if value == most_recurrent_state]\n",
    "\n",
    "        print(likely_states)\n",
    "        return standout_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_C_dim(self):\n",
    "    if self.C is not None:\n",
    "        for m in range(self.num_modalities):\n",
    "            if self.C[m].shape[0] < self.num_obs[m]:\n",
    "                self.C[m] = np.append(self.C[m], [0]*(self.num_obs[m]- self.C[m].shape[0]))\n",
    "                self.Cs = np.append(self.Cs, [0]*(self.num_states- len(self.Cs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_preference(self, obs:list=[-1,-1], pref_weight:float=1.0):\n",
    "        \"\"\"given a list of observations (must fill all expected observation. If no preference enters -1) we fill C with thos as preference. \n",
    "        If we have a partial preference over several observations, \n",
    "        then the given observation should be an integer < 0, the preference will be a null array \n",
    "        \"\"\"\n",
    "        if isinstance(obs, list):\n",
    "            self.update_A_dim_given_obs(obs, null_proba=[False]*len(obs))\n",
    "\n",
    "            C = self._construct_C_prior()\n",
    "            Cs = np.zeros(self.num_states)\n",
    "\n",
    "            for modality, ob in enumerate(obs):\n",
    "                if ob >= 0:\n",
    "                    self.preferred_ob[modality] = ob\n",
    "                    ob_processed = utils.process_observation(ob, 1, [self.num_obs[modality]])\n",
    "                    ob = utils.to_obj_array(ob_processed)\n",
    "                else:\n",
    "                    ob = utils.obj_array_zeros([self.num_obs[modality]])\n",
    "                C[modality] = np.array(ob[0])\n",
    "\n",
    "            if not isinstance(C, np.ndarray):\n",
    "                raise TypeError(\n",
    "                    'C vector must be a numpy array'\n",
    "                )\n",
    "            C = C * pref_weight\n",
    "            self.C = utils.to_obj_array(C)\n",
    "\n",
    "\n",
    "            assert len(self.C) == self.num_modalities, f\"Check C vector: number of sub-arrays must be equal to number of observation modalities: {self.num_modalities}\"\n",
    "\n",
    "            for modality, c_m in enumerate(self.C):\n",
    "                assert c_m.shape[0] == self.num_obs[modality], f\"Check C vector: number of rows of C vector for modality {modality} should be equal to {self.num_obs[modality]}\"\n",
    "        else:\n",
    "            self.preferred_ob = [-1,-1]\n",
    "            self.C = self._construct_C_prior()\n",
    "\n",
    "        desired_states = get_observation_most_likely_states(observations=obs, per_threshold=0.45)\n",
    "        for state in desired_states:\n",
    "            Cs[state] = 1.0\n",
    "        self.Cs = Cs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_inductive_preference(self, current_qs:np.ndarray, qs_pi:np.ndarray, C=None)->float:\n",
    "        \"\"\" given the observation belief of a state, what is the utility term\n",
    "        NOTE: THIS WORKS FOR VANILLA MODEL ONLY (NOT MMP) AS WE CONSIDER QS to have only 1 step \n",
    "        \"\"\"\n",
    "        if C is None:\n",
    "            C = self.C\n",
    "        current_qs = current_qs[0]\n",
    "        qs_arg_max = np.argmax(current_qs)  #NOTE: not sure this is ideal...\n",
    "        model_B = self.get_B()[:,qs_arg_max,:]\n",
    "        median = np.median(model_B)\n",
    "        B = model_B[model_B > median] \n",
    "        certitude_threshold = max(np.mean(B), 0.15)\n",
    "        I = [copy.copy(self.Cs)]\n",
    "        #Keep only certain Transitions\n",
    "        B_certain_trans = (self.get_B() > certitude_threshold).astype(float)\n",
    "\n",
    "        found_path = False\n",
    "        # print('START with preferred state', np.argmax(I), I)\n",
    "        # print('we are in starting state', qs_arg_max, 'prob',current_qs[qs_arg_max])\n",
    "        # print('qs_pi',qs_pi)\n",
    "        #from preferred states, which states lead to it then we repeat until we are in qs\n",
    "        for n in range(self.num_steps):\n",
    "            #TODO: ADD WHEN WE STOP FOR LOOP (WHEN WE ARE ON CURRENT STATE)\n",
    "            I_next = ((B_certain_trans.T.dot(I[-1])) > 0).astype(float) # New reachable states (as bool -> float)\n",
    "            I_next = np.max(I_next, axis=0) #We consider all states regardless of action\n",
    "            # print('backward step', len(I)-1)\n",
    "            I.append(I_next)\n",
    "            #logging.info(f'States to inflate H {np.argwhere(I[n] > np.amin((I[n] >0).astype(float))).flatten()}')\n",
    "            if I[-1][qs_arg_max] >= current_qs[qs_arg_max]:\n",
    "                # print('we end process induction in ',n+1,' steps,current state', qs_arg_max)\n",
    "                n-=1\n",
    "                found_path = True\n",
    "                break\n",
    "        n+=1 #to consider that I[0] is goal\n",
    "        if found_path:\n",
    "            logging.info(f'Final States to inflate H {np.argwhere(I[n] > np.amin((I[n] >0).astype(float))).flatten()}')\n",
    "            H = np.log(certitude_threshold)*I[n].dot(qs_pi[0])\n",
    "        else:\n",
    "            H = 0.0\n",
    "\n",
    "        return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ours = Ours_V5_RW(num_obs=2, num_states=2, n_actions=13, influence_radius=0.5,robot_dim=0.3, lookahead_node_creation=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mstop\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 ,   1 ,       2 ,  4,   5 ,  7,  9,    15 ,    35, 39\n",
    "\n",
    "_, [2,7,12-14], [1],[8], [0], [24], [11,40] , [44,45], [60], [33]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEst init MCTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obstacles = [1.4612406492233276, 2.0710742473602295, 2.7915122509002686, 2.571498155593872, 2.9910919666290283, 2.616743803024292, 2.5963499546051025, 1.2535045146942139, 0.49500948190689087, 0.5026026964187622, 1.1839525699615479, 1.4570804834365845]\n",
    "\n",
    "ob_id = 0\n",
    "\n",
    "ours = Ours_V5_RW(num_obs=2, num_states=2, dim=2, \\\n",
    "                    observations=[ob_id], lookahead_policy=5,\\\n",
    "                    n_actions=13, influence_radius=1,\\\n",
    "                    robot_dim=0.3, lookahead_node_creation= 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ours.update_transition_nodes(obstacle_dist_per_actions=obstacles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ours.update_preference([0,-1], pref_weight=1)\n",
    "ours.C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ours.use_states_info_gain = True \n",
    "ours.use_utility = False\n",
    "ours.use_param_info_gain = False #if true, do not use with the other terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action, data = ours.define_actions_from_MCTS_run(num_step=1, observations=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ours.action = np.array([12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ours.get_belief_over_states()[0].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = ours.infer_states([0,0], save_hist=False)\n",
    "prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST OUR MODEL ADJACENT STATE EFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 18:44:57,536 - INFO - Model successfully loaded from: /home/idlab332/workspace/ros_ws/tests/big_ware/0/model.pkl\n",
      "2025-06-17 18:44:57,685 - INFO - Model successfully loaded from: /home/idlab332/workspace/ros_ws/tests/big_ware/0/model.pkl\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = '/home/idlab332/workspace/ros_ws/tests/big_ware/0/model.pkl' # Path to your pickled model\n",
    "NUM_SIMULATIONS = 30  # Number of MCTS simulations per planning step\n",
    "NUM_STEPS = 1      # Number of actions to take in the environment\n",
    "MAX_ROLLOUT_DEPTH = 10 # Maximum depth for the simulation (rollout) phase\n",
    "C_PARAM = 5\n",
    "PLOT_TREE = True      # Whether to plot the MCTS tree after each planning step\n",
    "pref_weight = 10\n",
    "pref_obs = [11,-1]\n",
    "vanilal_model = pickle_load_model(MODEL_PATH)\n",
    "H_model = pickle_load_model(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SET A GOAL\n",
    "\n",
    "    #39 - 1step state33, 35 - 2 steps state 60, 30- 3steps state3, 7- 5 step - state24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desired_states [15]\n",
      "1 model setup\n",
      "desired_states [15]\n",
      "1 model setup\n"
     ]
    }
   ],
   "source": [
    "for model in [vanilal_model, H_model]:\n",
    "    #GOAL TESTS\n",
    "    #print('np.mean(H_model.get_B())', np.mean(H_model.get_B()),1/model.get_B()[0].shape[0] )\n",
    "    # model.certitude_transition_threshold  = np.mean(H_model.get_B())\n",
    "    model.num_steps = MAX_ROLLOUT_DEPTH\n",
    "    model.Cs = np.zeros(model.num_states)\n",
    "\n",
    "\n",
    "    model.goal_oriented_navigation(pref_obs, pref_weight = pref_weight)\n",
    "    model.use_utility = True\n",
    "    obstacle_dist_per_actions = [4.507089614868164, 4.789198398590088, 4.365529537200928, 2.7395713329315186, 2.3621973991394043, 1.7037241458892822, 1.7129298448562622, 2.037290573120117, 1.3319873809814453, 6.884044647216797, 5.011831283569336, 4.510308742523193]\n",
    "    possible_actions = model.define_next_possible_actions(obstacle_dist_per_actions, restrictive=True)\n",
    "    desired_states = get_observation_most_likely_states(model,observations=pref_obs, per_threshold=0.45)\n",
    "    for state in desired_states:\n",
    "        model.Cs[state] = 1.0\n",
    "    print('desired_states',desired_states)\n",
    "    print('1 model setup')\n",
    "\n",
    "# underlying_model.use_states_info_gain = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VANILLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 18:28:23,966 - INFO - MCTS_Model_Interface initialized with model type: <class 'map_dm_nav.model.V5.Ours_V5_RW'>\n",
      "2025-06-17 18:28:23,968 - INFO - MCTS initialized with exploration parameter c=5, num_simus=30, max_depth=10, policy_alpha=16.0,  action_selection=stochastic\n",
      "2025-06-17 18:28:23,975 - INFO - ===== Initial Root Node ID: 53 =====\n"
     ]
    }
   ],
   "source": [
    "# Create the MCTS algorithm instance\n",
    "vanilal_model.use_inductive_inference = False\n",
    "mcts = MCTS(vanilal_model, c_param=C_PARAM, num_simulation=NUM_SIMULATIONS) # Adjust c_param if needed\n",
    "\n",
    "# Get action names for logging\n",
    "map_action_names = vanilal_model.get_possible_actions() # Assuming pose 0 exists\n",
    "\n",
    "# Define the initial state\n",
    "initial_pose_id = 53 # Or get from your model/environment\n",
    "initial_belief_qs = vanilal_model.get_belief_over_states() # Get initial belief\n",
    "initial_observation = vanilal_model.get_expected_observation(initial_belief_qs)\n",
    "# Root node has no parent and no action leading to it\n",
    "root_node = Node(state_qs=initial_belief_qs,\n",
    "                pose_id=initial_pose_id,\n",
    "                parent=None,\n",
    "                action_index=None,\n",
    "                observation=initial_observation, \n",
    "                possible_actions=possible_actions)\n",
    "\n",
    "logging.info(f\"===== Initial Root Node ID: {root_node.id} =====\")\n",
    "\n",
    "# --- Simulation Loop ---\n",
    "current_node = root_node\n",
    "data = {\"qs\": initial_belief_qs[0],\n",
    "            \"qpi\": [],\n",
    "            \"efe\": [],\n",
    "            \"info_gain\": [],\n",
    "            \"utility\": [],\n",
    "            #\"bayesian_surprise\": utils.bayesian_surprise(posterior[0].copy(), prior),\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 18:28:24,004 - INFO - \n",
      "===== Planning Step 1/1 =====\n",
      "2025-06-17 18:28:24,007 - INFO - Current State (Node ID): 53\n",
      "2025-06-17 18:28:24,008 - INFO - Starting MCTS planning from root node 53 for 30 simulations.\n",
      "2025-06-17 18:28:24,010 - INFO - --- Simulation 1/30 ---\n",
      "2025-06-17 18:28:24,011 - INFO - --- Selection Phase End (Selected Node: 53) ---\n",
      "2025-06-17 18:28:24,023 - INFO - from node 53 -> Child Node 33, expanding with action 0(Initial full=-9.965, G=-9.965 H=0.000)\n",
      "2025-06-17 18:28:24,037 - INFO - from node 53 -> Child Node 57, expanding with action 1(Initial full=-9.973, G=-9.973 H=0.000)\n",
      "2025-06-17 18:28:24,049 - INFO - from node 53 -> Child Node 58, expanding with action 2(Initial full=-9.971, G=-9.971 H=0.000)\n",
      "2025-06-17 18:28:24,063 - INFO - from node 53 -> Child Node 51, expanding with action 9(Initial full=-9.957, G=-9.957 H=0.000)\n",
      "2025-06-17 18:28:24,072 - INFO - from node 53 -> Child Node 53, expanding with action 12(Initial full=-9.990, G=-9.990 H=0.000)\n",
      "2025-06-17 18:28:24,121 - INFO - Root node children stats: [('a', 0, 'child id', 33, 'N', 0, 'T', 0, 'efe_av', -9.96), ('a', 1, 'child id', 57, 'N', 0, 'T', 0, 'efe_av', -9.97), ('a', 2, 'child id', 58, 'N', 0, 'T', 0, 'efe_av', -9.97), ('a', 9, 'child id', 51, 'N', 0, 'T', 0, 'efe_av', -9.96), ('a', 12, 'child id', 53, 'N', 0, 'T', 0, 'efe_av', -9.99)]\n",
      "2025-06-17 18:28:24,122 - INFO - --- Simulation 2/30 ---\n",
      "2025-06-17 18:28:24,123 - INFO - --- Selection Phase End (Selected Node: 33) ---\n",
      "2025-06-17 18:28:24,132 - INFO - from node 33 -> Child Node 5, expanding with action 0(Initial full=-9.936, G=-9.936 H=0.000)\n",
      "2025-06-17 18:28:24,143 - INFO - from node 33 -> Child Node 18, expanding with action 1(Initial full=-9.935, G=-9.935 H=0.000)\n",
      "2025-06-17 18:28:24,155 - INFO - from node 33 -> Child Node 59, expanding with action 2(Initial full=-9.937, G=-9.937 H=0.000)\n",
      "2025-06-17 18:28:24,168 - INFO - from node 33 -> Child Node 60, expanding with action 3(Initial full=-9.939, G=-9.939 H=0.000)\n",
      "2025-06-17 18:28:24,181 - INFO - from node 33 -> Child Node 57, expanding with action 4(Initial full=-9.931, G=-9.931 H=0.000)\n",
      "2025-06-17 18:28:24,229 - INFO - from node 33 -> Child Node 20, expanding with action 9(Initial full=-9.936, G=-9.936 H=0.000)\n",
      "2025-06-17 18:28:24,245 - INFO - from node 33 -> Child Node 4, expanding with action 11(Initial full=-9.934, G=-9.934 H=0.000)\n",
      "2025-06-17 18:28:24,252 - INFO - from node 33 -> Child Node 33, expanding with action 12(Initial full=-9.965, G=-9.965 H=0.000)\n",
      "2025-06-17 18:28:24,316 - INFO - Root node children stats: [('a', 0, 'child id', 33, 'N', 1, 'T', -19.9, 'efe_av', -19.9), ('a', 1, 'child id', 57, 'N', 0, 'T', 0, 'efe_av', -9.93), ('a', 2, 'child id', 58, 'N', 0, 'T', 0, 'efe_av', -9.97), ('a', 9, 'child id', 51, 'N', 0, 'T', 0, 'efe_av', -9.96), ('a', 12, 'child id', 53, 'N', 0, 'T', 0, 'efe_av', -9.99)]\n",
      "2025-06-17 18:28:24,318 - INFO - --- Simulation 3/30 ---\n",
      "2025-06-17 18:28:24,318 - INFO - --- Selection Phase End (Selected Node: 57) ---\n",
      "2025-06-17 18:28:24,331 - INFO - from node 57 -> Child Node 59, expanding with action 0(Initial full=-9.729, G=-9.729 H=0.000)\n",
      "2025-06-17 18:28:24,350 - INFO - from node 57 -> Child Node 60, expanding with action 2(Initial full=-9.909, G=-9.909 H=0.000)\n",
      "2025-06-17 18:28:24,362 - INFO - from node 57 -> Child Node 61, expanding with action 3(Initial full=-9.844, G=-9.844 H=0.000)\n",
      "2025-06-17 18:28:24,382 - INFO - from node 57 -> Child Node 58, expanding with action 5(Initial full=-9.960, G=-9.960 H=0.000)\n",
      "2025-06-17 18:28:24,422 - INFO - from node 57 -> Child Node 33, expanding with action 10(Initial full=-9.953, G=-9.953 H=0.000)\n",
      "2025-06-17 18:28:24,437 - INFO - from node 57 -> Child Node 57, expanding with action 12(Initial full=-9.931, G=-9.973 H=0.000)\n",
      "2025-06-17 18:28:24,500 - INFO - Root node children stats: [('a', 0, 'child id', 33, 'N', 1, 'T', -19.9, 'efe_av', -19.9), ('a', 1, 'child id', 57, 'N', 1, 'T', -19.66, 'efe_av', -19.66), ('a', 2, 'child id', 58, 'N', 0, 'T', 0, 'efe_av', -9.96), ('a', 9, 'child id', 51, 'N', 0, 'T', 0, 'efe_av', -9.96), ('a', 12, 'child id', 53, 'N', 0, 'T', 0, 'efe_av', -9.99)]\n",
      "2025-06-17 18:28:24,502 - INFO - --- Simulation 4/30 ---\n",
      "2025-06-17 18:28:24,503 - INFO - --- Selection Phase End (Selected Node: 58) ---\n",
      "2025-06-17 18:28:24,514 - INFO - from node 58 -> Child Node 60, expanding with action 0(Initial full=-9.884, G=-9.884 H=0.000)\n",
      "2025-06-17 18:28:24,534 - INFO - from node 58 -> Child Node 61, expanding with action 2(Initial full=-9.844, G=-9.897 H=0.000)\n",
      "2025-06-17 18:28:24,604 - INFO - from node 58 -> Child Node 57, expanding with action 11(Initial full=-9.931, G=-9.946 H=0.000)\n",
      "2025-06-17 18:28:24,611 - INFO - from node 58 -> Child Node 58, expanding with action 12(Initial full=-9.960, G=-9.971 H=0.000)\n",
      "2025-06-17 18:28:24,650 - INFO - Root node children stats: [('a', 0, 'child id', 33, 'N', 1, 'T', -19.9, 'efe_av', -19.9), ('a', 1, 'child id', 57, 'N', 1, 'T', -19.66, 'efe_av', -19.66), ('a', 2, 'child id', 58, 'N', 1, 'T', -19.84, 'efe_av', -19.84), ('a', 9, 'child id', 51, 'N', 0, 'T', 0, 'efe_av', -9.96), ('a', 12, 'child id', 53, 'N', 0, 'T', 0, 'efe_av', -9.99)]\n",
      "2025-06-17 18:28:24,651 - INFO - --- Simulation 5/30 ---\n",
      "2025-06-17 18:28:24,653 - INFO - --- Selection Phase End (Selected Node: 51) ---\n",
      "2025-06-17 18:28:24,662 - INFO - from node 51 -> Child Node 20, expanding with action 0(Initial full=-9.908, G=-9.908 H=0.000)\n",
      "2025-06-17 18:28:24,699 - INFO - from node 51 -> Child Node 25, expanding with action 5(Initial full=-9.943, G=-9.943 H=0.000)\n",
      "2025-06-17 18:28:24,708 - INFO - from node 51 -> Child Node 25, expanding with action 6(Initial full=-9.915, G=-9.915 H=0.000)\n",
      "2025-06-17 18:28:24,716 - INFO - from node 51 -> Child Node 16, expanding with action 7(Initial full=-9.938, G=-9.938 H=0.000)\n",
      "2025-06-17 18:28:24,724 - INFO - from node 51 -> Child Node 27, expanding with action 8(Initial full=-9.927, G=-9.927 H=0.000)\n",
      "2025-06-17 18:28:24,732 - INFO - from node 51 -> Child Node 7, expanding with action 9(Initial full=-9.943, G=-9.943 H=0.000)\n",
      "2025-06-17 18:28:24,739 - INFO - from node 51 -> Child Node 6, expanding with action 10(Initial full=-9.926, G=-9.926 H=0.000)\n",
      "2025-06-17 18:28:24,755 - INFO - from node 51 -> Child Node 51, expanding with action 12(Initial full=-9.957, G=-9.957 H=0.000)\n",
      "2025-06-17 18:28:24,808 - INFO - Root node children stats: [('a', 0, 'child id', 33, 'N', 1, 'T', -19.9, 'efe_av', -19.9), ('a', 1, 'child id', 57, 'N', 1, 'T', -19.66, 'efe_av', -19.66), ('a', 2, 'child id', 58, 'N', 1, 'T', -19.84, 'efe_av', -19.84), ('a', 9, 'child id', 51, 'N', 1, 'T', -19.87, 'efe_av', -19.87), ('a', 12, 'child id', 53, 'N', 0, 'T', 0, 'efe_av', -9.99)]\n",
      "2025-06-17 18:28:24,809 - INFO - --- Simulation 6/30 ---\n",
      "2025-06-17 18:28:24,811 - INFO - --- Selection Phase End (Selected Node: 53) ---\n",
      "2025-06-17 18:28:24,820 - INFO - from node 53 -> Child Node 33, expanding with action 0(Initial full=-9.953, G=-9.965 H=0.000)\n",
      "2025-06-17 18:28:24,831 - INFO - from node 53 -> Child Node 57, expanding with action 1(Initial full=-9.931, G=-9.973 H=0.000)\n",
      "2025-06-17 18:28:24,843 - INFO - from node 53 -> Child Node 58, expanding with action 2(Initial full=-9.960, G=-9.971 H=0.000)\n",
      "2025-06-17 18:28:24,880 - INFO - from node 53 -> Child Node 25, expanding with action 7(Initial full=-9.915, G=-9.954 H=0.000)\n",
      "2025-06-17 18:28:24,887 - INFO - from node 53 -> Child Node 16, expanding with action 8(Initial full=-9.938, G=-9.952 H=0.000)\n",
      "2025-06-17 18:28:24,898 - INFO - from node 53 -> Child Node 51, expanding with action 9(Initial full=-9.957, G=-9.957 H=0.000)\n",
      "2025-06-17 18:28:24,964 - INFO - Root node children stats: [('a', 0, 'child id', 33, 'N', 1, 'T', -19.9, 'efe_av', -19.9), ('a', 1, 'child id', 57, 'N', 1, 'T', -19.66, 'efe_av', -19.66), ('a', 2, 'child id', 58, 'N', 1, 'T', -19.84, 'efe_av', -19.84), ('a', 9, 'child id', 51, 'N', 1, 'T', -19.87, 'efe_av', -19.87), ('a', 12, 'child id', 53, 'N', 1, 'T', -19.94, 'efe_av', -19.94)]\n",
      "2025-06-17 18:28:24,965 - INFO - --- Simulation 7/30 ---\n",
      "2025-06-17 18:28:24,966 - INFO - --- Selection Phase End (Selected Node: 59) ---\n",
      "2025-06-17 18:28:24,973 - INFO - from node 59 -> Child Node 18, expanding with action 0(Initial full=-9.911, G=-9.911 H=0.000)\n",
      "2025-06-17 18:28:24,988 - INFO - from node 59 -> Child Node 19, expanding with action 2(Initial full=-9.912, G=-9.912 H=0.000)\n",
      "2025-06-17 18:28:25,008 - INFO - from node 59 -> Child Node 60, expanding with action 4(Initial full=-9.884, G=-9.916 H=0.000)\n",
      "2025-06-17 18:28:25,038 - INFO - from node 59 -> Child Node 33, expanding with action 8(Initial full=-9.930, G=-9.930 H=0.000)\n",
      "2025-06-17 18:28:25,060 - INFO - from node 59 -> Child Node 5, expanding with action 11(Initial full=-9.908, G=-9.908 H=0.000)\n",
      "2025-06-17 18:28:25,066 - INFO - from node 59 -> Child Node 59, expanding with action 12(Initial full=-9.729, G=-9.937 H=0.000)\n",
      "2025-06-17 18:28:25,109 - INFO - Root node children stats: [('a', 0, 'child id', 33, 'N', 2, 'T', -39.53, 'efe_av', -19.77), ('a', 1, 'child id', 57, 'N', 1, 'T', -19.66, 'efe_av', -19.66), ('a', 2, 'child id', 58, 'N', 1, 'T', -19.84, 'efe_av', -19.84), ('a', 9, 'child id', 51, 'N', 1, 'T', -19.87, 'efe_av', -19.87), ('a', 12, 'child id', 53, 'N', 1, 'T', -19.94, 'efe_av', -19.94)]\n",
      "2025-06-17 18:28:25,110 - INFO - --- Simulation 8/30 ---\n",
      "2025-06-17 18:28:25,111 - INFO - --- Selection Phase End (Selected Node: 60) ---\n",
      "2025-06-17 18:28:25,119 - INFO - from node 60 -> Child Node 19, expanding with action 0(Initial full=-9.906, G=-9.906 H=0.000)\n",
      "2025-06-17 18:28:25,160 - INFO - from node 60 -> Child Node 61, expanding with action 5(Initial full=-9.844, G=-9.937 H=0.000)\n",
      "2025-06-17 18:28:25,171 - INFO - from node 60 -> Child Node 58, expanding with action 6(Initial full=-9.922, G=-9.922 H=0.000)\n",
      "2025-06-17 18:28:25,194 - INFO - from node 60 -> Child Node 33, expanding with action 9(Initial full=-9.919, G=-9.919 H=0.000)\n",
      "2025-06-17 18:28:25,205 - INFO - from node 60 -> Child Node 59, expanding with action 10(Initial full=-9.729, G=-9.912 H=0.000)\n",
      "2025-06-17 18:28:25,213 - INFO - from node 60 -> Child Node 18, expanding with action 11(Initial full=-9.904, G=-9.904 H=0.000)\n",
      "2025-06-17 18:28:25,219 - INFO - from node 60 -> Child Node 60, expanding with action 12(Initial full=-9.884, G=-9.939 H=0.000)\n",
      "2025-06-17 18:28:25,274 - INFO - Root node children stats: [('a', 0, 'child id', 33, 'N', 3, 'T', -59.32, 'efe_av', -19.77), ('a', 1, 'child id', 57, 'N', 1, 'T', -19.66, 'efe_av', -19.66), ('a', 2, 'child id', 58, 'N', 1, 'T', -19.84, 'efe_av', -19.84), ('a', 9, 'child id', 51, 'N', 1, 'T', -19.87, 'efe_av', -19.87), ('a', 12, 'child id', 53, 'N', 1, 'T', -19.94, 'efe_av', -19.94)]\n",
      "2025-06-17 18:28:25,276 - INFO - --- Simulation 9/30 ---\n",
      "2025-06-17 18:28:25,277 - INFO - --- Selection Phase End (Selected Node: 61) ---\n",
      "2025-06-17 18:28:25,354 - INFO - from node 61 -> Child Node 58, expanding with action 8(Initial full=-9.910, G=-9.910 H=0.000)\n",
      "2025-06-17 18:28:25,379 - INFO - from node 61 -> Child Node 60, expanding with action 11(Initial full=-9.833, G=-9.833 H=0.000)\n",
      "2025-06-17 18:28:25,386 - INFO - from node 61 -> Child Node 61, expanding with action 12(Initial full=-9.844, G=-9.844 H=0.000)\n",
      "2025-06-17 18:28:25,412 - INFO - Root node children stats: [('a', 0, 'child id', 33, 'N', 3, 'T', -59.32, 'efe_av', -19.77), ('a', 1, 'child id', 57, 'N', 2, 'T', -39.34, 'efe_av', -19.67), ('a', 2, 'child id', 58, 'N', 1, 'T', -19.84, 'efe_av', -19.84), ('a', 9, 'child id', 51, 'N', 1, 'T', -19.87, 'efe_av', -19.87), ('a', 12, 'child id', 53, 'N', 1, 'T', -19.94, 'efe_av', -19.94)]\n",
      "2025-06-17 18:28:25,414 - INFO - --- Simulation 10/30 ---\n",
      "2025-06-17 18:28:25,415 - INFO - --- Selection Phase End (Selected Node: 18) ---\n",
      "2025-06-17 18:28:25,450 - INFO - from node 18 -> Child Node 19, expanding with action 3(Initial full=-9.900, G=-9.900 H=0.000)\n",
      "2025-06-17 18:28:25,471 - INFO - from node 18 -> Child Node 60, expanding with action 5(Initial full=-9.833, G=-9.934 H=0.000)\n",
      "2025-06-17 18:28:25,489 - INFO - from node 18 -> Child Node 33, expanding with action 7(Initial full=-9.919, G=-9.921 H=0.000)\n",
      "2025-06-17 18:28:25,504 - INFO - from node 18 -> Child Node 5, expanding with action 9(Initial full=-9.908, G=-9.923 H=0.000)\n",
      "2025-06-17 18:28:25,526 - INFO - from node 18 -> Child Node 62, expanding with action 11(Initial full=-9.916, G=-9.916 H=0.000)\n",
      "2025-06-17 18:28:25,533 - INFO - from node 18 -> Child Node 18, expanding with action 12(Initial full=-9.904, G=-9.935 H=0.000)\n",
      "2025-06-17 18:28:25,581 - INFO - Root node children stats: [('a', 0, 'child id', 33, 'N', 4, 'T', -79.12, 'efe_av', -19.78), ('a', 1, 'child id', 57, 'N', 2, 'T', -39.34, 'efe_av', -19.67), ('a', 2, 'child id', 58, 'N', 1, 'T', -19.84, 'efe_av', -19.84), ('a', 9, 'child id', 51, 'N', 1, 'T', -19.87, 'efe_av', -19.87), ('a', 12, 'child id', 53, 'N', 1, 'T', -19.94, 'efe_av', -19.94)]\n",
      "2025-06-17 18:28:25,582 - INFO - --- Simulation 11/30 ---\n",
      "2025-06-17 18:28:25,584 - INFO - --- Selection Phase End (Selected Node: 19) ---\n",
      "2025-06-17 18:28:25,658 - INFO - from node 19 -> Child Node 59, expanding with action 8(Initial full=-9.729, G=-9.924 H=0.000)\n",
      "2025-06-17 18:28:25,667 - INFO - from node 19 -> Child Node 18, expanding with action 9(Initial full=-9.899, G=-9.899 H=0.000)\n",
      "2025-06-17 18:28:25,680 - INFO - from node 19 -> Child Node 62, expanding with action 10(Initial full=-9.892, G=-9.892 H=0.000)\n",
      "2025-06-17 18:28:25,695 - INFO - from node 19 -> Child Node 19, expanding with action 12(Initial full=-9.900, G=-9.912 H=0.000)\n",
      "2025-06-17 18:28:25,732 - INFO - Root node children stats: [('a', 0, 'child id', 33, 'N', 5, 'T', -98.92, 'efe_av', -19.78), ('a', 1, 'child id', 57, 'N', 2, 'T', -39.34, 'efe_av', -19.67), ('a', 2, 'child id', 58, 'N', 1, 'T', -19.84, 'efe_av', -19.84), ('a', 9, 'child id', 51, 'N', 1, 'T', -19.87, 'efe_av', -19.87), ('a', 12, 'child id', 53, 'N', 1, 'T', -19.94, 'efe_av', -19.94)]\n",
      "2025-06-17 18:28:25,733 - INFO - --- Simulation 12/30 ---\n",
      "2025-06-17 18:28:25,734 - INFO - --- Selection Phase End (Selected Node: 5) ---\n",
      "2025-06-17 18:28:25,745 - INFO - from node 5 -> Child Node 42, expanding with action 0(Initial full=-9.832, G=-9.832 H=0.000)\n",
      "2025-06-17 18:28:25,757 - INFO - from node 5 -> Child Node 62, expanding with action 1(Initial full=-9.884, G=-9.884 H=0.000)\n",
      "2025-06-17 18:28:25,788 - INFO - from node 5 -> Child Node 59, expanding with action 5(Initial full=-9.729, G=-9.924 H=0.000)\n",
      "2025-06-17 18:28:25,798 - INFO - from node 5 -> Child Node 33, expanding with action 6(Initial full=-9.919, G=-9.930 H=0.000)\n",
      "2025-06-17 18:28:25,806 - INFO - from node 5 -> Child Node 20, expanding with action 7(Initial full=-9.908, G=-9.915 H=0.000)\n",
      "2025-06-17 18:28:25,814 - INFO - from node 5 -> Child Node 4, expanding with action 8(Initial full=-9.934, G=-9.948 H=0.000)\n",
      "2025-06-17 18:28:25,822 - INFO - from node 5 -> Child Node 17, expanding with action 9(Initial full=-9.905, G=-9.905 H=0.000)\n",
      "2025-06-17 18:28:25,831 - INFO - from node 5 -> Child Node 23, expanding with action 10(Initial full=-9.881, G=-9.881 H=0.000)\n",
      "2025-06-17 18:28:25,846 - INFO - from node 5 -> Child Node 5, expanding with action 12(Initial full=-9.908, G=-9.936 H=0.000)\n",
      "2025-06-17 18:28:25,917 - INFO - Root node children stats: [('a', 0, 'child id', 33, 'N', 6, 'T', -118.66, 'efe_av', -19.78), ('a', 1, 'child id', 57, 'N', 2, 'T', -39.34, 'efe_av', -19.67), ('a', 2, 'child id', 58, 'N', 1, 'T', -19.84, 'efe_av', -19.84), ('a', 9, 'child id', 51, 'N', 1, 'T', -19.87, 'efe_av', -19.87), ('a', 12, 'child id', 53, 'N', 1, 'T', -19.94, 'efe_av', -19.94)]\n",
      "2025-06-17 18:28:25,918 - INFO - --- Simulation 13/30 ---\n",
      "2025-06-17 18:28:25,919 - INFO - --- Selection Phase End (Selected Node: 62) ---\n",
      "2025-06-17 18:28:25,959 - INFO - from node 62 -> Child Node 19, expanding with action 4(Initial full=-9.853, G=-9.853 H=0.000)\n",
      "2025-06-17 18:28:25,977 - INFO - from node 62 -> Child Node 5, expanding with action 7(Initial full=-9.908, G=-9.909 H=0.000)\n",
      "2025-06-17 18:28:25,997 - INFO - from node 62 -> Child Node 23, expanding with action 9(Initial full=-9.881, G=-9.888 H=0.000)\n",
      "2025-06-17 18:28:26,013 - INFO - from node 62 -> Child Node 42, expanding with action 10(Initial full=-9.832, G=-9.849 H=0.000)\n",
      "2025-06-17 18:28:26,030 - INFO - from node 62 -> Child Node 62, expanding with action 12(Initial full=-9.884, G=-9.916 H=0.000)\n",
      "2025-06-17 18:28:26,064 - INFO - Root node children stats: [('a', 0, 'child id', 33, 'N', 7, 'T', -138.39, 'efe_av', -19.77), ('a', 1, 'child id', 57, 'N', 2, 'T', -39.34, 'efe_av', -19.67), ('a', 2, 'child id', 58, 'N', 1, 'T', -19.84, 'efe_av', -19.84), ('a', 9, 'child id', 51, 'N', 1, 'T', -19.87, 'efe_av', -19.87), ('a', 12, 'child id', 53, 'N', 1, 'T', -19.94, 'efe_av', -19.94)]\n",
      "2025-06-17 18:28:26,065 - INFO - --- Simulation 14/30 ---\n",
      "2025-06-17 18:28:26,066 - INFO - --- Selection Phase End (Selected Node: 42) ---\n",
      "2025-06-17 18:28:26,109 - INFO - from node 42 -> Child Node 62, expanding with action 4(Initial full=-9.749, G=-9.749 H=0.000)\n",
      "2025-06-17 18:28:26,132 - INFO - from node 42 -> Child Node 23, expanding with action 8(Initial full=-9.881, G=-9.907 H=0.000)\n",
      "2025-06-17 18:28:26,161 - INFO - from node 42 -> Child Node 42, expanding with action 12(Initial full=-9.832, G=-9.832 H=0.000)\n",
      "2025-06-17 18:28:26,186 - INFO - Root node children stats: [('a', 0, 'child id', 33, 'N', 8, 'T', -157.97, 'efe_av', -19.75), ('a', 1, 'child id', 57, 'N', 2, 'T', -39.34, 'efe_av', -19.67), ('a', 2, 'child id', 58, 'N', 1, 'T', -19.84, 'efe_av', -19.84), ('a', 9, 'child id', 51, 'N', 1, 'T', -19.87, 'efe_av', -19.87), ('a', 12, 'child id', 53, 'N', 1, 'T', -19.94, 'efe_av', -19.94)]\n",
      "2025-06-17 18:28:26,187 - INFO - --- Simulation 15/30 ---\n",
      "2025-06-17 18:28:26,188 - INFO - --- Selection Phase End (Selected Node: 20) ---\n",
      "2025-06-17 18:28:26,195 - INFO - from node 20 -> Child Node 4, expanding with action 0(Initial full=-9.900, G=-9.900 H=0.000)\n",
      "2025-06-17 18:28:26,216 - INFO - from node 20 -> Child Node 33, expanding with action 3(Initial full=-9.919, G=-9.920 H=0.000)\n",
      "2025-06-17 18:28:26,242 - INFO - from node 20 -> Child Node 51, expanding with action 6(Initial full=-9.915, G=-9.915 H=0.000)\n",
      "2025-06-17 18:28:26,258 - INFO - from node 20 -> Child Node 6, expanding with action 8(Initial full=-9.926, G=-9.932 H=0.000)\n",
      "2025-06-17 18:28:26,266 - INFO - from node 20 -> Child Node 0, expanding with action 9(Initial full=-9.917, G=-9.917 H=0.000)\n",
      "2025-06-17 18:28:26,272 - INFO - from node 20 -> Child Node 3, expanding with action 10(Initial full=-9.906, G=-9.906 H=0.000)\n",
      "2025-06-17 18:28:26,285 - INFO - from node 20 -> Child Node 17, expanding with action 11(Initial full=-9.900, G=-9.900 H=0.000)\n",
      "2025-06-17 18:28:26,294 - INFO - from node 20 -> Child Node 20, expanding with action 12(Initial full=-9.908, G=-9.936 H=0.000)\n",
      "2025-06-17 18:28:26,353 - INFO - Root node children stats: [('a', 0, 'child id', 33, 'N', 9, 'T', -177.78, 'efe_av', -19.75), ('a', 1, 'child id', 57, 'N', 2, 'T', -39.34, 'efe_av', -19.67), ('a', 2, 'child id', 58, 'N', 1, 'T', -19.84, 'efe_av', -19.84), ('a', 9, 'child id', 51, 'N', 1, 'T', -19.87, 'efe_av', -19.87), ('a', 12, 'child id', 53, 'N', 1, 'T', -19.94, 'efe_av', -19.94)]\n",
      "2025-06-17 18:28:26,355 - INFO - --- Simulation 16/30 ---\n",
      "2025-06-17 18:28:26,356 - INFO - --- Selection Phase End (Selected Node: 4) ---\n",
      "2025-06-17 18:28:26,366 - INFO - from node 4 -> Child Node 23, expanding with action 0(Initial full=-9.881, G=-9.888 H=0.000)\n",
      "2025-06-17 18:28:26,408 - INFO - from node 4 -> Child Node 33, expanding with action 5(Initial full=-9.919, G=-9.933 H=0.000)\n",
      "2025-06-17 18:28:26,419 - INFO - from node 4 -> Child Node 20, expanding with action 6(Initial full=-9.908, G=-9.922 H=0.000)\n",
      "2025-06-17 18:28:26,435 - INFO - from node 4 -> Child Node 3, expanding with action 8(Initial full=-9.906, G=-9.939 H=0.000)\n",
      "2025-06-17 18:28:26,443 - INFO - from node 4 -> Child Node 1, expanding with action 9(Initial full=-9.913, G=-9.913 H=0.000)\n",
      "2025-06-17 18:28:26,452 - INFO - from node 4 -> Child Node 17, expanding with action 10(Initial full=-9.886, G=-9.886 H=0.000)\n",
      "2025-06-17 18:28:26,476 - INFO - from node 4 -> Child Node 4, expanding with action 12(Initial full=-9.900, G=-9.934 H=0.000)\n",
      "2025-06-17 18:28:26,528 - INFO - Root node children stats: [('a', 0, 'child id', 33, 'N', 10, 'T', -197.56, 'efe_av', -19.76), ('a', 1, 'child id', 57, 'N', 2, 'T', -39.34, 'efe_av', -19.67), ('a', 2, 'child id', 58, 'N', 1, 'T', -19.84, 'efe_av', -19.84), ('a', 9, 'child id', 51, 'N', 1, 'T', -19.87, 'efe_av', -19.87), ('a', 12, 'child id', 53, 'N', 1, 'T', -19.94, 'efe_av', -19.94)]\n",
      "2025-06-17 18:28:26,530 - INFO - --- Simulation 17/30 ---\n",
      "2025-06-17 18:28:26,531 - INFO - --- Selection Phase End (Selected Node: 17) ---\n",
      "2025-06-17 18:28:26,550 - INFO - from node 17 -> Child Node 23, expanding with action 1(Initial full=-9.880, G=-9.880 H=0.000)\n",
      "2025-06-17 18:28:26,578 - INFO - from node 17 -> Child Node 4, expanding with action 4(Initial full=-9.898, G=-9.898 H=0.000)\n",
      "2025-06-17 18:28:26,587 - INFO - from node 17 -> Child Node 20, expanding with action 5(Initial full=-9.908, G=-9.924 H=0.000)\n",
      "2025-06-17 18:28:26,595 - INFO - from node 17 -> Child Node 3, expanding with action 6(Initial full=-9.906, G=-9.912 H=0.000)\n",
      "2025-06-17 18:28:26,602 - INFO - from node 17 -> Child Node 0, expanding with action 7(Initial full=-9.917, G=-9.917 H=0.000)\n",
      "2025-06-17 18:28:26,611 - INFO - from node 17 -> Child Node 1, expanding with action 8(Initial full=-9.903, G=-9.903 H=0.000)\n",
      "2025-06-17 18:28:26,627 - INFO - from node 17 -> Child Node 2, expanding with action 10(Initial full=-9.858, G=-9.858 H=0.000)\n",
      "2025-06-17 18:28:26,641 - INFO - from node 17 -> Child Node 17, expanding with action 12(Initial full=-9.886, G=-9.905 H=0.000)\n",
      "2025-06-17 18:28:26,694 - INFO - Root node children stats: [('a', 0, 'child id', 33, 'N', 11, 'T', -217.31, 'efe_av', -19.76), ('a', 1, 'child id', 57, 'N', 2, 'T', -39.34, 'efe_av', -19.67), ('a', 2, 'child id', 58, 'N', 1, 'T', -19.84, 'efe_av', -19.84), ('a', 9, 'child id', 51, 'N', 1, 'T', -19.87, 'efe_av', -19.87), ('a', 12, 'child id', 53, 'N', 1, 'T', -19.94, 'efe_av', -19.94)]\n",
      "2025-06-17 18:28:26,695 - INFO - --- Simulation 18/30 ---\n",
      "2025-06-17 18:28:26,696 - INFO - --- Selection Phase End (Selected Node: 23) ---\n",
      "2025-06-17 18:28:26,721 - INFO - from node 23 -> Child Node 42, expanding with action 2(Initial full=-9.832, G=-9.889 H=0.000)\n",
      "2025-06-17 18:28:26,734 - INFO - from node 23 -> Child Node 62, expanding with action 3(Initial full=-9.749, G=-9.841 H=0.000)\n",
      "2025-06-17 18:28:26,748 - INFO - from node 23 -> Child Node 4, expanding with action 5(Initial full=-9.898, G=-9.916 H=0.000)\n",
      "2025-06-17 18:28:26,756 - INFO - from node 23 -> Child Node 4, expanding with action 6(Initial full=-9.898, G=-9.909 H=0.000)\n",
      "2025-06-17 18:28:26,767 - INFO - from node 23 -> Child Node 17, expanding with action 7(Initial full=-9.886, G=-9.903 H=0.000)\n",
      "2025-06-17 18:28:26,775 - INFO - from node 23 -> Child Node 2, expanding with action 8(Initial full=-9.858, G=-9.932 H=0.000)\n",
      "2025-06-17 18:28:26,786 - INFO - from node 23 -> Child Node 2, expanding with action 9(Initial full=-9.858, G=-9.892 H=0.000)\n",
      "2025-06-17 18:28:26,813 - INFO - from node 23 -> Child Node 23, expanding with action 12(Initial full=-9.880, G=-9.881 H=0.000)\n",
      "2025-06-17 18:28:26,870 - INFO - Root node children stats: [('a', 0, 'child id', 33, 'N', 12, 'T', -237.03, 'efe_av', -19.75), ('a', 1, 'child id', 57, 'N', 2, 'T', -39.34, 'efe_av', -19.67), ('a', 2, 'child id', 58, 'N', 1, 'T', -19.84, 'efe_av', -19.84), ('a', 9, 'child id', 51, 'N', 1, 'T', -19.87, 'efe_av', -19.87), ('a', 12, 'child id', 53, 'N', 1, 'T', -19.94, 'efe_av', -19.94)]\n",
      "2025-06-17 18:28:26,871 - INFO - --- Simulation 19/30 ---\n",
      "2025-06-17 18:28:26,873 - INFO - --- Selection Phase End (Selected Node: 2) ---\n",
      "2025-06-17 18:28:26,904 - INFO - from node 2 -> Child Node 17, expanding with action 4(Initial full=-9.850, G=-9.850 H=0.000)\n",
      "2025-06-17 18:28:26,911 - INFO - from node 2 -> Child Node 3, expanding with action 5(Initial full=-9.882, G=-9.882 H=0.000)\n",
      "2025-06-17 18:28:26,918 - INFO - from node 2 -> Child Node 1, expanding with action 6(Initial full=-9.880, G=-9.880 H=0.000)\n",
      "2025-06-17 18:28:26,934 - INFO - from node 2 -> Child Node 21, expanding with action 8(Initial full=-9.879, G=-9.879 H=0.000)\n",
      "2025-06-17 18:28:26,943 - INFO - from node 2 -> Child Node 24, expanding with action 9(Initial full=-7.567, G=-7.567 H=0.000)\n",
      "2025-06-17 18:28:26,953 - INFO - from node 2 -> Child Node 37, expanding with action 10(Initial full=-9.610, G=-9.610 H=0.000)\n",
      "2025-06-17 18:28:26,963 - INFO - from node 2 -> Child Node 38, expanding with action 11(Initial full=-9.583, G=-9.583 H=0.000)\n",
      "2025-06-17 18:28:26,970 - INFO - from node 2 -> Child Node 2, expanding with action 12(Initial full=-9.858, G=-9.858 H=0.000)\n",
      "2025-06-17 18:28:27,025 - INFO - Root node children stats: [('a', 0, 'child id', 33, 'N', 13, 'T', -254.45, 'efe_av', -19.57), ('a', 1, 'child id', 57, 'N', 2, 'T', -39.34, 'efe_av', -19.67), ('a', 2, 'child id', 58, 'N', 1, 'T', -19.84, 'efe_av', -19.84), ('a', 9, 'child id', 51, 'N', 1, 'T', -19.87, 'efe_av', -19.87), ('a', 12, 'child id', 53, 'N', 1, 'T', -19.94, 'efe_av', -19.94)]\n",
      "2025-06-17 18:28:27,026 - INFO - --- Simulation 20/30 ---\n",
      "2025-06-17 18:28:27,028 - INFO - --- Selection Phase End (Selected Node: 3) ---\n",
      "2025-06-17 18:28:27,036 - INFO - from node 3 -> Child Node 17, expanding with action 0(Initial full=-9.850, G=-9.875 H=0.000)\n",
      "2025-06-17 18:28:27,064 - INFO - from node 3 -> Child Node 20, expanding with action 4(Initial full=-9.886, G=-9.886 H=0.000)\n",
      "2025-06-17 18:28:27,079 - INFO - from node 3 -> Child Node 6, expanding with action 6(Initial full=-9.896, G=-9.896 H=0.000)\n",
      "2025-06-17 18:28:27,093 - INFO - from node 3 -> Child Node 0, expanding with action 8(Initial full=-9.917, G=-9.925 H=0.000)\n",
      "2025-06-17 18:28:27,108 - INFO - from node 3 -> Child Node 1, expanding with action 10(Initial full=-9.880, G=-9.893 H=0.000)\n",
      "2025-06-17 18:28:27,115 - INFO - from node 3 -> Child Node 2, expanding with action 11(Initial full=-9.858, G=-9.873 H=0.000)\n",
      "2025-06-17 18:28:27,121 - INFO - from node 3 -> Child Node 3, expanding with action 12(Initial full=-9.882, G=-9.906 H=0.000)\n",
      "2025-06-17 18:28:27,162 - INFO - Root node children stats: [('a', 0, 'child id', 33, 'N', 14, 'T', -274.21, 'efe_av', -19.59), ('a', 1, 'child id', 57, 'N', 2, 'T', -39.34, 'efe_av', -19.67), ('a', 2, 'child id', 58, 'N', 1, 'T', -19.84, 'efe_av', -19.84), ('a', 9, 'child id', 51, 'N', 1, 'T', -19.87, 'efe_av', -19.87), ('a', 12, 'child id', 53, 'N', 1, 'T', -19.94, 'efe_av', -19.94)]\n",
      "2025-06-17 18:28:27,163 - INFO - --- Simulation 21/30 ---\n",
      "2025-06-17 18:28:27,165 - INFO - --- Selection Phase End (Selected Node: 1) ---\n",
      "2025-06-17 18:28:27,171 - INFO - from node 1 -> Child Node 2, expanding with action 0(Initial full=-9.837, G=-9.837 H=0.000)\n",
      "2025-06-17 18:28:27,192 - INFO - from node 1 -> Child Node 17, expanding with action 2(Initial full=-9.847, G=-9.847 H=0.000)\n",
      "2025-06-17 18:28:27,206 - INFO - from node 1 -> Child Node 3, expanding with action 4(Initial full=-9.882, G=-9.906 H=0.000)\n",
      "2025-06-17 18:28:27,221 - INFO - from node 1 -> Child Node 0, expanding with action 6(Initial full=-9.911, G=-9.911 H=0.000)\n",
      "2025-06-17 18:28:27,239 - INFO - from node 1 -> Child Node 12, expanding with action 8(Initial full=-9.916, G=-9.916 H=0.000)\n",
      "2025-06-17 18:28:27,247 - INFO - from node 1 -> Child Node 21, expanding with action 9(Initial full=-9.857, G=-9.857 H=0.000)\n",
      "2025-06-17 18:28:27,256 - INFO - from node 1 -> Child Node 24, expanding with action 10(Initial full=-7.567, G=-8.995 H=0.000)\n",
      "2025-06-17 18:28:27,273 - INFO - from node 1 -> Child Node 1, expanding with action 12(Initial full=-9.880, G=-9.913 H=0.000)\n",
      "2025-06-17 18:28:27,322 - INFO - Root node children stats: [('a', 0, 'child id', 33, 'N', 15, 'T', -293.08, 'efe_av', -19.54), ('a', 1, 'child id', 57, 'N', 2, 'T', -39.34, 'efe_av', -19.67), ('a', 2, 'child id', 58, 'N', 1, 'T', -19.84, 'efe_av', -19.84), ('a', 9, 'child id', 51, 'N', 1, 'T', -19.87, 'efe_av', -19.87), ('a', 12, 'child id', 53, 'N', 1, 'T', -19.94, 'efe_av', -19.94)]\n",
      "2025-06-17 18:28:27,323 - INFO - --- Simulation 22/30 ---\n",
      "2025-06-17 18:28:27,324 - INFO - --- Selection Phase End (Selected Node: 21) ---\n",
      "2025-06-17 18:28:27,348 - INFO - from node 21 -> Child Node 1, expanding with action 3(Initial full=-9.844, G=-9.844 H=0.000)\n",
      "2025-06-17 18:28:27,363 - INFO - from node 21 -> Child Node 0, expanding with action 5(Initial full=-9.911, G=-9.914 H=0.000)\n",
      "2025-06-17 18:28:27,372 - INFO - from node 21 -> Child Node 12, expanding with action 6(Initial full=-9.869, G=-9.869 H=0.000)\n",
      "2025-06-17 18:28:27,387 - INFO - from node 21 -> Child Node 13, expanding with action 8(Initial full=-9.884, G=-9.884 H=0.000)\n",
      "2025-06-17 18:28:27,396 - INFO - from node 21 -> Child Node 22, expanding with action 9(Initial full=-9.849, G=-9.849 H=0.000)\n",
      "2025-06-17 18:28:27,407 - INFO - from node 21 -> Child Node 32, expanding with action 10(Initial full=-9.062, G=-9.062 H=0.000)\n",
      "2025-06-17 18:28:27,416 - INFO - from node 21 -> Child Node 24, expanding with action 11(Initial full=-7.567, G=-8.009 H=0.000)\n",
      "2025-06-17 18:28:27,422 - INFO - from node 21 -> Child Node 21, expanding with action 12(Initial full=-9.857, G=-9.879 H=0.000)\n",
      "2025-06-17 18:28:27,472 - INFO - Root node children stats: [('a', 0, 'child id', 33, 'N', 16, 'T', -310.95, 'efe_av', -19.43), ('a', 1, 'child id', 57, 'N', 2, 'T', -39.34, 'efe_av', -19.67), ('a', 2, 'child id', 58, 'N', 1, 'T', -19.84, 'efe_av', -19.84), ('a', 9, 'child id', 51, 'N', 1, 'T', -19.87, 'efe_av', -19.87), ('a', 12, 'child id', 53, 'N', 1, 'T', -19.94, 'efe_av', -19.94)]\n",
      "2025-06-17 18:28:27,473 - INFO - --- Simulation 23/30 ---\n",
      "2025-06-17 18:28:27,475 - INFO - --- Selection Phase End (Selected Node: 6) ---\n",
      "2025-06-17 18:28:27,481 - INFO - from node 6 -> Child Node 3, expanding with action 0(Initial full=-9.730, G=-9.730 H=0.000)\n",
      "2025-06-17 18:28:27,510 - INFO - from node 6 -> Child Node 51, expanding with action 4(Initial full=-9.902, G=-9.902 H=0.000)\n",
      "2025-06-17 18:28:27,518 - INFO - from node 6 -> Child Node 7, expanding with action 5(Initial full=-9.941, G=-9.941 H=0.000)\n",
      "2025-06-17 18:28:27,527 - INFO - from node 6 -> Child Node 27, expanding with action 6(Initial full=-9.873, G=-9.873 H=0.000)\n",
      "2025-06-17 18:28:27,535 - INFO - from node 6 -> Child Node 26, expanding with action 7(Initial full=-9.930, G=-9.930 H=0.000)\n",
      "2025-06-17 18:28:27,542 - INFO - from node 6 -> Child Node 9, expanding with action 8(Initial full=-9.935, G=-9.935 H=0.000)\n",
      "2025-06-17 18:28:27,551 - INFO - from node 6 -> Child Node 8, expanding with action 9(Initial full=-9.904, G=-9.904 H=0.000)\n",
      "2025-06-17 18:28:27,559 - INFO - from node 6 -> Child Node 12, expanding with action 10(Initial full=-9.869, G=-9.875 H=0.000)\n",
      "2025-06-17 18:28:27,566 - INFO - from node 6 -> Child Node 0, expanding with action 11(Initial full=-9.889, G=-9.889 H=0.000)\n",
      "2025-06-17 18:28:27,572 - INFO - from node 6 -> Child Node 6, expanding with action 12(Initial full=-9.896, G=-9.926 H=0.000)\n",
      "2025-06-17 18:28:27,635 - INFO - Root node children stats: [('a', 0, 'child id', 33, 'N', 16, 'T', -310.95, 'efe_av', -19.43), ('a', 1, 'child id', 57, 'N', 2, 'T', -39.34, 'efe_av', -19.67), ('a', 2, 'child id', 58, 'N', 1, 'T', -19.84, 'efe_av', -19.84), ('a', 9, 'child id', 51, 'N', 2, 'T', -39.49, 'efe_av', -19.75), ('a', 12, 'child id', 53, 'N', 1, 'T', -19.94, 'efe_av', -19.94)]\n",
      "2025-06-17 18:28:27,636 - INFO - --- Simulation 24/30 ---\n",
      "2025-06-17 18:28:27,637 - INFO - --- Selection Phase End (Selected Node: 0) ---\n",
      "2025-06-17 18:28:27,644 - INFO - from node 0 -> Child Node 1, expanding with action 0(Initial full=-9.844, G=-9.879 H=0.000)\n",
      "2025-06-17 18:28:27,652 - INFO - from node 0 -> Child Node 17, expanding with action 1(Initial full=-9.847, G=-9.893 H=0.000)\n",
      "2025-06-17 18:28:27,659 - INFO - from node 0 -> Child Node 3, expanding with action 2(Initial full=-9.730, G=-9.888 H=0.000)\n",
      "2025-06-17 18:28:27,678 - INFO - from node 0 -> Child Node 6, expanding with action 5(Initial full=-9.896, G=-9.929 H=0.000)\n",
      "2025-06-17 18:28:27,687 - INFO - from node 0 -> Child Node 26, expanding with action 6(Initial full=-9.909, G=-9.909 H=0.000)\n",
      "2025-06-17 18:28:27,694 - INFO - from node 0 -> Child Node 8, expanding with action 7(Initial full=-9.904, G=-9.920 H=0.000)\n",
      "2025-06-17 18:28:27,703 - INFO - from node 0 -> Child Node 28, expanding with action 8(Initial full=-9.924, G=-9.924 H=0.000)\n",
      "2025-06-17 18:28:27,711 - INFO - from node 0 -> Child Node 12, expanding with action 9(Initial full=-9.869, G=-9.909 H=0.000)\n",
      "2025-06-17 18:28:27,728 - INFO - from node 0 -> Child Node 21, expanding with action 11(Initial full=-9.857, G=-9.883 H=0.000)\n",
      "2025-06-17 18:28:27,734 - INFO - from node 0 -> Child Node 0, expanding with action 12(Initial full=-9.889, G=-9.917 H=0.000)\n",
      "2025-06-17 18:28:27,797 - INFO - Root node children stats: [('a', 0, 'child id', 33, 'N', 17, 'T', -330.72, 'efe_av', -19.45), ('a', 1, 'child id', 57, 'N', 2, 'T', -39.34, 'efe_av', -19.67), ('a', 2, 'child id', 58, 'N', 1, 'T', -19.84, 'efe_av', -19.84), ('a', 9, 'child id', 51, 'N', 2, 'T', -39.49, 'efe_av', -19.75), ('a', 12, 'child id', 53, 'N', 1, 'T', -19.94, 'efe_av', -19.94)]\n",
      "2025-06-17 18:28:27,798 - INFO - --- Simulation 25/30 ---\n",
      "2025-06-17 18:28:27,800 - INFO - --- Selection Phase End (Selected Node: 24) ---\n",
      "2025-06-17 18:28:27,809 - INFO - from node 24 -> Child Node 37, expanding with action 0(Initial full=-9.563, G=-9.563 H=0.000)\n",
      "2025-06-17 18:28:27,818 - INFO - from node 24 -> Child Node 38, expanding with action 1(Initial full=-9.583, G=-9.741 H=0.000)\n",
      "2025-06-17 18:28:27,836 - INFO - from node 24 -> Child Node 1, expanding with action 4(Initial full=-9.844, G=-9.848 H=0.000)\n",
      "2025-06-17 18:28:27,845 - INFO - from node 24 -> Child Node 21, expanding with action 5(Initial full=-9.857, G=-9.901 H=0.000)\n",
      "2025-06-17 18:28:27,862 - INFO - from node 24 -> Child Node 22, expanding with action 7(Initial full=-9.849, G=-9.865 H=0.000)\n",
      "2025-06-17 18:28:27,873 - INFO - from node 24 -> Child Node 35, expanding with action 8(Initial full=-9.831, G=-9.831 H=0.000)\n",
      "2025-06-17 18:28:27,884 - INFO - from node 24 -> Child Node 32, expanding with action 9(Initial full=-9.062, G=-9.830 H=0.000)\n",
      "2025-06-17 18:28:27,911 - INFO - from node 24 -> Child Node 24, expanding with action 12(Initial full=-7.567, G=-7.567 H=0.000)\n",
      "2025-06-17 18:28:27,978 - INFO - Root node children stats: [('a', 0, 'child id', 33, 'N', 18, 'T', -345.85, 'efe_av', -19.21), ('a', 1, 'child id', 57, 'N', 2, 'T', -39.34, 'efe_av', -19.67), ('a', 2, 'child id', 58, 'N', 1, 'T', -19.84, 'efe_av', -19.84), ('a', 9, 'child id', 51, 'N', 2, 'T', -39.49, 'efe_av', -19.75), ('a', 12, 'child id', 53, 'N', 1, 'T', -19.94, 'efe_av', -19.94)]\n",
      "2025-06-17 18:28:27,980 - INFO - --- Simulation 26/30 ---\n",
      "2025-06-17 18:28:27,981 - INFO - --- Selection Phase End (Selected Node: 37) ---\n",
      "2025-06-17 18:28:28,006 - INFO - from node 37 -> Child Node 38, expanding with action 2(Initial full=-9.583, G=-9.677 H=0.000)\n",
      "2025-06-17 18:28:28,037 - INFO - from node 37 -> Child Node 24, expanding with action 6(Initial full=-7.567, G=-8.888 H=0.000)\n",
      "2025-06-17 18:28:28,054 - INFO - from node 37 -> Child Node 32, expanding with action 8(Initial full=-9.062, G=-9.868 H=0.000)\n",
      "2025-06-17 18:28:28,082 - INFO - from node 37 -> Child Node 37, expanding with action 12(Initial full=-9.563, G=-9.610 H=0.000)\n",
      "2025-06-17 18:28:28,110 - INFO - Root node children stats: [('a', 0, 'child id', 33, 'N', 19, 'T', -364.3, 'efe_av', -19.17), ('a', 1, 'child id', 57, 'N', 2, 'T', -39.34, 'efe_av', -19.67), ('a', 2, 'child id', 58, 'N', 1, 'T', -19.84, 'efe_av', -19.84), ('a', 9, 'child id', 51, 'N', 2, 'T', -39.49, 'efe_av', -19.75), ('a', 12, 'child id', 53, 'N', 1, 'T', -19.94, 'efe_av', -19.94)]\n",
      "2025-06-17 18:28:28,112 - INFO - --- Simulation 27/30 ---\n",
      "2025-06-17 18:28:28,113 - INFO - --- Selection Phase End (Selected Node: 38) ---\n",
      "2025-06-17 18:28:28,168 - INFO - from node 38 -> Child Node 24, expanding with action 7(Initial full=-7.567, G=-9.813 H=0.000)\n",
      "2025-06-17 18:28:28,180 - INFO - from node 38 -> Child Node 37, expanding with action 8(Initial full=-9.563, G=-9.713 H=0.000)\n",
      "2025-06-17 18:28:28,208 - INFO - from node 38 -> Child Node 38, expanding with action 12(Initial full=-9.583, G=-9.583 H=0.000)\n",
      "2025-06-17 18:28:28,230 - INFO - Root node children stats: [('a', 0, 'child id', 33, 'N', 20, 'T', -383.47, 'efe_av', -19.17), ('a', 1, 'child id', 57, 'N', 2, 'T', -39.34, 'efe_av', -19.67), ('a', 2, 'child id', 58, 'N', 1, 'T', -19.84, 'efe_av', -19.84), ('a', 9, 'child id', 51, 'N', 2, 'T', -39.49, 'efe_av', -19.75), ('a', 12, 'child id', 53, 'N', 1, 'T', -19.94, 'efe_av', -19.94)]\n",
      "2025-06-17 18:28:28,231 - INFO - --- Simulation 28/30 ---\n",
      "2025-06-17 18:28:28,233 - INFO - --- Selection Phase End (Selected Node: 26) ---\n",
      "2025-06-17 18:28:28,243 - INFO - from node 26 -> Child Node 6, expanding with action 1(Initial full=-9.896, G=-9.900 H=0.000)\n",
      "2025-06-17 18:28:28,257 - INFO - from node 26 -> Child Node 7, expanding with action 3(Initial full=-9.883, G=-9.883 H=0.000)\n",
      "2025-06-17 18:28:28,265 - INFO - from node 26 -> Child Node 16, expanding with action 4(Initial full=-9.855, G=-9.855 H=0.000)\n",
      "2025-06-17 18:28:28,274 - INFO - from node 26 -> Child Node 27, expanding with action 5(Initial full=-9.873, G=-9.921 H=0.000)\n",
      "2025-06-17 18:28:28,285 - INFO - from node 26 -> Child Node 55, expanding with action 6(Initial full=-9.715, G=-9.715 H=0.000)\n",
      "2025-06-17 18:28:28,296 - INFO - from node 26 -> Child Node 46, expanding with action 7(Initial full=-9.932, G=-9.932 H=0.000)\n",
      "2025-06-17 18:28:28,303 - INFO - from node 26 -> Child Node 10, expanding with action 8(Initial full=-9.912, G=-9.912 H=0.000)\n",
      "2025-06-17 18:28:28,311 - INFO - from node 26 -> Child Node 9, expanding with action 9(Initial full=-9.912, G=-9.912 H=0.000)\n",
      "2025-06-17 18:28:28,320 - INFO - from node 26 -> Child Node 28, expanding with action 10(Initial full=-9.869, G=-9.869 H=0.000)\n",
      "2025-06-17 18:28:28,328 - INFO - from node 26 -> Child Node 8, expanding with action 11(Initial full=-9.899, G=-9.899 H=0.000)\n",
      "2025-06-17 18:28:28,334 - INFO - from node 26 -> Child Node 26, expanding with action 12(Initial full=-9.909, G=-9.930 H=0.000)\n",
      "2025-06-17 18:28:28,409 - INFO - Root node children stats: [('a', 0, 'child id', 33, 'N', 20, 'T', -383.47, 'efe_av', -19.17), ('a', 1, 'child id', 57, 'N', 2, 'T', -39.34, 'efe_av', -19.67), ('a', 2, 'child id', 58, 'N', 1, 'T', -19.84, 'efe_av', -19.84), ('a', 9, 'child id', 51, 'N', 3, 'T', -59.11, 'efe_av', -19.7), ('a', 12, 'child id', 53, 'N', 1, 'T', -19.94, 'efe_av', -19.94)]\n",
      "2025-06-17 18:28:28,410 - INFO - --- Simulation 29/30 ---\n",
      "2025-06-17 18:28:28,412 - INFO - --- Selection Phase End (Selected Node: 8) ---\n",
      "2025-06-17 18:28:28,437 - INFO - from node 8 -> Child Node 6, expanding with action 3(Initial full=-9.896, G=-9.901 H=0.000)\n",
      "2025-06-17 18:28:28,444 - INFO - from node 8 -> Child Node 7, expanding with action 4(Initial full=-9.875, G=-9.875 H=0.000)\n",
      "2025-06-17 18:28:28,453 - INFO - from node 8 -> Child Node 26, expanding with action 5(Initial full=-9.909, G=-9.939 H=0.000)\n",
      "2025-06-17 18:28:28,463 - INFO - from node 8 -> Child Node 46, expanding with action 6(Initial full=-9.895, G=-9.895 H=0.000)\n",
      "2025-06-17 18:28:28,471 - INFO - from node 8 -> Child Node 9, expanding with action 7(Initial full=-9.912, G=-9.937 H=0.000)\n",
      "2025-06-17 18:28:28,481 - INFO - from node 8 -> Child Node 34, expanding with action 8(Initial full=-9.811, G=-9.811 H=0.000)\n",
      "2025-06-17 18:28:28,490 - INFO - from node 8 -> Child Node 28, expanding with action 9(Initial full=-9.869, G=-9.897 H=0.000)\n",
      "2025-06-17 18:28:28,498 - INFO - from node 8 -> Child Node 13, expanding with action 10(Initial full=-9.848, G=-9.848 H=0.000)\n",
      "2025-06-17 18:28:28,505 - INFO - from node 8 -> Child Node 12, expanding with action 11(Initial full=-9.869, G=-9.878 H=0.000)\n",
      "2025-06-17 18:28:28,511 - INFO - from node 8 -> Child Node 8, expanding with action 12(Initial full=-9.899, G=-9.904 H=0.000)\n",
      "2025-06-17 18:28:28,623 - INFO - Root node children stats: [('a', 0, 'child id', 33, 'N', 20, 'T', -383.47, 'efe_av', -19.17), ('a', 1, 'child id', 57, 'N', 2, 'T', -39.34, 'efe_av', -19.67), ('a', 2, 'child id', 58, 'N', 1, 'T', -19.84, 'efe_av', -19.84), ('a', 9, 'child id', 51, 'N', 4, 'T', -78.83, 'efe_av', -19.71), ('a', 12, 'child id', 53, 'N', 1, 'T', -19.94, 'efe_av', -19.94)]\n",
      "2025-06-17 18:28:28,625 - INFO - --- Simulation 30/30 ---\n",
      "2025-06-17 18:28:28,627 - INFO - --- Selection Phase End (Selected Node: 28) ---\n",
      "2025-06-17 18:28:28,660 - INFO - from node 28 -> Child Node 12, expanding with action 1(Initial full=-9.869, G=-9.902 H=0.000)\n",
      "2025-06-17 18:28:28,691 - INFO - from node 28 -> Child Node 8, expanding with action 3(Initial full=-9.894, G=-9.894 H=0.000)\n",
      "2025-06-17 18:28:28,726 - INFO - from node 28 -> Child Node 26, expanding with action 4(Initial full=-9.894, G=-9.894 H=0.000)\n",
      "2025-06-17 18:28:28,751 - INFO - from node 28 -> Child Node 9, expanding with action 5(Initial full=-9.912, G=-9.920 H=0.000)\n",
      "2025-06-17 18:28:28,772 - INFO - from node 28 -> Child Node 10, expanding with action 6(Initial full=-9.878, G=-9.878 H=0.000)\n",
      "2025-06-17 18:28:28,783 - INFO - from node 28 -> Child Node 34, expanding with action 7(Initial full=-9.811, G=-9.896 H=0.000)\n",
      "2025-06-17 18:28:28,816 - INFO - from node 28 -> Child Node 29, expanding with action 9(Initial full=-9.890, G=-9.890 H=0.000)\n",
      "2025-06-17 18:28:28,826 - INFO - from node 28 -> Child Node 14, expanding with action 10(Initial full=-9.843, G=-9.843 H=0.000)\n",
      "2025-06-17 18:28:28,836 - INFO - from node 28 -> Child Node 13, expanding with action 11(Initial full=-9.848, G=-9.868 H=0.000)\n",
      "2025-06-17 18:28:28,843 - INFO - from node 28 -> Child Node 28, expanding with action 12(Initial full=-9.869, G=-9.924 H=0.000)\n",
      "2025-06-17 18:28:28,907 - INFO - Root node children stats: [('a', 0, 'child id', 33, 'N', 21, 'T', -403.18, 'efe_av', -19.2), ('a', 1, 'child id', 57, 'N', 2, 'T', -39.34, 'efe_av', -19.67), ('a', 2, 'child id', 58, 'N', 1, 'T', -19.84, 'efe_av', -19.84), ('a', 9, 'child id', 51, 'N', 4, 'T', -78.83, 'efe_av', -19.71), ('a', 12, 'child id', 53, 'N', 1, 'T', -19.94, 'efe_av', -19.94)]\n",
      "2025-06-17 18:28:28,909 - INFO - Root node children stats: Action 0: AvgR=-19.199, N=21; Action 1: AvgR=-19.669, N=2; Action 2: AvgR=-19.844, N=1; Action 9: AvgR=-19.706, N=4; Action 12: AvgR=-19.942, N=1\n",
      "2025-06-17 18:28:28,910 - INFO - action average G: [-19.19900414227978, -19.668707345065666, -19.843714517448973, -19.70629444172587, -19.942161210293598]\n",
      "2025-06-17 18:28:28,912 - INFO - softmax policies: [1. 0. 0. 0. 0.]\n",
      "2025-06-17 18:28:28,913 - INFO - Selected best action based on policy: 0\n",
      "2025-06-17 18:28:28,914 - INFO - Selected Action: 0 ([0, 30])\n",
      "2025-06-17 18:28:28,915 - INFO - Root Node Children Details:\n",
      "  Action 0 ([0, 30]): state=33 AvgR=-19.199, N=21\n",
      "  Action 1 ([30, 60]): state=57 AvgR=-19.669, N=2\n",
      "  Action 2 ([60, 90]): state=58 AvgR=-19.844, N=1\n",
      "  Action 9 ([270, 300]): state=51 AvgR=-19.706, N=4\n",
      "  Action 12 (STAY): state=53 AvgR=-19.942, N=1\n",
      "2025-06-17 18:28:28,917 - INFO - max visits:[(25, 0), (16, 0), (27, 0), (7, 0), (12, 0), (13, 0), (22, 0), (32, 0), (35, 0), (55, 0), (46, 0), (10, 0), (9, 0), (34, 0), (29, 0), (14, 0), (42, 1), (62, 1), (19, 1), (60, 1), (61, 1), (58, 1), (23, 1), (3, 1), (1, 1), (21, 1), (24, 1), (37, 1), (38, 1), (26, 1), (28, 1), (8, 1), (59, 2), (18, 2), (57, 2), (4, 2), (0, 2), (6, 3), (20, 4), (51, 4), (2, 5), (17, 6), (5, 9), (33, 21), (53, 30)], len dict:45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action visit counts: [21, 2, 1, 4, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173321/250434533.py:58: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "2025-06-17 18:28:30,243 - INFO - Executing action 0 -> Transitioning to Node 33\n",
      "2025-06-17 18:28:30,244 - INFO - \n",
      "===== Simulation Finished =====\n",
      "2025-06-17 18:28:30,245 - INFO - Completed 1 steps.\n",
      "2025-06-17 18:28:30,246 - INFO - Final State (Node ID): 33\n"
     ]
    }
   ],
   "source": [
    "for i in range(NUM_STEPS):\n",
    "    logging.info(f\"\\n===== Planning Step {i+1}/{NUM_STEPS} =====\")\n",
    "    logging.info(f\"Current State (Node ID): {current_node.id}\")\n",
    "\n",
    "    # Plan the next action using MCTS\n",
    "    # The root of the search is the current state node\n",
    "    best_action, data = mcts.plan(current_node, NUM_SIMULATIONS, MAX_ROLLOUT_DEPTH, logging=logging, data=data)\n",
    "\n",
    "    if best_action is None:\n",
    "        logging.error(\"MCTS failed to find a best action. Stopping simulation.\")\n",
    "        break\n",
    "\n",
    "    action_name = map_action_names.get(best_action, \"Unknown\")\n",
    "    logging.info(f\"Selected Action: {best_action} ({action_name})\")\n",
    "\n",
    "    # Display action values/visits from the root node\n",
    "    if current_node.childs:\n",
    "        child_info_list = []\n",
    "        for action_id, child in current_node.childs.items():\n",
    "                a_name = map_action_names.get(action_id, \"?\")\n",
    "                child_info_list.append(f\"  Action {action_id} ({a_name}): state={child.id} AvgR={child.get_averaged_reward():.3f}, N={child.N}\")\n",
    "        logging.info(\"Root Node Children Details:\\n\" + \"\\n\".join(child_info_list))\n",
    "        print('Action visit counts:', [current_node.childs[action_id].N for action_id in current_node.childs])\n",
    "    else:\n",
    "            logging.info(\"Root node has no children explored.\")\n",
    "\n",
    "    # Visualize the tree if enabled\n",
    "    if PLOT_TREE:\n",
    "        plot_mcts_tree(current_node)\n",
    "\n",
    "    # --- Execute the selected action ---\n",
    "    # In a real robot, this would involve sending the command and getting sensor feedback.\n",
    "    # Here, we transition to the corresponding child node in the tree.\n",
    "    if best_action in current_node.childs:\n",
    "        next_node = current_node.childs[best_action]\n",
    "        logging.info(f\"Executing action {best_action} -> Transitioning to Node {next_node.id}\")\n",
    "\n",
    "        # IMPORTANT: Detach the chosen next state from its parent (the previous state).\n",
    "        # This makes the chosen next state the new root for the *next* planning step\n",
    "        # and allows the old parts of the tree to be garbage collected.\n",
    "        \n",
    "        #WITH MEMORY\n",
    "        # next_node.detach_parent()\n",
    "        #current_node = next_node # Update the current state\n",
    "\n",
    "        #TMP TO TEST AS IN OUR MODEL\n",
    "\n",
    "        current_node = Node(state_qs=next_node.state_qs,\n",
    "                    pose_id=next_node.pose_id,\n",
    "                    parent=None,\n",
    "                    action_index=None,\n",
    "                    observation=next_node.observation, \n",
    "                    possible_actions=next_node.possible_actions)\n",
    "\n",
    "        # Log information about the new state (optional)\n",
    "        # logging.info(f\"New State Observation (Visual): {current_node.observation[0][0].round(2)}\")\n",
    "        # logging.info(f\"New State Observation (Pose): {current_node.observation[0][1].round(2)}\")\n",
    "\n",
    "    else:\n",
    "        logging.error(f\"Consistency Error: Best action {best_action} not found in children of node {current_node.id}. Stopping.\")\n",
    "        break # Stop if the tree is inconsistent\n",
    "\n",
    "logging.info(f\"\\n===== Simulation Finished =====\")\n",
    "logging.info(f\"Completed {i+1 if 'i' in locals() else 0} steps.\")\n",
    "logging.info(f\"Final State (Node ID): {current_node.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 18:45:37,285 - INFO - MCTS_Model_Interface initialized with model type: <class 'map_dm_nav.model.V5.Ours_V5_RW'>\n",
      "2025-06-17 18:45:37,288 - INFO - MCTS initialized with exploration parameter c=5, num_simus=30, max_depth=10, policy_alpha=16.0,  action_selection=stochastic\n",
      "2025-06-17 18:45:37,295 - INFO - ===== Initial Root Node ID: 53 =====\n"
     ]
    }
   ],
   "source": [
    "# Create the MCTS algorithm instance\n",
    "H_model.use_inductive_inference = True\n",
    "mcts = MCTS(H_model, c_param=C_PARAM, num_simulation=NUM_SIMULATIONS) # Adjust c_param if needed\n",
    "\n",
    "# Get action names for logging\n",
    "map_action_names = H_model.get_possible_actions() # Assuming pose 0 exists\n",
    "\n",
    "# Define the initial state\n",
    "initial_pose_id = 53 # Or get from your model/environment\n",
    "initial_belief_qs = H_model.get_belief_over_states() # Get initial belief\n",
    "initial_observation = H_model.get_expected_observation(initial_belief_qs)\n",
    "# Root node has no parent and no action leading to it\n",
    "root_node = Node(state_qs=initial_belief_qs,\n",
    "                pose_id=initial_pose_id,\n",
    "                parent=None,\n",
    "                action_index=None,\n",
    "                observation=initial_observation, \n",
    "                possible_actions=possible_actions)\n",
    "\n",
    "logging.info(f\"===== Initial Root Node ID: {root_node.id} =====\")\n",
    "\n",
    "# --- Simulation Loop ---\n",
    "current_node = root_node\n",
    "data = {\"qs\": initial_belief_qs[0],\n",
    "            \"qpi\": [],\n",
    "            \"efe\": [],\n",
    "            \"info_gain\": [],\n",
    "            \"utility\": [],\n",
    "            #\"bayesian_surprise\": utils.bayesian_surprise(posterior[0].copy(), prior),\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 18:50:24,783 - INFO - \n",
      "===== Planning Step 1/1 =====\n",
      "2025-06-17 18:50:24,784 - INFO - Current State (Node ID): 31\n",
      "2025-06-17 18:50:24,785 - INFO - Starting MCTS planning from root node 31 for 30 simulations.\n",
      "2025-06-17 18:50:24,786 - INFO - --- Simulation 1/30 ---\n",
      "2025-06-17 18:50:24,787 - INFO - --- Selection Phase End (Selected Node: 31) ---\n",
      "2025-06-17 18:50:24,801 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:24,802 - INFO - from node 31 -> Child Node 39, expanding with action 0(Initial full=-8.753, G=-8.985 H=0.231)\n",
      "2025-06-17 18:50:24,816 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:24,818 - INFO - from node 31 -> Child Node 15, expanding with action 1(Initial full=-9.259, G=-9.395 H=0.136)\n",
      "2025-06-17 18:50:24,834 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:24,836 - INFO - from node 31 -> Child Node 14, expanding with action 2(Initial full=-9.925, G=-9.934 H=0.009)\n",
      "2025-06-17 18:50:24,851 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:24,852 - INFO - from node 31 -> Child Node 30, expanding with action 3(Initial full=-9.936, G=-9.944 H=0.007)\n",
      "2025-06-17 18:50:24,866 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:24,868 - INFO - from node 31 -> Child Node 43, expanding with action 5(Initial full=-9.929, G=-9.937 H=0.008)\n",
      "2025-06-17 18:50:24,882 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:24,892 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:24,903 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:24,920 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:24,934 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:24,935 - INFO - Root node children stats: [('a', 0, 'child id', 39, 'N', 0, 'T', 0, 'efe_av', -8.75), ('a', 1, 'child id', 15, 'N', 0, 'T', 0, 'efe_av', -9.26), ('a', 2, 'child id', 14, 'N', 0, 'T', 0, 'efe_av', -9.92), ('a', 3, 'child id', 30, 'N', 0, 'T', 0, 'efe_av', -9.94), ('a', 5, 'child id', 43, 'N', 0, 'T', 0, 'efe_av', -9.93)]\n",
      "2025-06-17 18:50:24,937 - INFO - --- Simulation 2/30 ---\n",
      "2025-06-17 18:50:24,938 - INFO - --- Selection Phase End (Selected Node: 39) ---\n",
      "2025-06-17 18:50:24,951 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:24,953 - INFO - from node 39 -> Child Node 41, expanding with action 0(Initial full=-8.976, G=-9.164 H=0.188)\n",
      "2025-06-17 18:50:24,974 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:24,975 - INFO - from node 39 -> Child Node 36, expanding with action 2(Initial full=-9.928, G=-9.936 H=0.008)\n",
      "2025-06-17 18:50:24,997 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:24,999 - INFO - from node 39 -> Child Node 15, expanding with action 4(Initial full=-9.259, G=-9.531 H=0.103)\n",
      "2025-06-17 18:50:25,049 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,050 - INFO - from node 39 -> Child Node 54, expanding with action 10(Initial full=-9.548, G=-9.624 H=0.077)\n",
      "2025-06-17 18:50:25,066 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,067 - INFO - from node 39 -> Child Node 39, expanding with action 12(Initial full=-8.753, G=-8.985 H=0.231)\n",
      "2025-06-17 18:50:25,081 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,096 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,105 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,120 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,130 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,132 - INFO - Root node children stats: [('a', 0, 'child id', 39, 'N', 1, 'T', -17.51, 'efe_av', -17.51), ('a', 1, 'child id', 15, 'N', 0, 'T', 0, 'efe_av', -9.26), ('a', 2, 'child id', 14, 'N', 0, 'T', 0, 'efe_av', -9.92), ('a', 3, 'child id', 30, 'N', 0, 'T', 0, 'efe_av', -9.94), ('a', 5, 'child id', 43, 'N', 0, 'T', 0, 'efe_av', -9.93)]\n",
      "2025-06-17 18:50:25,134 - INFO - --- Simulation 3/30 ---\n",
      "2025-06-17 18:50:25,135 - INFO - --- Selection Phase End (Selected Node: 15) ---\n",
      "2025-06-17 18:50:25,149 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,151 - INFO - from node 15 -> Child Node 36, expanding with action 0(Initial full=-9.334, G=-9.453 H=0.119)\n",
      "2025-06-17 18:50:25,175 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,177 - INFO - from node 15 -> Child Node 35, expanding with action 2(Initial full=-9.928, G=-9.936 H=0.008)\n",
      "2025-06-17 18:50:25,190 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,192 - INFO - from node 15 -> Child Node 14, expanding with action 3(Initial full=-9.925, G=-9.945 H=0.007)\n",
      "2025-06-17 18:50:25,205 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,207 - INFO - from node 15 -> Child Node 29, expanding with action 4(Initial full=-9.865, G=-9.885 H=0.020)\n",
      "2025-06-17 18:50:25,222 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,223 - INFO - from node 15 -> Child Node 30, expanding with action 5(Initial full=-9.932, G=-9.939 H=0.008)\n",
      "2025-06-17 18:50:25,238 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,240 - INFO - from node 15 -> Child Node 43, expanding with action 6(Initial full=-9.875, G=-9.892 H=0.017)\n",
      "2025-06-17 18:50:25,277 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,279 - INFO - from node 15 -> Child Node 39, expanding with action 10(Initial full=-8.753, G=-9.742 H=0.053)\n",
      "2025-06-17 18:50:25,296 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,298 - INFO - from node 15 -> Child Node 15, expanding with action 12(Initial full=-9.259, G=-9.395 H=0.136)\n",
      "2025-06-17 18:50:25,311 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,324 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,338 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,349 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,360 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,374 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,387 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,399 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,401 - INFO - Root node children stats: [('a', 0, 'child id', 39, 'N', 1, 'T', -17.51, 'efe_av', -17.51), ('a', 1, 'child id', 15, 'N', 1, 'T', -18.52, 'efe_av', -18.52), ('a', 2, 'child id', 14, 'N', 0, 'T', 0, 'efe_av', -9.92), ('a', 3, 'child id', 30, 'N', 0, 'T', 0, 'efe_av', -9.93), ('a', 5, 'child id', 43, 'N', 0, 'T', 0, 'efe_av', -9.87)]\n",
      "2025-06-17 18:50:25,403 - INFO - --- Simulation 4/30 ---\n",
      "2025-06-17 18:50:25,404 - INFO - --- Selection Phase End (Selected Node: 14) ---\n",
      "2025-06-17 18:50:25,417 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,419 - INFO - from node 14 -> Child Node 35, expanding with action 0(Initial full=-9.651, G=-9.711 H=0.060)\n",
      "2025-06-17 18:50:25,441 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,443 - INFO - from node 14 -> Child Node 22, expanding with action 2(Initial full=-9.926, G=-9.934 H=0.009)\n",
      "2025-06-17 18:50:25,455 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,456 - INFO - from node 14 -> Child Node 13, expanding with action 3(Initial full=-9.938, G=-9.945 H=0.007)\n",
      "2025-06-17 18:50:25,469 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,471 - INFO - from node 14 -> Child Node 28, expanding with action 4(Initial full=-9.861, G=-9.882 H=0.020)\n",
      "2025-06-17 18:50:25,481 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,483 - INFO - from node 14 -> Child Node 29, expanding with action 5(Initial full=-9.865, G=-9.938 H=0.008)\n",
      "2025-06-17 18:50:25,507 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,508 - INFO - from node 14 -> Child Node 30, expanding with action 7(Initial full=-9.043, G=-9.219 H=0.176)\n",
      "2025-06-17 18:50:25,525 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,527 - INFO - from node 14 -> Child Node 15, expanding with action 9(Initial full=-9.259, G=-9.406 H=0.134)\n",
      "2025-06-17 18:50:25,550 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,552 - INFO - from node 14 -> Child Node 36, expanding with action 11(Initial full=-9.334, G=-9.878 H=0.023)\n",
      "2025-06-17 18:50:25,560 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,561 - INFO - from node 14 -> Child Node 14, expanding with action 12(Initial full=-9.925, G=-9.934 H=0.009)\n",
      "2025-06-17 18:50:25,576 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,588 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,598 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,615 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,630 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,641 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,650 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,663 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,675 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,676 - INFO - Root node children stats: [('a', 0, 'child id', 39, 'N', 1, 'T', -17.51, 'efe_av', -17.51), ('a', 1, 'child id', 15, 'N', 1, 'T', -18.52, 'efe_av', -18.52), ('a', 2, 'child id', 14, 'N', 1, 'T', -18.97, 'efe_av', -18.97), ('a', 3, 'child id', 30, 'N', 0, 'T', 0, 'efe_av', -9.04), ('a', 5, 'child id', 43, 'N', 0, 'T', 0, 'efe_av', -9.87)]\n",
      "2025-06-17 18:50:25,678 - INFO - --- Simulation 5/30 ---\n",
      "2025-06-17 18:50:25,679 - INFO - --- Selection Phase End (Selected Node: 30) ---\n",
      "2025-06-17 18:50:25,704 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,706 - INFO - from node 30 -> Child Node 14, expanding with action 1(Initial full=-9.895, G=-9.909 H=0.014)\n",
      "2025-06-17 18:50:25,719 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,721 - INFO - from node 30 -> Child Node 13, expanding with action 2(Initial full=-9.923, G=-9.932 H=0.009)\n",
      "2025-06-17 18:50:25,737 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,739 - INFO - from node 30 -> Child Node 29, expanding with action 3(Initial full=-9.865, G=-9.948 H=0.006)\n",
      "2025-06-17 18:50:25,756 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,757 - INFO - from node 30 -> Child Node 34, expanding with action 4(Initial full=-9.873, G=-9.892 H=0.018)\n",
      "2025-06-17 18:50:25,773 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,775 - INFO - from node 30 -> Child Node 44, expanding with action 5(Initial full=-9.932, G=-9.940 H=0.008)\n",
      "2025-06-17 18:50:25,789 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,792 - INFO - from node 30 -> Child Node 44, expanding with action 6(Initial full=-9.865, G=-9.883 H=0.018)\n",
      "2025-06-17 18:50:25,809 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,811 - INFO - from node 30 -> Child Node 43, expanding with action 7(Initial full=-9.793, G=-9.827 H=0.033)\n",
      "2025-06-17 18:50:25,861 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,863 - INFO - from node 30 -> Child Node 15, expanding with action 11(Initial full=-9.192, G=-9.342 H=0.149)\n",
      "2025-06-17 18:50:25,870 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,871 - INFO - from node 30 -> Child Node 30, expanding with action 12(Initial full=-9.043, G=-9.944 H=0.007)\n",
      "2025-06-17 18:50:25,882 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,892 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,909 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,947 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:25,986 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:26,024 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:26,043 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:26,060 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:26,075 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:26,078 - INFO - Root node children stats: [('a', 0, 'child id', 39, 'N', 1, 'T', -17.51, 'efe_av', -17.51), ('a', 1, 'child id', 15, 'N', 1, 'T', -18.52, 'efe_av', -18.52), ('a', 2, 'child id', 14, 'N', 1, 'T', -18.97, 'efe_av', -18.97), ('a', 3, 'child id', 30, 'N', 1, 'T', -18.24, 'efe_av', -18.24), ('a', 5, 'child id', 43, 'N', 0, 'T', 0, 'efe_av', -9.79)]\n",
      "2025-06-17 18:50:26,079 - INFO - --- Simulation 6/30 ---\n",
      "2025-06-17 18:50:26,083 - INFO - --- Selection Phase End (Selected Node: 43) ---\n",
      "2025-06-17 18:50:26,098 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:26,100 - INFO - from node 43 -> Child Node 15, expanding with action 0(Initial full=-8.558, G=-8.827 H=0.268)\n",
      "2025-06-17 18:50:26,117 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:26,119 - INFO - from node 43 -> Child Node 30, expanding with action 1(Initial full=-9.043, G=-9.674 H=0.071)\n",
      "2025-06-17 18:50:26,133 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:26,135 - INFO - from node 43 -> Child Node 29, expanding with action 2(Initial full=-9.865, G=-9.935 H=0.009)\n",
      "2025-06-17 18:50:26,159 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:26,160 - INFO - from node 43 -> Child Node 44, expanding with action 4(Initial full=-9.865, G=-9.900 H=0.017)\n",
      "2025-06-17 18:50:26,174 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:26,178 - INFO - from node 43 -> Child Node 48, expanding with action 5(Initial full=-9.932, G=-9.939 H=0.007)\n",
      "2025-06-17 18:50:26,206 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:26,212 - INFO - from node 43 -> Child Node 45, expanding with action 6(Initial full=-9.869, G=-9.886 H=0.017)\n",
      "2025-06-17 18:50:26,286 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:26,287 - INFO - from node 43 -> Child Node 43, expanding with action 12(Initial full=-9.793, G=-9.937 H=0.008)\n",
      "2025-06-17 18:50:26,299 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:26,313 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:26,326 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:26,340 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:26,352 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:26,366 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:26,376 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:26,379 - INFO - Root node children stats: [('a', 0, 'child id', 39, 'N', 1, 'T', -17.51, 'efe_av', -17.51), ('a', 1, 'child id', 15, 'N', 1, 'T', -18.52, 'efe_av', -18.52), ('a', 2, 'child id', 14, 'N', 1, 'T', -18.97, 'efe_av', -18.97), ('a', 3, 'child id', 30, 'N', 1, 'T', -18.24, 'efe_av', -18.24), ('a', 5, 'child id', 43, 'N', 1, 'T', -18.35, 'efe_av', -18.35)]\n",
      "2025-06-17 18:50:26,380 - INFO - --- Simulation 7/30 ---\n",
      "2025-06-17 18:50:26,381 - INFO - --- Selection Phase End (Selected Node: 41) ---\n",
      "2025-06-17 18:50:26,422 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:26,423 - INFO - from node 41 -> Child Node 40, expanding with action 3(Initial full=-9.933, G=-9.941 H=0.008)\n",
      "2025-06-17 18:50:26,435 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:26,437 - INFO - from node 41 -> Child Node 35, expanding with action 4(Initial full=-9.651, G=-9.817 H=0.035)\n",
      "2025-06-17 18:50:26,450 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:26,452 - INFO - from node 41 -> Child Node 36, expanding with action 5(Initial full=-9.334, G=-9.929 H=0.010)\n",
      "2025-06-17 18:50:26,483 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:26,485 - INFO - from node 41 -> Child Node 54, expanding with action 8(Initial full=-9.039, G=-9.216 H=0.177)\n",
      "2025-06-17 18:50:26,520 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:26,521 - INFO - from node 41 -> Child Node 41, expanding with action 12(Initial full=-8.976, G=-9.164 H=0.188)\n",
      "2025-06-17 18:50:26,535 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:26,548 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:26,562 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:26,578 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:26,586 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:26,588 - INFO - Root node children stats: [('a', 0, 'child id', 39, 'N', 2, 'T', -35.46, 'efe_av', -17.73), ('a', 1, 'child id', 15, 'N', 1, 'T', -18.52, 'efe_av', -18.52), ('a', 2, 'child id', 14, 'N', 1, 'T', -18.97, 'efe_av', -18.97), ('a', 3, 'child id', 30, 'N', 1, 'T', -18.24, 'efe_av', -18.24), ('a', 5, 'child id', 43, 'N', 1, 'T', -18.35, 'efe_av', -18.35)]\n",
      "2025-06-17 18:50:26,589 - INFO - --- Simulation 8/30 ---\n",
      "2025-06-17 18:50:26,590 - INFO - --- Selection Phase End (Selected Node: 13) ---\n",
      "2025-06-17 18:50:26,605 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:26,607 - INFO - from node 13 -> Child Node 22, expanding with action 0(Initial full=-9.479, G=-9.689 H=0.210)\n",
      "2025-06-17 18:50:26,631 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:26,633 - INFO - from node 13 -> Child Node 21, expanding with action 2(Initial full=-9.767, G=-9.921 H=0.154)\n",
      "2025-06-17 18:50:26,644 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:26,645 - INFO - from node 13 -> Child Node 12, expanding with action 3(Initial full=-9.813, G=-9.947 H=0.134)\n",
      "2025-06-17 18:50:26,655 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:26,656 - INFO - from node 13 -> Child Node 8, expanding with action 4(Initial full=-9.734, G=-9.885 H=0.151)\n",
      "2025-06-17 18:50:26,669 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:26,671 - INFO - from node 13 -> Child Node 28, expanding with action 5(Initial full=-9.819, G=-9.937 H=0.118)\n",
      "2025-06-17 18:50:26,685 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:26,687 - INFO - from node 13 -> Child Node 34, expanding with action 6(Initial full=-9.733, G=-9.902 H=0.169)\n",
      "2025-06-17 18:50:26,700 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:26,701 - INFO - from node 13 -> Child Node 29, expanding with action 7(Initial full=-9.546, G=-9.855 H=0.308)\n",
      "2025-06-17 18:50:26,724 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:26,734 - INFO - from node 13 -> Child Node 14, expanding with action 9(Initial full=-9.395, G=-9.870 H=0.474)\n",
      "2025-06-17 18:50:26,794 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:26,796 - INFO - from node 13 -> Child Node 35, expanding with action 11(Initial full=-9.594, G=-9.873 H=0.280)\n",
      "2025-06-17 18:50:26,808 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:26,810 - INFO - from node 13 -> Child Node 13, expanding with action 12(Initial full=-9.801, G=-9.945 H=0.144)\n",
      "2025-06-17 18:50:26,825 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:26,841 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:26,855 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:26,869 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:26,885 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:26,898 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:26,909 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:26,921 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:26,933 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:26,943 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:26,945 - INFO - Root node children stats: [('a', 0, 'child id', 39, 'N', 2, 'T', -35.46, 'efe_av', -17.73), ('a', 1, 'child id', 15, 'N', 1, 'T', -18.52, 'efe_av', -18.52), ('a', 2, 'child id', 14, 'N', 2, 'T', -38.16, 'efe_av', -19.08), ('a', 3, 'child id', 30, 'N', 1, 'T', -18.24, 'efe_av', -18.24), ('a', 5, 'child id', 43, 'N', 1, 'T', -18.35, 'efe_av', -18.35)]\n",
      "2025-06-17 18:50:26,947 - INFO - --- Simulation 9/30 ---\n",
      "2025-06-17 18:50:26,948 - INFO - --- Selection Phase End (Selected Node: 29) ---\n",
      "2025-06-17 18:50:26,972 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:26,973 - INFO - from node 29 -> Child Node 13, expanding with action 1(Initial full=-9.801, G=-9.903 H=0.016)\n",
      "2025-06-17 18:50:26,983 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:26,984 - INFO - from node 29 -> Child Node 12, expanding with action 2(Initial full=-9.813, G=-9.929 H=0.009)\n",
      "2025-06-17 18:50:26,999 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:27,001 - INFO - from node 29 -> Child Node 28, expanding with action 3(Initial full=-9.819, G=-9.943 H=0.007)\n",
      "2025-06-17 18:50:27,013 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:27,014 - INFO - from node 29 -> Child Node 9, expanding with action 4(Initial full=-9.836, G=-9.862 H=0.026)\n",
      "2025-06-17 18:50:27,030 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:27,033 - INFO - from node 29 -> Child Node 34, expanding with action 5(Initial full=-9.733, G=-9.934 H=0.009)\n",
      "2025-06-17 18:50:27,062 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:27,064 - INFO - from node 29 -> Child Node 44, expanding with action 7(Initial full=-9.229, G=-9.369 H=0.140)\n",
      "2025-06-17 18:50:27,076 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:27,078 - INFO - from node 29 -> Child Node 43, expanding with action 8(Initial full=-9.115, G=-9.275 H=0.160)\n",
      "2025-06-17 18:50:27,096 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:27,098 - INFO - from node 29 -> Child Node 15, expanding with action 10(Initial full=-8.558, G=-9.580 H=0.091)\n",
      "2025-06-17 18:50:27,111 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:27,113 - INFO - from node 29 -> Child Node 14, expanding with action 11(Initial full=-9.395, G=-9.810 H=0.039)\n",
      "2025-06-17 18:50:27,122 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:27,123 - INFO - from node 29 -> Child Node 29, expanding with action 12(Initial full=-9.546, G=-9.885 H=0.020)\n",
      "2025-06-17 18:50:27,136 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:27,151 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:27,163 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:27,174 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:27,191 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:27,208 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:27,224 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:27,237 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:27,246 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:27,256 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:27,258 - INFO - Root node children stats: [('a', 0, 'child id', 39, 'N', 2, 'T', -35.46, 'efe_av', -17.73), ('a', 1, 'child id', 15, 'N', 2, 'T', -37.18, 'efe_av', -18.59), ('a', 2, 'child id', 14, 'N', 2, 'T', -38.16, 'efe_av', -19.08), ('a', 3, 'child id', 30, 'N', 1, 'T', -18.24, 'efe_av', -18.24), ('a', 5, 'child id', 43, 'N', 1, 'T', -18.35, 'efe_av', -18.35)]\n",
      "2025-06-17 18:50:27,258 - INFO - --- Simulation 10/30 ---\n",
      "2025-06-17 18:50:27,260 - INFO - --- Selection Phase End (Selected Node: 34) ---\n",
      "2025-06-17 18:50:27,273 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:27,275 - INFO - from node 34 -> Child Node 13, expanding with action 0(Initial full=-9.610, G=-9.798 H=0.188)\n",
      "2025-06-17 18:50:27,291 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:27,292 - INFO - from node 34 -> Child Node 28, expanding with action 1(Initial full=-9.773, G=-9.908 H=0.135)\n",
      "2025-06-17 18:50:27,303 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:27,305 - INFO - from node 34 -> Child Node 8, expanding with action 2(Initial full=-9.734, G=-9.932 H=0.119)\n",
      "2025-06-17 18:50:27,319 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:27,321 - INFO - from node 34 -> Child Node 9, expanding with action 3(Initial full=-9.822, G=-9.944 H=0.122)\n",
      "2025-06-17 18:50:27,339 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:27,340 - INFO - from node 34 -> Child Node 46, expanding with action 4(Initial full=-9.692, G=-9.866 H=0.174)\n",
      "2025-06-17 18:50:27,356 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:27,358 - INFO - from node 34 -> Child Node 10, expanding with action 5(Initial full=-9.793, G=-9.935 H=0.142)\n",
      "2025-06-17 18:50:27,371 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:27,372 - INFO - from node 34 -> Child Node 11, expanding with action 6(Initial full=-9.700, G=-9.889 H=0.188)\n",
      "2025-06-17 18:50:27,397 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:27,399 - INFO - from node 34 -> Child Node 44, expanding with action 8(Initial full=-9.229, G=-9.731 H=0.221)\n",
      "2025-06-17 18:50:27,426 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:27,427 - INFO - from node 34 -> Child Node 29, expanding with action 11(Initial full=-9.524, G=-9.820 H=0.296)\n",
      "2025-06-17 18:50:27,436 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:27,437 - INFO - from node 34 -> Child Node 34, expanding with action 12(Initial full=-9.733, G=-9.892 H=0.151)\n",
      "2025-06-17 18:50:27,450 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:27,460 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:27,472 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:27,482 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:27,498 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:27,512 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:27,522 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:27,537 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:27,548 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:27,558 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:27,561 - INFO - Root node children stats: [('a', 0, 'child id', 39, 'N', 2, 'T', -35.46, 'efe_av', -17.73), ('a', 1, 'child id', 15, 'N', 2, 'T', -37.18, 'efe_av', -18.59), ('a', 2, 'child id', 14, 'N', 2, 'T', -38.16, 'efe_av', -19.08), ('a', 3, 'child id', 30, 'N', 2, 'T', -37.48, 'efe_av', -18.74), ('a', 5, 'child id', 43, 'N', 1, 'T', -18.35, 'efe_av', -18.35)]\n",
      "2025-06-17 18:50:27,562 - INFO - --- Simulation 11/30 ---\n",
      "2025-06-17 18:50:27,563 - INFO - --- Selection Phase End (Selected Node: 44) ---\n",
      "2025-06-17 18:50:27,575 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:27,576 - INFO - from node 44 -> Child Node 30, expanding with action 0(Initial full=-9.043, G=-9.464 H=0.117)\n",
      "2025-06-17 18:50:27,589 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:27,591 - INFO - from node 44 -> Child Node 29, expanding with action 1(Initial full=-9.524, G=-9.914 H=0.015)\n",
      "2025-06-17 18:50:27,607 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:27,608 - INFO - from node 44 -> Child Node 34, expanding with action 2(Initial full=-9.733, G=-9.933 H=0.009)\n",
      "2025-06-17 18:50:27,620 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:27,621 - INFO - from node 44 -> Child Node 10, expanding with action 3(Initial full=-9.793, G=-9.943 H=0.007)\n",
      "2025-06-17 18:50:27,645 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:27,647 - INFO - from node 44 -> Child Node 11, expanding with action 5(Initial full=-9.700, G=-9.942 H=0.007)\n",
      "2025-06-17 18:50:27,660 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:27,663 - INFO - from node 44 -> Child Node 48, expanding with action 6(Initial full=-9.857, G=-9.877 H=0.019)\n",
      "2025-06-17 18:50:27,679 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:27,681 - INFO - from node 44 -> Child Node 50, expanding with action 7(Initial full=-9.828, G=-9.854 H=0.026)\n",
      "2025-06-17 18:50:27,695 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:27,697 - INFO - from node 44 -> Child Node 45, expanding with action 8(Initial full=-9.794, G=-9.825 H=0.031)\n",
      "2025-06-17 18:50:27,732 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:27,734 - INFO - from node 44 -> Child Node 44, expanding with action 12(Initial full=-9.229, G=-9.940 H=0.008)\n",
      "2025-06-17 18:50:27,749 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:27,763 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:27,776 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:27,787 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:27,798 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:27,814 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:27,829 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:27,846 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:27,857 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:27,858 - INFO - Root node children stats: [('a', 0, 'child id', 39, 'N', 2, 'T', -35.46, 'efe_av', -17.73), ('a', 1, 'child id', 15, 'N', 2, 'T', -37.18, 'efe_av', -18.59), ('a', 2, 'child id', 14, 'N', 2, 'T', -38.16, 'efe_av', -19.08), ('a', 3, 'child id', 30, 'N', 3, 'T', -56.05, 'efe_av', -18.68), ('a', 5, 'child id', 43, 'N', 1, 'T', -18.35, 'efe_av', -18.35)]\n",
      "2025-06-17 18:50:27,860 - INFO - --- Simulation 12/30 ---\n",
      "2025-06-17 18:50:27,861 - INFO - --- Selection Phase End (Selected Node: 48) ---\n",
      "2025-06-17 18:50:27,876 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:27,878 - INFO - from node 48 -> Child Node 44, expanding with action 0(Initial full=-8.921, G=-9.120 H=0.200)\n",
      "2025-06-17 18:50:27,900 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:27,902 - INFO - from node 48 -> Child Node 10, expanding with action 2(Initial full=-9.793, G=-9.935 H=0.009)\n",
      "2025-06-17 18:50:27,913 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:27,915 - INFO - from node 48 -> Child Node 11, expanding with action 3(Initial full=-9.700, G=-9.934 H=0.007)\n",
      "2025-06-17 18:50:27,954 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:27,955 - INFO - from node 48 -> Child Node 49, expanding with action 6(Initial full=-9.869, G=-9.886 H=0.017)\n",
      "2025-06-17 18:50:27,979 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:27,981 - INFO - from node 48 -> Child Node 50, expanding with action 8(Initial full=-9.827, G=-9.851 H=0.024)\n",
      "2025-06-17 18:50:28,003 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:28,004 - INFO - from node 48 -> Child Node 45, expanding with action 10(Initial full=-9.776, G=-9.811 H=0.035)\n",
      "2025-06-17 18:50:28,021 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:28,022 - INFO - from node 48 -> Child Node 48, expanding with action 12(Initial full=-9.857, G=-9.939 H=0.007)\n",
      "2025-06-17 18:50:28,039 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:28,050 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:28,061 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:28,074 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:28,093 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:28,113 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:28,126 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:28,128 - INFO - Root node children stats: [('a', 0, 'child id', 39, 'N', 2, 'T', -35.46, 'efe_av', -17.73), ('a', 1, 'child id', 15, 'N', 2, 'T', -37.18, 'efe_av', -18.59), ('a', 2, 'child id', 14, 'N', 2, 'T', -38.16, 'efe_av', -19.08), ('a', 3, 'child id', 30, 'N', 3, 'T', -56.05, 'efe_av', -18.68), ('a', 5, 'child id', 43, 'N', 2, 'T', -37.13, 'efe_av', -18.56)]\n",
      "2025-06-17 18:50:28,130 - INFO - --- Simulation 13/30 ---\n",
      "2025-06-17 18:50:28,131 - INFO - --- Selection Phase End (Selected Node: 36) ---\n",
      "2025-06-17 18:50:28,162 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:28,169 - INFO - from node 36 -> Child Node 40, expanding with action 1(Initial full=-9.886, G=-9.902 H=0.016)\n",
      "2025-06-17 18:50:28,197 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:28,200 - INFO - from node 36 -> Child Node 32, expanding with action 2(Initial full=-9.925, G=-9.934 H=0.009)\n",
      "2025-06-17 18:50:28,217 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:28,219 - INFO - from node 36 -> Child Node 35, expanding with action 3(Initial full=-9.594, G=-9.942 H=0.008)\n",
      "2025-06-17 18:50:28,246 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:28,248 - INFO - from node 36 -> Child Node 14, expanding with action 5(Initial full=-9.395, G=-9.933 H=0.009)\n",
      "2025-06-17 18:50:28,262 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:28,265 - INFO - from node 36 -> Child Node 15, expanding with action 6(Initial full=-8.558, G=-9.757 H=0.050)\n",
      "2025-06-17 18:50:28,299 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:28,301 - INFO - from node 36 -> Child Node 54, expanding with action 9(Initial full=-9.039, G=-9.801 H=0.040)\n",
      "2025-06-17 18:50:28,320 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:28,321 - INFO - from node 36 -> Child Node 41, expanding with action 11(Initial full=-8.976, G=-9.873 H=0.024)\n",
      "2025-06-17 18:50:28,330 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:28,332 - INFO - from node 36 -> Child Node 36, expanding with action 12(Initial full=-9.334, G=-9.936 H=0.008)\n",
      "2025-06-17 18:50:28,348 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:28,359 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:28,374 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:28,387 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:28,399 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:28,414 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:28,426 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:28,439 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:28,441 - INFO - Root node children stats: [('a', 0, 'child id', 39, 'N', 3, 'T', -54.5, 'efe_av', -18.17), ('a', 1, 'child id', 15, 'N', 2, 'T', -37.18, 'efe_av', -18.59), ('a', 2, 'child id', 14, 'N', 2, 'T', -38.16, 'efe_av', -19.08), ('a', 3, 'child id', 30, 'N', 3, 'T', -56.05, 'efe_av', -18.68), ('a', 5, 'child id', 43, 'N', 2, 'T', -37.13, 'efe_av', -18.56)]\n",
      "2025-06-17 18:50:28,442 - INFO - --- Simulation 14/30 ---\n",
      "2025-06-17 18:50:28,443 - INFO - --- Selection Phase End (Selected Node: 45) ---\n",
      "2025-06-17 18:50:28,475 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:28,476 - INFO - from node 45 -> Child Node 44, expanding with action 2(Initial full=-8.921, G=-9.935 H=0.008)\n",
      "2025-06-17 18:50:28,503 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:28,505 - INFO - from node 45 -> Child Node 48, expanding with action 4(Initial full=-9.857, G=-9.891 H=0.018)\n",
      "2025-06-17 18:50:28,520 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:28,522 - INFO - from node 45 -> Child Node 49, expanding with action 5(Initial full=-9.869, G=-9.929 H=0.009)\n",
      "2025-06-17 18:50:28,540 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:28,545 - INFO - from node 45 -> Child Node 50, expanding with action 6(Initial full=-9.827, G=-9.898 H=0.016)\n",
      "2025-06-17 18:50:28,604 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:28,605 - INFO - from node 45 -> Child Node 45, expanding with action 12(Initial full=-9.776, G=-9.886 H=0.017)\n",
      "2025-06-17 18:50:28,618 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:28,632 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:28,647 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:28,662 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:28,670 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:28,671 - INFO - Root node children stats: [('a', 0, 'child id', 39, 'N', 3, 'T', -54.5, 'efe_av', -18.17), ('a', 1, 'child id', 15, 'N', 2, 'T', -37.18, 'efe_av', -18.59), ('a', 2, 'child id', 14, 'N', 2, 'T', -38.16, 'efe_av', -19.08), ('a', 3, 'child id', 30, 'N', 3, 'T', -56.05, 'efe_av', -18.68), ('a', 5, 'child id', 43, 'N', 3, 'T', -56.77, 'efe_av', -18.92)]\n",
      "2025-06-17 18:50:28,672 - INFO - --- Simulation 15/30 ---\n",
      "2025-06-17 18:50:28,673 - INFO - --- Selection Phase End (Selected Node: 35) ---\n",
      "2025-06-17 18:50:28,696 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:28,697 - INFO - from node 35 -> Child Node 32, expanding with action 1(Initial full=-9.750, G=-9.897 H=0.147)\n",
      "2025-06-17 18:50:28,709 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:28,712 - INFO - from node 35 -> Child Node 24, expanding with action 2(Initial full=-9.805, G=-9.925 H=0.120)\n",
      "2025-06-17 18:50:28,724 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:28,725 - INFO - from node 35 -> Child Node 22, expanding with action 3(Initial full=-9.479, G=-9.943 H=0.110)\n",
      "2025-06-17 18:50:28,747 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:28,748 - INFO - from node 35 -> Child Node 13, expanding with action 5(Initial full=-9.610, G=-9.931 H=0.124)\n",
      "2025-06-17 18:50:28,758 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:28,760 - INFO - from node 35 -> Child Node 14, expanding with action 6(Initial full=-9.395, G=-9.891 H=0.231)\n",
      "2025-06-17 18:50:28,788 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:28,789 - INFO - from node 35 -> Child Node 36, expanding with action 9(Initial full=-9.334, G=-9.847 H=0.326)\n",
      "2025-06-17 18:50:28,803 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:28,804 - INFO - from node 35 -> Child Node 41, expanding with action 10(Initial full=-8.976, G=-9.881 H=0.266)\n",
      "2025-06-17 18:50:28,819 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:28,820 - INFO - from node 35 -> Child Node 40, expanding with action 11(Initial full=-9.576, G=-9.868 H=0.292)\n",
      "2025-06-17 18:50:28,829 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:28,831 - INFO - from node 35 -> Child Node 35, expanding with action 12(Initial full=-9.594, G=-9.936 H=0.197)\n",
      "2025-06-17 18:50:28,846 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:28,859 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:28,871 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:28,883 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:28,895 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:28,908 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:28,925 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:28,938 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:28,948 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:28,950 - INFO - Root node children stats: [('a', 0, 'child id', 39, 'N', 3, 'T', -54.5, 'efe_av', -18.17), ('a', 1, 'child id', 15, 'N', 3, 'T', -56.29, 'efe_av', -18.76), ('a', 2, 'child id', 14, 'N', 2, 'T', -38.16, 'efe_av', -19.08), ('a', 3, 'child id', 30, 'N', 3, 'T', -56.05, 'efe_av', -18.68), ('a', 5, 'child id', 43, 'N', 3, 'T', -56.77, 'efe_av', -18.92)]\n",
      "2025-06-17 18:50:28,951 - INFO - --- Simulation 16/30 ---\n",
      "2025-06-17 18:50:28,953 - INFO - --- Selection Phase End (Selected Node: 22) ---\n",
      "2025-06-17 18:50:28,979 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:28,981 - INFO - from node 22 -> Child Node 24, expanding with action 1(Initial full=-9.730, G=-9.896 H=0.166)\n",
      "2025-06-17 18:50:29,002 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:29,003 - INFO - from node 22 -> Child Node 21, expanding with action 3(Initial full=-9.767, G=-9.940 H=0.140)\n",
      "2025-06-17 18:50:29,024 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:29,028 - INFO - from node 22 -> Child Node 12, expanding with action 5(Initial full=-9.806, G=-9.933 H=0.127)\n",
      "2025-06-17 18:50:29,042 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:29,046 - INFO - from node 22 -> Child Node 13, expanding with action 6(Initial full=-9.610, G=-9.884 H=0.176)\n",
      "2025-06-17 18:50:29,104 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:29,107 - INFO - from node 22 -> Child Node 35, expanding with action 9(Initial full=-9.565, G=-9.842 H=0.277)\n",
      "2025-06-17 18:50:29,141 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:29,143 - INFO - from node 22 -> Child Node 40, expanding with action 10(Initial full=-9.576, G=-9.860 H=0.282)\n",
      "2025-06-17 18:50:29,161 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:29,165 - INFO - from node 22 -> Child Node 32, expanding with action 11(Initial full=-9.567, G=-9.864 H=0.297)\n",
      "2025-06-17 18:50:29,178 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:29,181 - INFO - from node 22 -> Child Node 22, expanding with action 12(Initial full=-9.479, G=-9.934 H=0.139)\n",
      "2025-06-17 18:50:29,196 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:29,211 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:29,226 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:29,239 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:29,251 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:29,265 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:29,278 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:29,287 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:29,289 - INFO - Root node children stats: [('a', 0, 'child id', 39, 'N', 3, 'T', -54.5, 'efe_av', -18.17), ('a', 1, 'child id', 15, 'N', 3, 'T', -56.29, 'efe_av', -18.76), ('a', 2, 'child id', 14, 'N', 3, 'T', -57.21, 'efe_av', -19.07), ('a', 3, 'child id', 30, 'N', 3, 'T', -56.05, 'efe_av', -18.68), ('a', 5, 'child id', 43, 'N', 3, 'T', -56.77, 'efe_av', -18.92)]\n",
      "2025-06-17 18:50:29,291 - INFO - --- Simulation 17/30 ---\n",
      "2025-06-17 18:50:29,293 - INFO - --- Selection Phase End (Selected Node: 54) ---\n",
      "2025-06-17 18:50:29,323 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:29,324 - INFO - from node 54 -> Child Node 41, expanding with action 2(Initial full=-8.976, G=-9.924 H=0.010)\n",
      "2025-06-17 18:50:29,337 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:29,339 - INFO - from node 54 -> Child Node 36, expanding with action 3(Initial full=-9.334, G=-9.923 H=0.011)\n",
      "2025-06-17 18:50:29,406 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:29,407 - INFO - from node 54 -> Child Node 54, expanding with action 12(Initial full=-9.039, G=-9.624 H=0.077)\n",
      "2025-06-17 18:50:29,419 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:29,432 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:29,440 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:29,442 - INFO - Root node children stats: [('a', 0, 'child id', 39, 'N', 4, 'T', -73.09, 'efe_av', -18.27), ('a', 1, 'child id', 15, 'N', 3, 'T', -56.29, 'efe_av', -18.76), ('a', 2, 'child id', 14, 'N', 3, 'T', -57.21, 'efe_av', -19.07), ('a', 3, 'child id', 30, 'N', 3, 'T', -56.05, 'efe_av', -18.68), ('a', 5, 'child id', 43, 'N', 3, 'T', -56.77, 'efe_av', -18.92)]\n",
      "2025-06-17 18:50:29,444 - INFO - --- Simulation 18/30 ---\n",
      "2025-06-17 18:50:29,446 - INFO - --- Selection Phase End (Selected Node: 10) ---\n",
      "2025-06-17 18:50:29,458 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:29,459 - INFO - from node 10 -> Child Node 28, expanding with action 0(Initial full=-8.928, G=-9.765 H=0.837)\n",
      "2025-06-17 18:50:29,472 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:29,474 - INFO - from node 10 -> Child Node 9, expanding with action 1(Initial full=-9.346, G=-9.909 H=0.563)\n",
      "2025-06-17 18:50:29,493 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:29,495 - INFO - from node 10 -> Child Node 26, expanding with action 2(Initial full=-9.558, G=-9.933 H=0.375)\n",
      "2025-06-17 18:50:29,515 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:29,517 - INFO - from node 10 -> Child Node 46, expanding with action 3(Initial full=-9.590, G=-9.942 H=0.353)\n",
      "2025-06-17 18:50:29,534 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:29,536 - INFO - from node 10 -> Child Node 55, expanding with action 4(Initial full=-9.547, G=-9.896 H=0.349)\n",
      "2025-06-17 18:50:29,553 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:29,554 - INFO - from node 10 -> Child Node 52, expanding with action 5(Initial full=-9.537, G=-9.938 H=0.400)\n",
      "2025-06-17 18:50:29,570 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:29,571 - INFO - from node 10 -> Child Node 47, expanding with action 6(Initial full=-9.436, G=-9.879 H=0.443)\n",
      "2025-06-17 18:50:29,582 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:29,584 - INFO - from node 10 -> Child Node 11, expanding with action 7(Initial full=-9.386, G=-9.870 H=0.484)\n",
      "2025-06-17 18:50:29,603 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:29,605 - INFO - from node 10 -> Child Node 48, expanding with action 8(Initial full=-9.254, G=-9.841 H=0.587)\n",
      "2025-06-17 18:50:29,636 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:29,637 - INFO - from node 10 -> Child Node 34, expanding with action 11(Initial full=-8.790, G=-9.792 H=1.003)\n",
      "2025-06-17 18:50:29,647 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:29,648 - INFO - from node 10 -> Child Node 10, expanding with action 12(Initial full=-9.443, G=-9.935 H=0.491)\n",
      "2025-06-17 18:50:29,665 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:29,676 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:29,689 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:29,705 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:29,722 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:29,738 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:29,754 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:29,768 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:29,786 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:29,803 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:29,813 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:29,814 - INFO - Root node children stats: [('a', 0, 'child id', 39, 'N', 4, 'T', -73.09, 'efe_av', -18.27), ('a', 1, 'child id', 15, 'N', 3, 'T', -56.29, 'efe_av', -18.76), ('a', 2, 'child id', 14, 'N', 3, 'T', -57.21, 'efe_av', -19.07), ('a', 3, 'child id', 30, 'N', 4, 'T', -74.29, 'efe_av', -18.57), ('a', 5, 'child id', 43, 'N', 3, 'T', -56.77, 'efe_av', -18.92)]\n",
      "2025-06-17 18:50:29,816 - INFO - --- Simulation 19/30 ---\n",
      "2025-06-17 18:50:29,817 - INFO - --- Selection Phase End (Selected Node: 40) ---\n",
      "2025-06-17 18:50:29,857 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:29,858 - INFO - from node 40 -> Child Node 32, expanding with action 3(Initial full=-9.567, G=-9.946 H=0.007)\n",
      "2025-06-17 18:50:29,868 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:29,869 - INFO - from node 40 -> Child Node 22, expanding with action 4(Initial full=-9.479, G=-9.884 H=0.020)\n",
      "2025-06-17 18:50:29,881 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:29,882 - INFO - from node 40 -> Child Node 35, expanding with action 5(Initial full=-9.565, G=-9.932 H=0.009)\n",
      "2025-06-17 18:50:29,920 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:29,921 - INFO - from node 40 -> Child Node 41, expanding with action 9(Initial full=-8.976, G=-9.235 H=0.174)\n",
      "2025-06-17 18:50:29,947 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:29,949 - INFO - from node 40 -> Child Node 40, expanding with action 12(Initial full=-9.576, G=-9.941 H=0.008)\n",
      "2025-06-17 18:50:29,962 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:29,973 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:29,985 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:30,002 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:30,010 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:30,012 - INFO - Root node children stats: [('a', 0, 'child id', 39, 'N', 5, 'T', -91.72, 'efe_av', -18.34), ('a', 1, 'child id', 15, 'N', 3, 'T', -56.29, 'efe_av', -18.76), ('a', 2, 'child id', 14, 'N', 3, 'T', -57.21, 'efe_av', -19.07), ('a', 3, 'child id', 30, 'N', 4, 'T', -74.29, 'efe_av', -18.57), ('a', 5, 'child id', 43, 'N', 3, 'T', -56.77, 'efe_av', -18.92)]\n",
      "2025-06-17 18:50:30,013 - INFO - --- Simulation 20/30 ---\n",
      "2025-06-17 18:50:30,014 - INFO - --- Selection Phase End (Selected Node: 32) ---\n",
      "2025-06-17 18:50:30,047 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:30,048 - INFO - from node 32 -> Child Node 37, expanding with action 2(Initial full=-9.769, G=-9.922 H=0.153)\n",
      "2025-06-17 18:50:30,058 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:30,059 - INFO - from node 32 -> Child Node 24, expanding with action 3(Initial full=-9.730, G=-9.934 H=0.156)\n",
      "2025-06-17 18:50:30,070 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:30,071 - INFO - from node 32 -> Child Node 21, expanding with action 4(Initial full=-9.751, G=-9.891 H=0.140)\n",
      "2025-06-17 18:50:30,083 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:30,085 - INFO - from node 32 -> Child Node 22, expanding with action 5(Initial full=-9.479, G=-9.928 H=0.136)\n",
      "2025-06-17 18:50:30,114 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:30,116 - INFO - from node 32 -> Child Node 35, expanding with action 7(Initial full=-9.565, G=-9.865 H=0.228)\n",
      "2025-06-17 18:50:30,138 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:30,139 - INFO - from node 32 -> Child Node 40, expanding with action 9(Initial full=-9.576, G=-9.843 H=0.239)\n",
      "2025-06-17 18:50:30,168 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:30,170 - INFO - from node 32 -> Child Node 32, expanding with action 12(Initial full=-9.567, G=-9.934 H=0.148)\n",
      "2025-06-17 18:50:30,182 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:30,197 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:30,208 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:30,222 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:30,235 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:30,252 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:30,267 - INFO - Final States to inflate H [14 15 29 30 31 35 36 39 43]\n",
      "2025-06-17 18:50:30,269 - INFO - Root node children stats: [('a', 0, 'child id', 39, 'N', 6, 'T', -110.89, 'efe_av', -18.48), ('a', 1, 'child id', 15, 'N', 3, 'T', -56.29, 'efe_av', -18.76), ('a', 2, 'child id', 14, 'N', 3, 'T', -57.21, 'efe_av', -19.07), ('a', 3, 'child id', 30, 'N', 4, 'T', -74.29, 'efe_av', -18.57), ('a', 5, 'child id', 43, 'N', 3, 'T', -56.77, 'efe_av', -18.92)]\n",
      "2025-06-17 18:50:30,271 - INFO - --- Simulation 21/30 ---\n",
      "2025-06-17 18:50:30,273 - INFO - --- Selection Phase End (Selected Node: 12) ---\n",
      "2025-06-17 18:50:30,287 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:30,289 - INFO - from node 12 -> Child Node 21, expanding with action 0(Initial full=-9.083, G=-9.714 H=0.631)\n",
      "2025-06-17 18:50:30,312 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:30,314 - INFO - from node 12 -> Child Node 1, expanding with action 2(Initial full=-9.602, G=-9.935 H=0.334)\n",
      "2025-06-17 18:50:30,324 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:30,326 - INFO - from node 12 -> Child Node 0, expanding with action 3(Initial full=-9.623, G=-9.946 H=0.323)\n",
      "2025-06-17 18:50:30,337 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:30,338 - INFO - from node 12 -> Child Node 6, expanding with action 4(Initial full=-9.546, G=-9.904 H=0.358)\n",
      "2025-06-17 18:50:30,352 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:30,354 - INFO - from node 12 -> Child Node 8, expanding with action 5(Initial full=-9.560, G=-9.936 H=0.376)\n",
      "2025-06-17 18:50:30,369 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:30,371 - INFO - from node 12 -> Child Node 9, expanding with action 6(Initial full=-9.346, G=-9.909 H=0.539)\n",
      "2025-06-17 18:50:30,388 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:30,390 - INFO - from node 12 -> Child Node 28, expanding with action 7(Initial full=-8.928, G=-9.870 H=0.590)\n",
      "2025-06-17 18:50:30,412 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:30,415 - INFO - from node 12 -> Child Node 13, expanding with action 9(Initial full=-9.020, G=-9.877 H=0.857)\n",
      "2025-06-17 18:50:30,445 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:30,447 - INFO - from node 12 -> Child Node 22, expanding with action 11(Initial full=-8.994, G=-9.884 H=0.890)\n",
      "2025-06-17 18:50:30,459 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:30,461 - INFO - from node 12 -> Child Node 12, expanding with action 12(Initial full=-9.529, G=-9.947 H=0.418)\n",
      "2025-06-17 18:50:30,476 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:30,489 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:30,500 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:30,514 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:30,530 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:30,550 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:30,567 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:30,579 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:30,591 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:30,601 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:30,602 - INFO - Root node children stats: [('a', 0, 'child id', 39, 'N', 6, 'T', -110.89, 'efe_av', -18.48), ('a', 1, 'child id', 15, 'N', 3, 'T', -56.29, 'efe_av', -18.76), ('a', 2, 'child id', 14, 'N', 4, 'T', -75.73, 'efe_av', -18.93), ('a', 3, 'child id', 30, 'N', 4, 'T', -74.29, 'efe_av', -18.57), ('a', 5, 'child id', 43, 'N', 3, 'T', -56.77, 'efe_av', -18.92)]\n",
      "2025-06-17 18:50:30,603 - INFO - --- Simulation 22/30 ---\n",
      "2025-06-17 18:50:30,605 - INFO - --- Selection Phase End (Selected Node: 28) ---\n",
      "2025-06-17 18:50:30,628 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:30,629 - INFO - from node 28 -> Child Node 12, expanding with action 1(Initial full=-9.529, G=-9.901 H=0.017)\n",
      "2025-06-17 18:50:30,638 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:30,639 - INFO - from node 28 -> Child Node 0, expanding with action 2(Initial full=-9.623, G=-9.930 H=0.009)\n",
      "2025-06-17 18:50:30,651 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:30,652 - INFO - from node 28 -> Child Node 8, expanding with action 3(Initial full=-9.560, G=-9.942 H=0.007)\n",
      "2025-06-17 18:50:30,669 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:30,670 - INFO - from node 28 -> Child Node 26, expanding with action 4(Initial full=-9.558, G=-9.860 H=0.026)\n",
      "2025-06-17 18:50:30,683 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:30,684 - INFO - from node 28 -> Child Node 9, expanding with action 5(Initial full=-9.346, G=-9.934 H=0.009)\n",
      "2025-06-17 18:50:30,696 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:30,697 - INFO - from node 28 -> Child Node 10, expanding with action 6(Initial full=-9.443, G=-9.891 H=0.018)\n",
      "2025-06-17 18:50:30,712 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:30,714 - INFO - from node 28 -> Child Node 34, expanding with action 7(Initial full=-8.790, G=-9.326 H=0.150)\n",
      "2025-06-17 18:50:30,746 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:30,748 - INFO - from node 28 -> Child Node 14, expanding with action 10(Initial full=-9.395, G=-9.847 H=0.028)\n",
      "2025-06-17 18:50:30,761 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:30,762 - INFO - from node 28 -> Child Node 13, expanding with action 11(Initial full=-9.020, G=-9.808 H=0.040)\n",
      "2025-06-17 18:50:30,772 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:30,773 - INFO - from node 28 -> Child Node 28, expanding with action 12(Initial full=-8.928, G=-9.882 H=0.020)\n",
      "2025-06-17 18:50:30,786 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:30,796 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:30,810 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:30,831 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:30,844 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:30,855 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:30,869 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:30,881 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:30,891 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:30,901 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:30,902 - INFO - Root node children stats: [('a', 0, 'child id', 39, 'N', 6, 'T', -110.89, 'efe_av', -18.48), ('a', 1, 'child id', 15, 'N', 3, 'T', -56.29, 'efe_av', -18.76), ('a', 2, 'child id', 14, 'N', 5, 'T', -93.84, 'efe_av', -18.77), ('a', 3, 'child id', 30, 'N', 4, 'T', -74.29, 'efe_av', -18.57), ('a', 5, 'child id', 43, 'N', 3, 'T', -56.77, 'efe_av', -18.92)]\n",
      "2025-06-17 18:50:30,903 - INFO - --- Simulation 23/30 ---\n",
      "2025-06-17 18:50:30,904 - INFO - --- Selection Phase End (Selected Node: 9) ---\n",
      "2025-06-17 18:50:30,917 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:30,919 - INFO - from node 9 -> Child Node 12, expanding with action 0(Initial full=-9.529, G=-9.791 H=0.042)\n",
      "2025-06-17 18:50:30,933 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:30,935 - INFO - from node 9 -> Child Node 8, expanding with action 1(Initial full=-9.560, G=-9.910 H=0.015)\n",
      "2025-06-17 18:50:30,947 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:30,949 - INFO - from node 9 -> Child Node 6, expanding with action 2(Initial full=-9.546, G=-9.931 H=0.009)\n",
      "2025-06-17 18:50:30,964 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:30,966 - INFO - from node 9 -> Child Node 26, expanding with action 3(Initial full=-9.558, G=-9.944 H=0.007)\n",
      "2025-06-17 18:50:30,979 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:30,981 - INFO - from node 9 -> Child Node 27, expanding with action 4(Initial full=-9.842, G=-9.867 H=0.025)\n",
      "2025-06-17 18:50:30,996 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:30,998 - INFO - from node 9 -> Child Node 46, expanding with action 5(Initial full=-9.590, G=-9.935 H=0.009)\n",
      "2025-06-17 18:50:31,013 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:31,014 - INFO - from node 9 -> Child Node 52, expanding with action 6(Initial full=-9.537, G=-9.892 H=0.017)\n",
      "2025-06-17 18:50:31,028 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:31,030 - INFO - from node 9 -> Child Node 10, expanding with action 7(Initial full=-9.330, G=-9.451 H=0.121)\n",
      "2025-06-17 18:50:31,056 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:31,058 - INFO - from node 9 -> Child Node 34, expanding with action 9(Initial full=-8.790, G=-9.811 H=0.038)\n",
      "2025-06-17 18:50:31,078 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:31,080 - INFO - from node 9 -> Child Node 28, expanding with action 11(Initial full=-8.928, G=-9.791 H=0.043)\n",
      "2025-06-17 18:50:31,089 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:31,090 - INFO - from node 9 -> Child Node 9, expanding with action 12(Initial full=-9.346, G=-9.862 H=0.026)\n",
      "2025-06-17 18:50:31,101 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:31,112 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:31,122 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:31,132 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:31,146 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:31,164 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:31,178 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:31,190 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:31,213 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:31,241 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:31,260 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:31,263 - INFO - Root node children stats: [('a', 0, 'child id', 39, 'N', 6, 'T', -110.89, 'efe_av', -18.48), ('a', 1, 'child id', 15, 'N', 4, 'T', -74.97, 'efe_av', -18.74), ('a', 2, 'child id', 14, 'N', 5, 'T', -93.84, 'efe_av', -18.77), ('a', 3, 'child id', 30, 'N', 4, 'T', -74.29, 'efe_av', -18.57), ('a', 5, 'child id', 43, 'N', 3, 'T', -56.77, 'efe_av', -18.92)]\n",
      "2025-06-17 18:50:31,264 - INFO - --- Simulation 24/30 ---\n",
      "2025-06-17 18:50:31,270 - INFO - --- Selection Phase End (Selected Node: 11) ---\n",
      "2025-06-17 18:50:31,299 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:31,306 - INFO - from node 11 -> Child Node 34, expanding with action 0(Initial full=-8.790, G=-9.718 H=0.866)\n",
      "2025-06-17 18:50:31,327 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:31,331 - INFO - from node 11 -> Child Node 10, expanding with action 1(Initial full=-9.292, G=-9.891 H=0.599)\n",
      "2025-06-17 18:50:31,356 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:31,360 - INFO - from node 11 -> Child Node 46, expanding with action 2(Initial full=-9.528, G=-9.935 H=0.408)\n",
      "2025-06-17 18:50:31,379 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:31,381 - INFO - from node 11 -> Child Node 52, expanding with action 3(Initial full=-9.537, G=-9.938 H=0.398)\n",
      "2025-06-17 18:50:31,411 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:31,413 - INFO - from node 11 -> Child Node 47, expanding with action 5(Initial full=-9.436, G=-9.934 H=0.464)\n",
      "2025-06-17 18:50:31,447 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:31,448 - INFO - from node 11 -> Child Node 49, expanding with action 8(Initial full=-9.146, G=-9.775 H=0.628)\n",
      "2025-06-17 18:50:31,462 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:31,464 - INFO - from node 11 -> Child Node 48, expanding with action 9(Initial full=-8.780, G=-9.744 H=0.964)\n",
      "2025-06-17 18:50:31,493 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:31,495 - INFO - from node 11 -> Child Node 11, expanding with action 12(Initial full=-9.386, G=-9.889 H=0.481)\n",
      "2025-06-17 18:50:31,506 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:31,519 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:31,535 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:31,553 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:31,568 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:31,583 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:31,599 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:31,608 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:31,610 - INFO - Root node children stats: [('a', 0, 'child id', 39, 'N', 6, 'T', -110.89, 'efe_av', -18.48), ('a', 1, 'child id', 15, 'N', 4, 'T', -74.97, 'efe_av', -18.74), ('a', 2, 'child id', 14, 'N', 5, 'T', -93.84, 'efe_av', -18.77), ('a', 3, 'child id', 30, 'N', 5, 'T', -92.45, 'efe_av', -18.49), ('a', 5, 'child id', 43, 'N', 3, 'T', -56.77, 'efe_av', -18.92)]\n",
      "2025-06-17 18:50:31,612 - INFO - --- Simulation 25/30 ---\n",
      "2025-06-17 18:50:31,614 - INFO - --- Selection Phase End (Selected Node: 50) ---\n",
      "2025-06-17 18:50:31,628 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:31,629 - INFO - from node 50 -> Child Node 45, expanding with action 0(Initial full=-8.523, G=-9.510 H=0.987)\n",
      "2025-06-17 18:50:31,653 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:31,655 - INFO - from node 50 -> Child Node 48, expanding with action 2(Initial full=-8.780, G=-9.935 H=0.552)\n",
      "2025-06-17 18:50:31,678 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:31,680 - INFO - from node 50 -> Child Node 49, expanding with action 4(Initial full=-9.146, G=-9.872 H=0.532)\n",
      "2025-06-17 18:50:31,748 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:31,749 - INFO - from node 50 -> Child Node 50, expanding with action 12(Initial full=-9.147, G=-9.854 H=0.707)\n",
      "2025-06-17 18:50:31,762 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:31,777 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:31,793 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:31,803 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:31,805 - INFO - Root node children stats: [('a', 0, 'child id', 39, 'N', 6, 'T', -110.89, 'efe_av', -18.48), ('a', 1, 'child id', 15, 'N', 4, 'T', -74.97, 'efe_av', -18.74), ('a', 2, 'child id', 14, 'N', 5, 'T', -93.84, 'efe_av', -18.77), ('a', 3, 'child id', 30, 'N', 6, 'T', -110.12, 'efe_av', -18.35), ('a', 5, 'child id', 43, 'N', 3, 'T', -56.77, 'efe_av', -18.92)]\n",
      "2025-06-17 18:50:31,806 - INFO - --- Simulation 26/30 ---\n",
      "2025-06-17 18:50:31,807 - INFO - --- Selection Phase End (Selected Node: 46) ---\n",
      "2025-06-17 18:50:31,817 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:31,819 - INFO - from node 46 -> Child Node 8, expanding with action 0(Initial full=-9.168, G=-9.790 H=0.623)\n",
      "2025-06-17 18:50:31,834 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:31,836 - INFO - from node 46 -> Child Node 26, expanding with action 1(Initial full=-9.438, G=-9.912 H=0.474)\n",
      "2025-06-17 18:50:31,849 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:31,851 - INFO - from node 46 -> Child Node 7, expanding with action 2(Initial full=-9.547, G=-9.932 H=0.385)\n",
      "2025-06-17 18:50:31,865 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:31,866 - INFO - from node 46 -> Child Node 27, expanding with action 3(Initial full=-9.571, G=-9.943 H=0.372)\n",
      "2025-06-17 18:50:31,883 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:31,885 - INFO - from node 46 -> Child Node 56, expanding with action 4(Initial full=-9.476, G=-9.863 H=0.388)\n",
      "2025-06-17 18:50:31,900 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:31,901 - INFO - from node 46 -> Child Node 55, expanding with action 5(Initial full=-9.515, G=-9.929 H=0.414)\n",
      "2025-06-17 18:50:31,929 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:31,931 - INFO - from node 46 -> Child Node 52, expanding with action 7(Initial full=-9.250, G=-9.766 H=0.516)\n",
      "2025-06-17 18:50:31,948 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:31,950 - INFO - from node 46 -> Child Node 10, expanding with action 9(Initial full=-9.027, G=-9.813 H=0.786)\n",
      "2025-06-17 18:50:31,966 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:31,968 - INFO - from node 46 -> Child Node 34, expanding with action 10(Initial full=-8.790, G=-9.826 H=0.902)\n",
      "2025-06-17 18:50:31,979 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:31,981 - INFO - from node 46 -> Child Node 9, expanding with action 11(Initial full=-8.923, G=-9.791 H=0.868)\n",
      "2025-06-17 18:50:31,991 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:31,993 - INFO - from node 46 -> Child Node 46, expanding with action 12(Initial full=-9.474, G=-9.866 H=0.392)\n",
      "2025-06-17 18:50:32,006 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:32,021 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:32,033 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:32,046 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:32,063 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:32,076 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:32,093 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:32,103 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:32,117 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:32,130 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:32,139 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:32,141 - INFO - Root node children stats: [('a', 0, 'child id', 39, 'N', 6, 'T', -110.89, 'efe_av', -18.48), ('a', 1, 'child id', 15, 'N', 4, 'T', -74.97, 'efe_av', -18.74), ('a', 2, 'child id', 14, 'N', 5, 'T', -93.84, 'efe_av', -18.77), ('a', 3, 'child id', 30, 'N', 7, 'T', -128.52, 'efe_av', -18.36), ('a', 5, 'child id', 43, 'N', 3, 'T', -56.77, 'efe_av', -18.92)]\n",
      "2025-06-17 18:50:32,142 - INFO - --- Simulation 27/30 ---\n",
      "2025-06-17 18:50:32,144 - INFO - --- Selection Phase End (Selected Node: 52) ---\n",
      "2025-06-17 18:50:32,156 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:32,157 - INFO - from node 52 -> Child Node 9, expanding with action 0(Initial full=-8.923, G=-9.754 H=0.753)\n",
      "2025-06-17 18:50:32,175 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:32,176 - INFO - from node 52 -> Child Node 46, expanding with action 1(Initial full=-9.429, G=-9.910 H=0.481)\n",
      "2025-06-17 18:50:32,193 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:32,197 - INFO - from node 52 -> Child Node 27, expanding with action 2(Initial full=-9.571, G=-9.932 H=0.348)\n",
      "2025-06-17 18:50:32,243 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:32,248 - INFO - from node 52 -> Child Node 55, expanding with action 3(Initial full=-9.515, G=-9.928 H=0.336)\n",
      "2025-06-17 18:50:32,327 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:32,333 - INFO - from node 52 -> Child Node 47, expanding with action 7(Initial full=-9.311, G=-9.861 H=0.549)\n",
      "2025-06-17 18:50:32,368 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:32,369 - INFO - from node 52 -> Child Node 10, expanding with action 11(Initial full=-8.875, G=-9.778 H=0.903)\n",
      "2025-06-17 18:50:32,378 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:32,379 - INFO - from node 52 -> Child Node 52, expanding with action 12(Initial full=-9.250, G=-9.938 H=0.400)\n",
      "2025-06-17 18:50:32,389 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:32,405 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:32,417 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:32,434 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:32,454 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:32,467 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:32,479 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:32,481 - INFO - Root node children stats: [('a', 0, 'child id', 39, 'N', 6, 'T', -110.89, 'efe_av', -18.48), ('a', 1, 'child id', 15, 'N', 4, 'T', -74.97, 'efe_av', -18.74), ('a', 2, 'child id', 14, 'N', 5, 'T', -93.84, 'efe_av', -18.77), ('a', 3, 'child id', 30, 'N', 8, 'T', -146.64, 'efe_av', -18.33), ('a', 5, 'child id', 43, 'N', 3, 'T', -56.77, 'efe_av', -18.92)]\n",
      "2025-06-17 18:50:32,483 - INFO - --- Simulation 28/30 ---\n",
      "2025-06-17 18:50:32,484 - INFO - --- Selection Phase End (Selected Node: 47) ---\n",
      "2025-06-17 18:50:32,496 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:32,497 - INFO - from node 47 -> Child Node 10, expanding with action 0(Initial full=-8.861, G=-9.698 H=0.837)\n",
      "2025-06-17 18:50:32,515 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:32,517 - INFO - from node 47 -> Child Node 52, expanding with action 1(Initial full=-9.250, G=-9.900 H=0.602)\n",
      "2025-06-17 18:50:32,533 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:32,534 - INFO - from node 47 -> Child Node 55, expanding with action 2(Initial full=-9.515, G=-9.931 H=0.403)\n",
      "2025-06-17 18:50:32,606 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:32,607 - INFO - from node 47 -> Child Node 49, expanding with action 9(Initial full=-8.936, G=-9.795 H=0.859)\n",
      "2025-06-17 18:50:32,627 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:32,628 - INFO - from node 47 -> Child Node 47, expanding with action 12(Initial full=-9.311, G=-9.879 H=0.443)\n",
      "2025-06-17 18:50:32,638 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:32,654 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:32,670 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:32,686 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:32,695 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:32,697 - INFO - Root node children stats: [('a', 0, 'child id', 39, 'N', 6, 'T', -110.89, 'efe_av', -18.48), ('a', 1, 'child id', 15, 'N', 4, 'T', -74.97, 'efe_av', -18.74), ('a', 2, 'child id', 14, 'N', 5, 'T', -93.84, 'efe_av', -18.77), ('a', 3, 'child id', 30, 'N', 9, 'T', -164.82, 'efe_av', -18.31), ('a', 5, 'child id', 43, 'N', 3, 'T', -56.77, 'efe_av', -18.92)]\n",
      "2025-06-17 18:50:32,698 - INFO - --- Simulation 29/30 ---\n",
      "2025-06-17 18:50:32,699 - INFO - --- Selection Phase End (Selected Node: 49) ---\n",
      "2025-06-17 18:50:32,718 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:32,719 - INFO - from node 49 -> Child Node 48, expanding with action 0(Initial full=-8.780, G=-9.205 H=0.180)\n",
      "2025-06-17 18:50:32,748 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:32,750 - INFO - from node 49 -> Child Node 47, expanding with action 3(Initial full=-9.311, G=-9.934 H=0.007)\n",
      "2025-06-17 18:50:32,812 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:32,814 - INFO - from node 49 -> Child Node 50, expanding with action 10(Initial full=-9.147, G=-9.854 H=0.023)\n",
      "2025-06-17 18:50:32,824 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:32,825 - INFO - from node 49 -> Child Node 45, expanding with action 11(Initial full=-8.523, G=-9.315 H=0.155)\n",
      "2025-06-17 18:50:32,834 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:32,835 - INFO - from node 49 -> Child Node 49, expanding with action 12(Initial full=-8.936, G=-9.886 H=0.017)\n",
      "2025-06-17 18:50:32,852 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:32,868 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:32,880 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:32,894 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:32,903 - INFO - Final States to inflate H [15]\n",
      "2025-06-17 18:50:32,904 - INFO - Root node children stats: [('a', 0, 'child id', 39, 'N', 6, 'T', -110.89, 'efe_av', -18.48), ('a', 1, 'child id', 15, 'N', 4, 'T', -74.97, 'efe_av', -18.74), ('a', 2, 'child id', 14, 'N', 5, 'T', -93.84, 'efe_av', -18.77), ('a', 3, 'child id', 30, 'N', 9, 'T', -164.82, 'efe_av', -18.31), ('a', 5, 'child id', 43, 'N', 4, 'T', -74.74, 'efe_av', -18.68)]\n",
      "2025-06-17 18:50:32,905 - INFO - --- Simulation 30/30 ---\n",
      "2025-06-17 18:50:32,907 - INFO - --- Selection Phase End (Selected Node: 8) ---\n",
      "2025-06-17 18:50:32,925 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:32,926 - INFO - from node 8 -> Child Node 0, expanding with action 1(Initial full=-9.407, G=-9.904 H=0.497)\n",
      "2025-06-17 18:50:32,947 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:32,948 - INFO - from node 8 -> Child Node 6, expanding with action 3(Initial full=-9.546, G=-9.941 H=0.364)\n",
      "2025-06-17 18:50:32,962 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:32,964 - INFO - from node 8 -> Child Node 7, expanding with action 4(Initial full=-9.476, G=-9.864 H=0.388)\n",
      "2025-06-17 18:50:32,979 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:32,980 - INFO - from node 8 -> Child Node 26, expanding with action 5(Initial full=-9.438, G=-9.929 H=0.405)\n",
      "2025-06-17 18:50:33,012 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:33,013 - INFO - from node 8 -> Child Node 9, expanding with action 7(Initial full=-8.923, G=-9.819 H=0.603)\n",
      "2025-06-17 18:50:33,028 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:33,030 - INFO - from node 8 -> Child Node 34, expanding with action 8(Initial full=-8.790, G=-9.764 H=0.656)\n",
      "2025-06-17 18:50:33,049 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:33,052 - INFO - from node 8 -> Child Node 28, expanding with action 9(Initial full=-8.928, G=-9.822 H=0.769)\n",
      "2025-06-17 18:50:33,070 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:33,075 - INFO - from node 8 -> Child Node 13, expanding with action 10(Initial full=-8.972, G=-9.853 H=0.881)\n",
      "2025-06-17 18:50:33,110 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:33,112 - INFO - from node 8 -> Child Node 12, expanding with action 11(Initial full=-8.965, G=-9.810 H=0.845)\n",
      "2025-06-17 18:50:33,132 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:33,137 - INFO - from node 8 -> Child Node 8, expanding with action 12(Initial full=-9.168, G=-9.885 H=0.426)\n",
      "2025-06-17 18:50:33,154 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:33,168 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:33,187 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:33,201 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:33,216 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:33,239 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:33,251 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:33,264 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:33,276 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:33,288 - INFO - Final States to inflate H [ 9 12 13 14 15 22 24 28 29 30 31 32 34 35 36 39 40 41 43 44 45 48 54]\n",
      "2025-06-17 18:50:33,290 - INFO - Root node children stats: [('a', 0, 'child id', 39, 'N', 6, 'T', -110.89, 'efe_av', -18.48), ('a', 1, 'child id', 15, 'N', 4, 'T', -74.97, 'efe_av', -18.74), ('a', 2, 'child id', 14, 'N', 6, 'T', -111.97, 'efe_av', -18.66), ('a', 3, 'child id', 30, 'N', 9, 'T', -164.82, 'efe_av', -18.31), ('a', 5, 'child id', 43, 'N', 4, 'T', -74.74, 'efe_av', -18.68)]\n",
      "2025-06-17 18:50:33,291 - INFO - Root node children stats: Action 0: AvgR=-18.482, N=6; Action 1: AvgR=-18.742, N=4; Action 2: AvgR=-18.661, N=6; Action 3: AvgR=-18.313, N=9; Action 5: AvgR=-18.684, N=4\n",
      "2025-06-17 18:50:33,292 - INFO - action average G: [-18.48212262851794, -18.742339561060113, -18.66135384514164, -18.312907231191247, -18.683766324415412]\n",
      "2025-06-17 18:50:33,294 - INFO - softmax policies: [0.06 0.   0.   0.93 0.  ]\n",
      "2025-06-17 18:50:33,295 - INFO - Selected best action based on policy: 3\n",
      "2025-06-17 18:50:33,296 - INFO - Selected Action: 3 ([90, 120])\n",
      "2025-06-17 18:50:33,299 - INFO - Root Node Children Details:\n",
      "  Action 0 ([0, 30]): state=39 AvgR=-18.482, N=6\n",
      "  Action 1 ([30, 60]): state=15 AvgR=-18.742, N=4\n",
      "  Action 2 ([60, 90]): state=14 AvgR=-18.661, N=6\n",
      "  Action 3 ([90, 120]): state=30 AvgR=-18.313, N=9\n",
      "  Action 5 ([150, 180]): state=43 AvgR=-18.684, N=4\n",
      "2025-06-17 18:50:33,302 - INFO - max visits:[(37, 0), (24, 0), (21, 0), (1, 0), (0, 0), (6, 0), (7, 0), (26, 0), (27, 0), (56, 0), (55, 0), (40, 1), (32, 1), (22, 1), (12, 1), (8, 1), (9, 1), (46, 1), (52, 1), (47, 1), (28, 1), (35, 1), (11, 1), (49, 1), (50, 1), (45, 1), (54, 1), (41, 2), (29, 2), (44, 2), (36, 2), (48, 2), (10, 3), (13, 3), (15, 4), (43, 4), (39, 6), (34, 6), (14, 6), (30, 9), (31, 30)], len dict:41\n",
      "/tmp/ipykernel_193623/250434533.py:48: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  plt.figure(figsize=(12, 8))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action visit counts: [6, 4, 6, 9, 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_193623/250434533.py:58: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "2025-06-17 18:50:34,760 - INFO - Executing action 3 -> Transitioning to Node 30\n",
      "2025-06-17 18:50:34,762 - INFO - \n",
      "===== Simulation Finished =====\n",
      "2025-06-17 18:50:34,763 - INFO - Completed 1 steps.\n",
      "2025-06-17 18:50:34,764 - INFO - Final State (Node ID): 30\n"
     ]
    }
   ],
   "source": [
    "for i in range(NUM_STEPS):\n",
    "    logging.info(f\"\\n===== Planning Step {i+1}/{NUM_STEPS} =====\")\n",
    "    logging.info(f\"Current State (Node ID): {current_node.id}\")\n",
    "\n",
    "    # Plan the next action using MCTS\n",
    "    # The root of the search is the current state node\n",
    "    best_action, data = mcts.plan(current_node, NUM_SIMULATIONS, MAX_ROLLOUT_DEPTH, logging=logging, data=data)\n",
    "\n",
    "    if best_action is None:\n",
    "        logging.error(\"MCTS failed to find a best action. Stopping simulation.\")\n",
    "        break\n",
    "\n",
    "    action_name = map_action_names.get(best_action, \"Unknown\")\n",
    "    logging.info(f\"Selected Action: {best_action} ({action_name})\")\n",
    "\n",
    "    # Display action values/visits from the root node\n",
    "    if current_node.childs:\n",
    "        child_info_list = []\n",
    "        for action_id, child in current_node.childs.items():\n",
    "                a_name = map_action_names.get(action_id, \"?\")\n",
    "                child_info_list.append(f\"  Action {action_id} ({a_name}): state={child.id} AvgR={child.get_averaged_reward():.3f}, N={child.N}\")\n",
    "        logging.info(\"Root Node Children Details:\\n\" + \"\\n\".join(child_info_list))\n",
    "        print('Action visit counts:', [current_node.childs[action_id].N for action_id in current_node.childs])\n",
    "    else:\n",
    "            logging.info(\"Root node has no children explored.\")\n",
    "\n",
    "    # Visualize the tree if enabled\n",
    "    if PLOT_TREE:\n",
    "        plot_mcts_tree(current_node)\n",
    "\n",
    "    # --- Execute the selected action ---\n",
    "    # In a real robot, this would involve sending the command and getting sensor feedback.\n",
    "    # Here, we transition to the corresponding child node in the tree.\n",
    "    if best_action in current_node.childs:\n",
    "        next_node = current_node.childs[best_action]\n",
    "        logging.info(f\"Executing action {best_action} -> Transitioning to Node {next_node.id}\")\n",
    "\n",
    "        # IMPORTANT: Detach the chosen next state from its parent (the previous state).\n",
    "        # This makes the chosen next state the new root for the *next* planning step\n",
    "        # and allows the old parts of the tree to be garbage collected.\n",
    "        \n",
    "        #WITH MEMORY\n",
    "        # next_node.detach_parent()\n",
    "        #current_node = next_node # Update the current state\n",
    "\n",
    "        #TMP TO TEST AS IN OUR MODEL\n",
    "\n",
    "        current_node = Node(state_qs=next_node.state_qs,\n",
    "                    pose_id=next_node.pose_id,\n",
    "                    parent=None,\n",
    "                    action_index=None,\n",
    "                    observation=next_node.observation, \n",
    "                    possible_actions=next_node.possible_actions)\n",
    "\n",
    "        # Log information about the new state (optional)\n",
    "        # logging.info(f\"New State Observation (Visual): {current_node.observation[0][0].round(2)}\")\n",
    "        # logging.info(f\"New State Observation (Pose): {current_node.observation[0][1].round(2)}\")\n",
    "\n",
    "    else:\n",
    "        logging.error(f\"Consistency Error: Best action {best_action} not found in children of node {current_node.id}. Stopping.\")\n",
    "        break # Stop if the tree is inconsistent\n",
    "\n",
    "logging.info(f\"\\n===== Simulation Finished =====\")\n",
    "logging.info(f\"Completed {i+1 if 'i' in locals() else 0} steps.\")\n",
    "logging.info(f\"Final State (Node ID): {current_node.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02, 0.  , 0.02, 0.  , 0.  , 0.  , 0.85, 0.  , 0.  , 0.02, 0.  ,\n",
       "       0.02, 0.  ])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H_model.get_B()[3,17,:].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mstop\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST 1 SQUARE MOTION NO OB - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "csvfile = pd.read_csv('/home/idlab332/workspace/ros_ws/pose_obs_test1_v3.csv')\n",
    "# csvfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#START POSE\n",
    "ob_id = 0 #csvfile['ob_id'].values[-1]\n",
    "odom_theta = float(csvfile['theta'].values[0])\n",
    "odom = [0.0,0.0, odom_theta]\n",
    "\n",
    "p_idx = ours.PoseMemory.pose_to_id(odom)\n",
    "obstacle_dists = eval(csvfile['ob_dists'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = ours.get_belief_over_states() #self.qs\n",
    "# agent_state_mapping for TEST PURPOSES\n",
    "ours.update_agent_state_mapping(tuple(odom[:2]), [ob_id,p_idx], qs[0])\n",
    "ours.update_transition_nodes(obstacle_dist_per_actions=obstacle_dists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP1 \n",
    "action_step1 = 10\n",
    "ob_id_step1 = 1 \n",
    "excel_step = 1\n",
    "# p_id = int(csvfile['state'].values[excel_step])\n",
    "pose_x = float(csvfile['Pose x for agent'].values[excel_step])\n",
    "pose_y = float(csvfile['Pose Y for agent'].values[excel_step])\n",
    "theta = float(csvfile['theta'].values[excel_step])\n",
    "p_idx_step1 = ours.PoseMemory.pose_to_id([pose_x,pose_y], save_in_memory=False)\n",
    "pose = ours.PoseMemory.id_to_pose(p_idx_step1)\n",
    "\n",
    "odom_step1 = [pose[0],pose[1], theta]\n",
    "\n",
    "obstacle_dists_step1 = eval(csvfile['ob_dists'].values[excel_step])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_x, pose_y, odom_step1, p_idx_step1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ours.agent_manual_action_step(action_step1)\n",
    "ours.agent_step_update(action_step1, [ob_id_step1,p_idx_step1,obstacle_dists_step1])\n",
    "\n",
    "# ours.PoseMemory.update_odom_given_pose(odom_step1[:2])\n",
    "# ours.current_pose = ours.PoseMemory.get_odom(as_tuple=True)\n",
    "# ours.update_A_dim_given_obs([ob_id_step1,p_idx_step1], null_proba=[False,False])\n",
    "# Qs = ours.infer_states([ob_id_step1,p_idx_step1], save_hist=False)\n",
    "# print('prior on believed state; action', ours.action, 'colour_ob:', ob_id_step1, 'inf pose:',odom_step1,'belief:', Qs[0].round(3))\n",
    "            \n",
    "# ours.update_believes_with_obs(Qs,action=action_step1, obs=[ob_id_step1,p_idx_step1])\n",
    "# qs = ours.get_belief_over_states()\n",
    "\n",
    "# print('qs',qs[0].round(3))\n",
    "# # # agent_state_mapping for TEST PURPOSES\n",
    "# ours.update_agent_state_mapping(tuple(odom_step1[:2]), [ob_id_step1,p_idx_step1], qs[0])\n",
    "# ours.update_transition_nodes(obstacle_dist_per_actions=obstacle_dists_step1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP2\n",
    "action_step2 = 8\n",
    "ob_id_step2 = 2 \n",
    "excel_step = 2\n",
    "\n",
    "pose_x = float(csvfile['Pose x for agent'].values[excel_step])\n",
    "pose_y = float(csvfile['Pose Y for agent'].values[excel_step])\n",
    "theta = float(csvfile['theta'].values[excel_step])\n",
    "p_idx_step2 = ours.PoseMemory.pose_to_id([pose_x,pose_y], save_in_memory=False)\n",
    "pose = ours.PoseMemory.id_to_pose(p_idx_step2)\n",
    "odom_step2 = [pose[0],pose[1], theta]\n",
    "\n",
    "obstacle_dists_step2 = eval(csvfile['ob_dists'].values[excel_step])\n",
    "ob_id_step2 ,p_idx_step2, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ours.agent_manual_action_step(action_step2)\n",
    "ours.agent_step_update(action_step2, [ob_id_step2,p_idx_step2,obstacle_dists_step2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP3\n",
    "action_step3 = 4\n",
    "ob_id_step3 = 3\n",
    "excel_step = 3\n",
    "\n",
    "pose_x = float(csvfile['Pose x for agent'].values[excel_step])\n",
    "pose_y = float(csvfile['Pose Y for agent'].values[excel_step])\n",
    "theta = float(csvfile['theta'].values[excel_step])\n",
    "p_idx_step3 = ours.PoseMemory.pose_to_id([pose_x,pose_y], save_in_memory=False)\n",
    "pose = ours.PoseMemory.id_to_pose(p_idx_step3)\n",
    "odom_step3 = [pose[0],pose[1], theta]\n",
    "obstacle_dists_step3 = eval(csvfile['ob_dists'].values[excel_step])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ours.agent_manual_action_step(action_step3)\n",
    "ours.agent_step_update(action_step3, [ob_id_step3,p_idx_step3,obstacle_dists_step3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP4 NO OB\n",
    "action_step4 = 2\n",
    "ob_id_step4 = 0 \n",
    "excel_step = 0\n",
    "\n",
    "#STEP4 WITH NEW OB\n",
    "# action_step4 = 2\n",
    "# ob_id_step4 = 4 \n",
    "# excel_step = 4\n",
    "\n",
    "pose_x = float(csvfile['Pose x for agent'].values[excel_step])\n",
    "pose_y = float(csvfile['Pose Y for agent'].values[excel_step])\n",
    "theta = float(csvfile['theta'].values[excel_step])\n",
    "p_idx_step4 = ours.PoseMemory.pose_to_id([pose_x,pose_y], save_in_memory=False)\n",
    "pose = ours.PoseMemory.id_to_pose(p_idx_step4)\n",
    "odom_step4 = [pose[0],pose[1], theta]\n",
    "obstacle_dists_step4= eval(csvfile['ob_dists'].values[excel_step])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ours.agent_manual_action_step(action_step4)\n",
    "ours.agent_step_update(action_step4, [ob_id_step4,p_idx_step4,obstacle_dists_step4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ours.agent_state_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ours.B[0].shape)\n",
    "ours.agent_state_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ours.A[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A0 = plot_likelihood(ours.A[0], ours.agent_state_mapping, tittle_add='observation')\n",
    "A1 = plot_likelihood(ours.A[1], ours.agent_state_mapping, tittle_add='pose')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plot_state_in_map(ours.B[0], ours.agent_state_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from map_dm_nav.visualisation_tools import pickle_dump_model\n",
    "from pathlib import Path\n",
    "\n",
    "# pickle_dump_model(ours, store_path=Path('/home/idlab332/workspace/ros_ws/src/map_dm_nav/map_dm_nav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pose_id = 0\n",
    "visit = 0\n",
    "from pathlib import Path\n",
    "import os\n",
    "a = str(pose_id) + '_' + str(visit)\n",
    "store_path = Path.cwd() / 'tests' /  a\n",
    "\n",
    "store_path\n",
    "store_path = str(store_path)\n",
    "os.path.exists(store_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_transitions(H_model.B[0], H_model.agent_state_mapping, H_model.possible_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "actions_plots = plot_transitions_per_actions(H_model.B[0], H_model.agent_state_mapping, H_model.possible_actions)\n",
    "# list = plt.get_fignums()\n",
    "plt.tight_layout(pad=35)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_plot = plot_transitions(ours.B[0], ours.agent_state_mapping, ours.possible_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_plot_compare = compare_B1_B2_plots(B_v1_test1_ob, V_v1_test1_ob, ours.agent_state_mapping, ours.possible_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUB TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def part1(self,qs):\n",
    "\n",
    "    qs_arg_max = np.argmax(qs)  #NOTE: not sure this is ideal...\n",
    "    model_B = self.get_B()[:,qs_arg_max,:]\n",
    "    median = np.median(model_B)\n",
    "    B = model_B[model_B > median] \n",
    "    certitude_threshold = max(np.mean(B), 0.15)\n",
    "    return certitude_threshold, qs_arg_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def part2(qs, B_certain_trans, I):\n",
    "    qs_arg_max = np.argmax(qs)\n",
    "    for n in range(4):\n",
    "        \n",
    "        I_next = ((B_certain_trans.T @ I[-1]) > 0).astype(float) # New reachable states (as bool -> float)\n",
    "        I_next = np.sum(I_next, axis=0) #We consider all states regardless of action\n",
    "        I.append(I_next)\n",
    "        if I[-1][qs_arg_max] >= qs[qs_arg_max]:\n",
    "            print('we end process induction in ',n+1,' steps,current state', qs_arg_max)\n",
    "            n-=1\n",
    "            break\n",
    "    n+=1\n",
    "    return I, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = H_model.get_belief_over_states()[0]\n",
    "next_sim_qs = [np.array([\n",
    "        0.00297072, 0.0029671 , 0.00296772, 0.00213682, 0.00216489,\n",
    "        0.00216486, 0.00203948, 0.00276972, 0.0029765 , 0.00203766,\n",
    "        0.00203773, 0.00204936, 0.00298157, 0.00300263, 0.00296908,\n",
    "        0.00203766, 0.00296783, 0.0029674 , 0.00188876, 0.00296883,\n",
    "        0.00241505, 0.00203808, 0.00298006, 0.00296959, 0.00203822,\n",
    "        0.0029696 , 0.0021555 , 0.00297541, 0.00297485, 0.00296827,\n",
    "        0.00203807, 0.00203807, 0.00204936, 0.85620934, 0.00206093,\n",
    "        0.00206093, 0.00206093, 0.00206093, 0.00206092, 0.00206093,\n",
    "        0.00206093, 0.00206092, 0.00206092, 0.00206093, 0.00206093,\n",
    "        0.00206091, 0.00206092, 0.00206092, 0.00206093, 0.00206092,\n",
    "        0.00206092, 0.00206093, 0.00206092, 0.00206092, 0.00206092,\n",
    "        0.00206092, 0.00206092, 0.00245272, 0.00205433, 0.00206053,\n",
    "        0.00208947, 0.0019949 , 0.00206101])]\n",
    "print('next state:', np.argmax(next_sim_qs))\n",
    "# sim_qo_pi = H_model.get_expected_observation(next_sim_qs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "certitude_threshold, qs_arg_max = part1(H_model, qs)\n",
    "I = [copy.copy(H_model.Cs)]\n",
    "#Keep only certain Transitions\n",
    "B_certain_trans = (H_model.get_B() > certitude_threshold).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('START with preferred state', np.argmax(I), I)\n",
    "print('we are in starting state', qs_arg_max, 'prob',qs[qs_arg_max])\n",
    "#from preferred states, which states lead to it then we repeat until we are in qs\n",
    "I_end,m = part2(qs, B_certain_trans, copy.copy(I))\n",
    "print('m', m)\n",
    "for i, step_I in enumerate(I_end):\n",
    "    print('step',i, step_I)\n",
    "    print(np.argwhere(step_I > np.amin((step_I >0).astype(float))).flatten())\n",
    "    # print('B*I', B_certain_trans.T.dot(step_I))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('considered step',m)\n",
    "H =  np.log(0.25)*I_end[m].dot(next_sim_qs[0])\n",
    "print('H',H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figures = plot_transitions_per_actions(B_certain_trans, H_model.agent_state_mapping, H_model.possible_actions, selected_actions = [9,10,11])\n",
    "plt.tight_layout(pad=35)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
